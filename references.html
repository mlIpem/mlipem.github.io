<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>References | Exploring music interactions</title>
<meta name="author" content="Marc Leman">
<meta name="description" content="Bader, R. (Ed.). (2018). Springer handbook of systematic musicology. Springer. Bonicco-Donato, D. (2016). Une archéologie de l’interaction. De David Hume à Erving Goffman. Paris: Vrin. Bürkner P....">
<meta name="generator" content="bookdown 0.41 with bs4_book()">
<meta property="og:title" content="References | Exploring music interactions">
<meta property="og:type" content="book">
<meta property="og:url" content="https://www.ugent.be/references.html">
<meta property="og:image" content="https://www.ugent.be/images/cover.jpeg">
<meta property="og:description" content="Bader, R. (Ed.). (2018). Springer handbook of systematic musicology. Springer. Bonicco-Donato, D. (2016). Une archéologie de l’interaction. De David Hume à Erving Goffman. Paris: Vrin. Bürkner P....">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="References | Exploring music interactions">
<meta name="twitter:description" content="Bader, R. (Ed.). (2018). Springer handbook of systematic musicology. Springer. Bonicco-Donato, D. (2016). Une archéologie de l’interaction. De David Hume à Erving Goffman. Paris: Vrin. Bürkner P....">
<meta name="twitter:image" content="https://www.ugent.be/images/cover.jpeg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/Lato-0.4.9/font.css" rel="stylesheet">
<link href="libs/Roboto_Mono-0.4.9/font.css" rel="stylesheet">
<link href="libs/Montserrat-0.4.9/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.8.0/transition.js"></script><script src="libs/bs3compat-0.8.0/tabs.js"></script><script src="libs/bs3compat-0.8.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
<script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-99618359-1', 'auto');
      ga('send', 'pageview');

    </script><!-- Google tag (gtag.js) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-CDTTJLM7N4"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-CDTTJLM7N4');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="style/style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h2>
        <a href="index.html" title="">Exploring music interactions</a>
      </h2>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li><a class="" href="chapTheory.html"><span class="header-section-number">1</span> Theory</a></li>
<li><a class="" href="chapModelling.html"><span class="header-section-number">2</span> Modelling</a></li>
<li><a class="" href="chapListener.html"><span class="header-section-number">3</span> Listener appreciation</a></li>
<li><a class="" href="chapDancer.html"><span class="header-section-number">4</span> Dancer synchronization</a></li>
<li><a class="" href="chapViolinist.html"><span class="header-section-number">5</span> Violin player visual feedback</a></li>
<li><a class="" href="chapExoskeletons.html"><span class="header-section-number">6</span> Two violin players’ haptic feedback</a></li>
<li><a class="" href="chapTappers1.html"><span class="header-section-number">7</span> Two finger tappers’ entrainment (Part 1)</a></li>
<li><a class="" href="chapTappers2.html"><span class="header-section-number">8</span> Two finger tappers’ entrainment (Part 2)</a></li>
<li><a class="" href="chapConclusion.html"><span class="header-section-number">9</span> Conclusion</a></li>
<li><a class="active" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mlIpem/ExploringMusicInteractionWithR">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="references" class="section level1 unnumbered">
<h1>References<a class="anchor" aria-label="anchor" href="#references"><i class="fas fa-link"></i></a>
</h1>
<!-- ## chapTheory References -->
<!-- Reybrouck and Van Dyck (2024), -->
<!-- Leman (2007, 2016), -->
<!-- Bader (2018), -->
<!-- Bonicco-Donato (2016), -->
<!-- Langner (2015), -->
<!-- Schneider (2018a, b), -->
<!-- Collins et al. (2014), -->
<!-- Sears et al. (2018), -->
<!-- Godøy and Leman (2010), -->
<!-- Clayton et al. (2005), -->
<!-- Trost et al. (2017), -->
<!-- Robbins et al. (2010) -->
<!-- ## chapModelling References -->
<!-- Buerckner (2018), -->
<!-- Buerckner (2017, 2018, 2021), -->
<!-- Rosso et al. (2023) -->
<!-- McElreath (2020) -->
<!-- ## chapListener References -->
<!-- Jacobs et al. (in preparation) -->
<!-- ## chapDancer References -->
<!-- Tabeli et al. (2023), -->
<!-- McElreath (2020) -->
<!-- ## chapViolinist References -->
<!-- Campo et al. (2023a, 2023b, 2024) -->
<!-- ## chapTappers References -->
<!-- (Demos & Palmer, 2023) -->
<!-- (e.g. Heggli et al., 2019) Kuramoto models -->
<!-- (see Repp and Su (2012) for a review of finger tapping and anticipation -->
<!-- (e.g. McElreath, 2020, Gelman et al., 2013) -->
<!-- , see a number of blogs listed at the end of this chapter -->
<!-- (Rosso et al., 2021, 2023) -->
<p>Bader, R. (Ed.). (2018). Springer handbook of systematic musicology. Springer.</p>
<p>Bonicco-Donato, D. (2016). Une archéologie de l’interaction. De David Hume à Erving Goffman. Paris: Vrin.</p>
<p>Bürkner P. C. (2021). Bayesian Item Response Modelling in R with brms and Stan. Journal of Statistical Software. <a href="doi:10.18637/jss.v100.i05" class="uri">doi:10.18637/jss.v100.i05</a></p>
<p>Bürkner P. C. (2018). Advanced Bayesian Multilevel Modeling with the R Package brms. The R Journal. <a href="doi:10.32614/RJ-2018-017" class="uri">doi:10.32614/RJ-2018-017</a></p>
<p>Bürkner P. C. (2017). brms: An R Package for Bayesian Multilevel Models using Stan. Journal of Statistical Software. <a href="doi:10.18637/jss.v080.i01" class="uri">doi:10.18637/jss.v080.i01</a></p>
<p>Campo, A., Michałko, A., Van Kerrebroeck, B., Stajic, B., Pokric, M., and Leman, M. (2023a). The assessment of presence and performance in an AR environment for motor imitation learning: A case-study on violinists, Computers in Human Behavior, Volume 146, 2023, 107810, ISSN 0747-5632, <a href="https://doi.org/10.1016/j.chb.2023.107810" class="uri">https://doi.org/10.1016/j.chb.2023.107810</a>.</p>
<p>Campo, A., Michałko, A., Van Kerrebroeck, B., and Leman, M. (2023b).
Dataset for the assessment of presence and performance in an augmented reality environment for motor imitation learning: A case-study on violinists. Data in Brief 51 109663.
<a href="https://10.1016/j.chb.2023.107810" class="uri">https://10.1016/j.chb.2023.107810</a></p>
<p>Campo, A., Van Kerrebroeck, B., Leman, M. (2024).
MC-AR — A software suite for comparative mocap analysis in an augmented reality environment
Software Impacts 19 100605. <a href="https://doi.org/10.1016/j.dib.2023.109663" class="uri">https://doi.org/10.1016/j.dib.2023.109663</a>.</p>
<p>Campo, A. et al. (submitted). Haptic Feedback in Violin Education: A Case Study of Robotic Exoskeleton-Mediated Motor Learning.</p>
<p>Carpenter, B. (2018). Predator-Prey Population Dynamics:
the Lotka-Volterra model in Stan.
<a href="https://mc-stan.org/users/documentation/case-studies/lotka-volterra-predator-prey.html" class="uri">https://mc-stan.org/users/documentation/case-studies/lotka-volterra-predator-prey.html</a></p>
<p>Clayton, M., Sager, R., &amp; Will, U. (2005). In time with the music: the concept of entrainment and its significance for ethnomusicology. In European meetings in ethnomusicology.(Vol. 11, pp. 1-82). Romanian Society for Ethnomusicology.</p>
<p>Collins, T., Tillmann, B., Barrett, F. S., Delbé, C., &amp; Janata, P. (2014). A combined model of sensory and cognitive representations underlying tonal expectations in music: from audio signals to behavior. Psychological review, 121(1), 33.</p>
<p>Demos, A. and Palmer, C. (2023).
Social and nonlinear dynamics unite: musical group synchrony,
Trends in Cognitive Sciences. <a href="https://doi.org/10.1016/j.tics.2023.05.005" class="uri">https://doi.org/10.1016/j.tics.2023.05.005</a></p>
<p>Dunn, P. and Smyth, G. (2018). Generalized linear models with examples in R. New York: Springer.</p>
<p>Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp; Rubin, D. B. (2014). Bayesian Data Analysis (3rd ed.). CRC Press.</p>
<p>Gesmann, M., and Morris, J. Hierarchical Compartmental Reserving Models. Casualty Actuarial Society, CAS Research Papers, 19 Aug. 2020, <a href="https://www.casact.org/sites/default/files/2021-02/compartmental-reserving-models-gesmannmorris0820.pdf" class="uri">https://www.casact.org/sites/default/files/2021-02/compartmental-reserving-models-gesmannmorris0820.pdf</a></p>
<p>Hallam, S. and Himonides, E. (2022). The power of music. An exploration of the evidence. Open book publishers.</p>
<p>Kruschke, J. K. (2015). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan (2nd ed.). Academic Press.</p>
<p>Langner, G. D. (2015). The neural code of pitch and harmony. Cambridge University Press.</p>
<p>Leman, M. (2007). Embodied music cognition and mediation technology. MIT press.</p>
<p>Leman, M. (2016). The expressive moment: How interaction (with music) shapes human empowerment. MIT press.</p>
<p>McElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd ed.). CRC Press. See <a href="https://github.com/rmcelreath/stat_rethinking_2020" class="uri">https://github.com/rmcelreath/stat_rethinking_2020</a>.</p>
<p>Michałko, A., Di Stefano, N., Campo, A. and Leman, M. (2024). Enhancing human-human
musical interaction through kinesthetic haptic feedback using wearable exoskeletons: theoretical foundations, validation scenarios, and limitations. Frontiers in Psychology. 15:1327992. <a href="https://doi.org/10.3389/fpsyg.2024.1327992" class="uri">https://doi.org/10.3389/fpsyg.2024.1327992</a></p>
<p>Michałko, A., Six, J., Campo, A., Van Kerrebroeck, B., Pokric, M., Leman, M. (submitted). Amateur Violin practice in augmented reality: Exploring user’s behaviour and experience.</p>
<p>Repp, B., Su, YH (2013). Sensorimotor synchronization: A review of recent research (2006–2012). Psychonomic Bulletin &amp; Review 20, 403–452. <a href="https://doi.org/10.3758/s13423-012-0371-2" class="uri">https://doi.org/10.3758/s13423-012-0371-2</a></p>
<p>Reybrouck, M., &amp; Van Dyck, E. (2024). Is music a drug? How music listening may trigger neurochemical responses in the brain. Musicae Scientiae, 0(0). <a href="https://doi.org/10.1177/10298649241236770" class="uri">https://doi.org/10.1177/10298649241236770</a></p>
<p>Roback, P. and Legler, J. (2021). Beyond multiple linear regression. Applied generalized liear models and multilevels models in R. CRC press. See <a href="https://bookdown.org/roback/bookdown-BeyondMLR/" class="uri">https://bookdown.org/roback/bookdown-BeyondMLR/</a></p>
<p>Robbins, T, Everitt, B, and Nutt, D. (2010). The neurobiology of addiction. Oxford University Press.</p>
<p>Rosso, M., Maes, P.J. &amp; Leman, M. (2021). Modality-specific attractor dynamics in dyadic entrainment. Sci Rep 11, 18355. <a href="https://doi.org/10.1038/s41598-021-96054-8" class="uri">https://doi.org/10.1038/s41598-021-96054-8</a></p>
<p>Rosso, M., Van Kerrebroeck, B., Maes, P-J &amp; Leman, M. (2023). Embodied perspective taking enhances interpersonal synchronization. A body-swap study. iScience. (accepted)</p>
<p>Rosso, M., Maes PJ. &amp; Leman, M. (in preparation). (Tentative title) Estimating coupling and phase delay parameters of entrainment in a body-swap study.</p>
<p>Russell JA. (1980). A circumplex model of affect. Journal of Personality and Social Psychology. 1980;39:1161–1178. doi: 10.1037//0022-3514.79.2.286.</p>
<p>Schneider, A. (2018a). Pitch and pitch perception. In Springer Handbook of Systematic Musicology (pp. 605-686). Springer, Berlin, Heidelberg.</p>
<p>Schneider, A. (2018b). Perception of timbre and sound color. In Springer Handbook of Systematic Musicology (pp. 687-725). Springer, Berlin, Heidelberg.</p>
<p>Sears, D. R., Pearce, M. T., Spitzer, J., Caplin, W. E., &amp; McAdams, S. (2019). Expectations for tonal cadences: Sensory and cognitive priming effects. Quarterly Journal of Experimental Psychology, 72(6), 1422–1438. <a href="https://doi.org/10.1177/1747021818814472" class="uri">https://doi.org/10.1177/1747021818814472</a></p>
<p>Seth, A. K. (2015). The cybernetic Bayesian brain - From interoceptive inference to sensorimotor contingencies.
In T. Metzinger &amp; J. M. Windt (Eds). Open MIND: 35(T). Frankfurt am Main: MIND Group. doi: 10.15502/9783958570108</p>
<p>Singer, J. and Willett, J. (2003). Applied longitudinal data analysis. Modeling change and event occurrence. Oxford University Press.</p>
<p>Talebi, M. , Campo, A., Aarts, N. &amp; Leman, M. (2023).
Influence of musical context on sensorimotor synchronization in classical ballet solo dance. Plos one 18 (4), e0284387.
<a href="https://doi.org/10.1371/journal.pone.0284387" class="uri">https://doi.org/10.1371/journal.pone.0284387</a></p>
<p>Trost, W. J., Labbé, C., &amp; Grandjean, D. (2017). Rhythmic entrainment as a musical affect induction mechanism. Neuropsychologia, 96, 96-110.</p>
<p>Vuust, Peter &amp; Heggli, Ole &amp; Friston, Karl &amp; Kringelbach, Morten. (2022). Music in the brain. Nature Reviews Neuroscience. 23. 10.1038/s41583-022-00578-5.</p>

</div>








































  <div class="chapter-nav">
<div class="prev"><a href="chapConclusion.html"><span class="header-section-number">9</span> Conclusion</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <h2>Provide your feedback</h2>
    <!--<p>Now is a great time to provide feedback</p>-->
        <ul class="list-unstyled">
<!--<li><a href="https://forms.gle/nq9RmbxJyZXQgc948">Provide feedback (5 min)</a></li>--><li><a href="https://www.ugent.be/lw/kunstwetenschappen/ipem/en/services/asil">art and science interaction lab</a></li>
        </ul>
<hr>
<nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav"><li><a class="nav-link" href="#references">References</a></li></ul>
      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mlIpem/ExploringMusicInteractionWithR/blob/main/11_References.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mlIpem/ExploringMusicInteractionWithR/edit/main/11_References.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Exploring music interactions</strong>" was written by Marc Leman. It was last built on 2024-12-19.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
