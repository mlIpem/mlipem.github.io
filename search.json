[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"online home Exploring music interactions, R, book musical data analysis, visualization modeling.","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"preface.html","id":"description","chapter":"Preface","heading":"Description","text":"","code":""},{"path":"preface.html","id":"goal","chapter":"Preface","heading":"Goal","text":"Many people experience music positive force lives. probably based human ability use music creating precarious interaction states high value.book, use statistical modeling increase understanding interaction states.research focuses musical domain, applies many domains human interactive activity, conversations, sports, teamwork.\nhope book interest readers inside outside field music research.","code":""},{"path":"preface.html","id":"limitations","chapter":"Preface","heading":"Limitations","text":"Every book limitations, important transparent outset.First, focus exclusively behavioral data. recognize importance neurobiology, expertise lies elsewhere. hope others build work incorporating neurobiological data fully support theoretical claims.Second, analysis behavioral data, focus primarily timing. Specifically, examine people act time one another, music playing dancing. chose focus timing crucial building maintaining interactions, music provides excellent domain understanding self-augmented interactions.Third, book textbook, rather guide navigating space theory data. exploring music interactions, acknowledge research area still infancy.Finally, book applications biofeedback technologies, rather data. data collected using technologies augmented reality, virtual reality, exoskeletons, delve deeply data acquisition.Given limitations, , limited capacities musicologists, offer book open explorative contribution field. welcome suggestions improvement readers.","code":""},{"path":"preface.html","id":"overview","chapter":"Preface","heading":"Overview","text":"\nTABLE 0.1: Overview chapters\nTable 0.1 gives overview chapters.first two chapters theory methodology. Chapter 1 introduces theory self-augmented interactions Bayesian perspective developed subsequent chapters.\nChapter 2 introduces regression modelling main tool analysis data timing.first two chapters theory methodology. Chapter 1 introduces theory self-augmented interactions Bayesian perspective developed subsequent chapters.\nChapter 2 introduces regression modelling main tool analysis data timing.Chapter 3 accesses listener’s music appreciation using questionnaires. chapter shows questionnaires used structural equation model validating theory appreciation. chapter timing.Chapter 3 accesses listener’s music appreciation using questionnaires. chapter shows questionnaires used structural equation model validating theory appreciation. chapter timing.Chapter 4 shows synchronization movement music can influenced classical ballet dancing narrative. chapter applies circular-linear smooth regression approach contrast musical phrases selected time.Chapter 4 shows synchronization movement music can influenced classical ballet dancing narrative. chapter applies circular-linear smooth regression approach contrast musical phrases selected time.Chapter 5 effect parallax, using 3D versus 2D music play-along system violin, training synchronized bowing gestures orchestra. reduces bowing gesture discrete events applies regression way similar previous chapter, including approach contrast musical phrases.Chapter 5 effect parallax, using 3D versus 2D music play-along system violin, training synchronized bowing gestures orchestra. reduces bowing gesture discrete events applies regression way similar previous chapter, including approach contrast musical phrases.Chapter 6 effect auditory, visual haptic modalities synchronized playing two violinists, connected via exoskeletons. go deeper feature extraction use regression categorical predictors.Chapter 6 effect auditory, visual haptic modalities synchronized playing two violinists, connected via exoskeletons. go deeper feature extraction use regression categorical predictors.Chapter 7 prepares study synchronized human finger tapping, using simulated data.\nchapter, develop dynamic system described ordinal differential equations. use dynamic system predictor regression capture entrainment coupling strength.Chapter 7 prepares study synchronized human finger tapping, using simulated data.\nchapter, develop dynamic system described ordinal differential equations. use dynamic system predictor regression capture entrainment coupling strength.Chapter 8 builds previous chapter. applies dynamic system synchronized human finger tapping. previous chapter bit advanced show type non-linear regression powerful promising future work field.Chapter 8 builds previous chapter. applies dynamic system synchronized human finger tapping. previous chapter bit advanced show type non-linear regression powerful promising future work field.brief concluding chapter 9 offers perspectives future work field.brief concluding chapter 9 offers perspectives future work field.","code":""},{"path":"preface.html","id":"usage","chapter":"Preface","heading":"Usage","text":"recommended start chapters theory 1 methodology 2 offer overall framework subsequent chapters.Chapter 7 chapter 8 closely related can best read order.\nchapters, however, can read order reader’s preference.book organized reader can easy access code R.\nReference code, , given start chapter.\nchapter follow logic: first data preparation data plotting, modelling plotting modelling outcomes, contrast testing sometimes plotting tests. try maintain logic much possible reflects workflow statistical modelling well structure chapter.easy access code use file name convention.\nOverall, syntax XXX_YYY_ZZZ.R:XXX indicates shortname chapter, chapListener, chapDancer. names shortcuts full chapter names.XXX indicates shortname chapter, chapListener, chapDancer. names shortcuts full chapter names.YYY sequence number, 02, O3, indicates order script processed.YYY sequence number, 02, O3, indicates order script processed.ZZZ processing name, Initialization, DataPreparation, DataPlotting, Modelling, indicates kind processing dealt .ZZZ processing name, Initialization, DataPreparation, DataPlotting, Modelling, indicates kind processing dealt ..R just extension indicate fact file pure R-script..R just extension indicate fact file pure R-script.example, filename chapListener_02_DataPreparation.R R-script data preparation chapter listener. ’s sequence number 02 suggests 01, even 00 script executed first.\nscript chapListener_05_ModelPlotting.R plotting results modelling. executed running modelling script script_chapListener_04_Modelling.R. script requires least scripts 00, 01, 02 03 considered.scripts run chapters called: chapAll_00_Initialization.R chapAll_01_Functions.R.","code":""},{"path":"preface.html","id":"level","chapter":"Preface","heading":"Level","text":"book written MA-students, PhD-students, interested researchers.\nlevel statistics knowledge might required order able read book.\nHowever, motivation essential self-learning can profit explorations code provided.Much statistical inspiration came McElreath (2020), also Kruschke (2015) Gelman et al. (2014) recommended. Moreover, can useful consult books regression, example, Roback Legler (2021), Singer Willet (2003), Dunn Smyth (2018).","code":""},{"path":"preface.html","id":"setting-up-your-computational-environment","chapter":"Preface","heading":"Setting up your computational environment","text":"computational tool statistical analysis, use R several R-packages RStudio get initialized : chapAll_00_Initialization.R. sure packages installed system try re-calculate scripts.statistical modelling can computational intensive.\nserver used parallel processing.\nserver runs R version 4.2.3 (2023-03-15) R-Studio Server 2023.03.0 build 386 Ubuntu 22.04.2 LTS. hardware consists dual AMD Epyc 74F3 CPU (48 cores total, 96 threads), 128 GB (8x16GB) ECC DDR4 RAM Nvidia RTX 3090TI graphics card.offer fitted models computation intensive.","code":""},{"path":"preface.html","id":"finding-sources","chapter":"Preface","heading":"Finding sources","text":"Sources found Data, Code, Figures, Fitted.","code":""},{"path":"preface.html","id":"about-the-author","chapter":"Preface","heading":"About the author","text":"Marc Leman Methusalem research professor Ghent University, specialized epistemology methodology music research, founder ASIL.","code":""},{"path":"preface.html","id":"acknowledgements","chapter":"Preface","heading":"Acknowledgements","text":"work supported Methusalem grant Ghent University, grant number 01M00208, BOF UGent.","code":""},{"path":"chapTheory.html","id":"chapTheory","chapter":"1 Theory","heading":"1 Theory","text":"assumptions – call hypotheses – tested book refer theory music interaction. theory resembles grandmother told us1, namely , achieve something life, little effort needed. idea applies human interaction music. effort form alert active participation needed establish interaction music, achieve something interaction, feeling power beauty. music?chapter attempt reformulate grandmother’s advice perspective core theoretical concepts prominent modern music research.","code":""},{"path":"chapTheory.html","id":"self-augmented-interactions","chapter":"1 Theory","heading":"1.1 Self-augmented interactions","text":"Basically, book assume people urge create engage particular interaction states involving music, experience benefits . interaction states special sense facilitate increased alertness attention, reduce stress, optimize perception critical spatial-temporal actions, engaging chain bodily-related changes affect human well-. states facilitate effects called self-augmented interaction states.\nself-augmented people create interactions states , volitional, choice decision.goal find evidence supports theory (falsify ).\nHowever, moment, far able prove theory self-augmented interaction, reason research domain young insufficiently mature handle enormous complexity going . Evidence likely based joint effort behavioral neuroscience studies, involving neurobiology necessary component entire picture. Increased alertness, reduced stress, pleasure motivation suggest involvement neurotransmitters hormones norepinephrine, oxytocine, cortisol, dopamine regulate brain functions, affecting behavioral activities interactions2.\nenvision complexity dynamic mechanism whose state can build time, maintained , declines becomes normal state back . kind complexity challenging. able identify self-augmented interaction state already challenge.However, contribute theory focusing timing. ’s tiny little part grand dynamic mechanism believe timing interesting distinguishing, measurable, partly controllable, feature interacting.paradigmatic example tempo music played ensemble musicians. tempo feature timing created maintained collaborative effort co-regulation musicians ensemble. precarious state associated ensemble’s musical quality. sure, tempo interesting feature timing, ’s important one. can measured, example, identifying onsets audio, calculating underlying distribution inter-onset intervals. timing stable, special interaction state built upon alertness, physical effort, fine sensory-motor control. expected features self-augmented interaction state. bodily features associated states can studied detail.short, theory self-augmented interaction improving , one another way. drive probably yet entirely clear. solely effort – pleasure – reward – motivation chain something , something set goals beliefs?\ncomplete theory self-augmented interaction might yet within reach, goal contribute , firstly posing valuable theory, secondly, offering data-analysis tools sharpen details contributing insights may lead us towards ultimate theory.","code":""},{"path":"chapTheory.html","id":"supporting-theories","chapter":"1 Theory","heading":"1.2 Supporting theories","text":"ultimate theory, clearly complex dynamic theory, draws upon number theories humans interacting environment.\ntheories relate embodiment, prediction expression.","code":""},{"path":"chapTheory.html","id":"embodiment","chapter":"1 Theory","heading":"Embodiment","text":"Embodiment holds idea humans repertoire gestures actions, use coding decoding music3. music playing (coding), different kinds bodily gestures shape phrasing, articulations, intonations, structure sound. Accordingly, musical sound reflect traces gestures patterns, called moving sonic forms. listening dancing (decoding), human decoder recruits bodily gestures gesture repertoire align moving sonic forms. alignment allows human decoder develop understanding music gestural/action perspective, , embodying gestural traces music.Musical embodiment, encoding decoding gestures, works many people shared repertoire gestures actions. repertoire partly biological, due shared bio-mechanics biological basis humans cultures, partly cultural, due codifications people move behave different cultural contexts.timing rooted bodily actions encode sound cues timing, close relationship timing body movement. Sometimes can hard detect timing cues audio likely timing cues can also extracted bowing gestures. rely movement recordings motion capture systems4.","code":""},{"path":"chapTheory.html","id":"prediction","chapter":"1 Theory","heading":"Prediction","text":"Embodiment connected prediction, idea moving sonic forms can anticipated human encoder/decoder5. Often anticipation based gesturing. example, dancing beat music, gestural alignment body movement typically initiated ahead beat. ahead, movement late.Moving sync musical beat thus proves embodiment fundamentally predictive. Consider conducting preferred piece music cd6. conducting music likely ahead time, due predictive processing brain. really engaged conducting, probably gives feeling agency power. ? ’s effect reverse causality illusion7. illusion, appears gesturing causes music. movement cause, music effect.\nreason illusion correlation contiguity: gestural musical events go hand hand, gestural events come musical events.Obviously, perception reverse causality illusory music goes gesturing suddenly stops. Nevertheless, experience reverse causality illusion may create strong feeling control (agency). may feel gestures consequences music. may feel control music, gives particular sense power satisfaction power.connection self-augmented interaction clear.\nEstablishing reverse causality self-created augmented interaction states may crucial ability human decoder create empowering effects.Nevertheless, reverse causality effect. Due prediction, just possible co-regulate action heard another musician, way stable tempo can established collaboration. Prediction everywhere therefore, ’s crucial element understanding self-augmented interaction states can maintained. Effects reverse causality illusion can seen consequence prediction.","code":""},{"path":"chapTheory.html","id":"expression","chapter":"1 Theory","heading":"Expression","text":"Embodiment prediction, considered viewpoint social interaction, supports expression. viewpoint holds gestures social signals, rooted human social biological culturally codified social actions. gesture expressive signal receiver responds expressive signal8. exchanging expressive signals, gestures, sender receiver typically tend trigger\nembodied predictions arousal, enhanced state attention, focus emotional engagement strongly contributes self-augmented interaction states. lead ritualized behavior exchanging gestures habituated.Expression therefore crucial people interact speak expressive timing timing works signal evoking responses audience.\nmutual exchange gestural expressions, thanks predictions, humans capable interacting coordinated manner. musical rhythms enhance exchanges bodily expression rhythms, facilitate formation co-regulated interaction pave way self-augmentation.Together three constructs offer way understanding musical self-augmentation terms gestural, anticipatory, expressive dynamic. Ultimately, dynamic results state senses, cognitive abilities, emotional engagement become sharpened function optimally.","code":""},{"path":"chapTheory.html","id":"moving-sonic-forms","chapter":"1 Theory","heading":"1.3 Moving sonic forms","text":"Given theories, useful define music perspective moving sonic forms emergent patterns endowed expression.","code":""},{"path":"chapTheory.html","id":"pattern-emergence","chapter":"1 Theory","heading":"Pattern emergence","text":"Pattern emergence idea pattern structural features conjugate human disposition emergence. Due disposition structure, emergence may happen. example, auditory system disposition transforms harmonic structure composed 600, 800, 1000, 1200 Hz pitch heard 200 Hz9.auditory disposition may also fuse multiple harmonic patterns chord. harmonic patterns played sequence, fusion may elicit expectations, leading tonal tensions relaxation dynamics10. bottom-mechanisms pattern emergence may compete top-mechanisms patterns formed habits, competition may influence perception tonal tension relaxation, although precise contributions sensory (bottom ) cognitive (long term memory) processing still debated11.similar observation can made rhythms. Rhythms made pulses subsume meter super-structure emerges lower-level pulse structure.\nSimilarly, timbres might blend form emergent patterns texture, phenomenon well-known orchestration.Blending timbres less obvious speech may just blur signal, making less apt understanding semantics. Moreover, music often happens different performers co-regulate actions order generate joint pattern emergence rhythmic, pitch timbre levels. , phenomenon joint speech far less prominent speech. heathed debates moderator intervene tone , leaving word one speaker.","code":""},{"path":"chapTheory.html","id":"endowed-expression","chapter":"1 Theory","heading":"Endowed expression","text":"Music characterized fact emergent patterns get endowed expression. latter refers importance gesturing encoding decoding12. discussed, gestural traces form constituent part sound pattern. mould musical pitch portamento intonation. similar way, make intervals shorter longer order pronounce rhythms. Gestural traces define articulations (e.g., legato staccato), sound color, musical narrative, dynamics (e.g., crescendo diminuendo).short, human gestures get embedded structure music, creating emergent patterns endowed gestural expression.\nemergent patterns define moving sonic forms, necessary generating self-augmented interaction states.","code":""},{"path":"chapTheory.html","id":"interaction-capacities","chapter":"1 Theory","heading":"1.4 Interaction capacities","text":"now ready look music perspective human interaction capacities.\nThree additional concepts complete set concepts introduced chapter.\n: affordance, entrainment, narration.","code":""},{"path":"chapTheory.html","id":"affordance","chapter":"1 Theory","heading":"Affordance","text":"affordance property music capacity act upon affordance called affordance capacity. Affordances sometimes linked notion frozen emotion idea composers performers encode frozen emotion music, listeners capacity decode emotions work affordances. fact, possible replace emotion gesture idea still stands.","code":""},{"path":"chapTheory.html","id":"entrainment","chapter":"1 Theory","heading":"Entrainment","text":"Entrainment capacity human decoder adapt music, aligh , either continuous manner, movement flows along music, discrete manner, movement marks musical events13. word suggests, entrainment implies something music attracts listener.context (co-regulated) sensorimotor synchronization, entrainment associated bias subliminally reduce prediction errors alignment body movement sound cues. entrainment often defined relation synchronization, dynamic adaptation sensorimotor behavior due coupling, entrainment may also defined broader perspective, capacity giving response cues, even brain-principle acting neuronal oscillations.","code":""},{"path":"chapTheory.html","id":"narration","chapter":"1 Theory","heading":"Narration","text":"Last least mention narration, least well-understood principle music research. Narration refers story telling, often associated human encoder. Jazz musicians, example, use patterns previously trained playing gestures kind alphabet construct larger arcs phrases, bind phrases larger structures: stories music. way telling narrative, .e., performance, equally important, builds anticipation, entrainment, affordance capacity.good example Clifford Brown14. legendary jazz trumpeter composer died young age 25 car crash. known ability tell stories music, using patterns previously trained playing gestures construct larger arcs phrases. One famous improvizations Joy Spring. serveral recorded solos piece, one hears similar phrase components arranged differently. One solos widely regarded one best solo improvisations ever played. Brown’s work jazz striking architectonic structure emotional immediacy.Unfortunately, narration often integrated studies embodiment, prediction, expression. small contribution chapter 4 ’s limited work needed domain, sensorimotor cognitive capacities work together.short, music involves several capacities necessary interact environment. capacities well-suited process dynamic structure music, return, emergent patterns.","code":""},{"path":"chapTheory.html","id":"music-addiction","chapter":"1 Theory","heading":"1.5 Music addiction","text":"\nFIGURE 1.1: Engine self-augmented interaction\nLet us come back grandmothers idea, effort needed achieve something. people engage self-augmented interactions require effort? answer pays . However, compelling force behind likely related biological processes addiction15.Figure 1.1 offers rough biological model suggesting interaction music engages physical effort, expression, prediction mechanisms co-engage arousal, valence, agency, activating reward-related processes, dopamine-spread brain, drive human subjects engage music, addiction.\ncycle may support realization self-augmented interaction states.assume emergent patterns endowed expression facilitate generation self-augmented interaction states patterns fit human capacity affordance entrainment. multi-person co-regulation actions sets social context can motivating, formation musical narrative can become compelling.\npays , many ways.","code":""},{"path":"chapTheory.html","id":"note-about-expression-theory","chapter":"1 Theory","heading":"1.6 Note about expression theory","text":"close chapter, something said expression theory often, like narrative, well understood, often neglected.Briefly stated, expression theory based idea expression person calls expressive response person B, turn serves stimulus expression , thus leading mutual exchange expressions might result particular interaction state.\nindeed suggested figure 2.2, dynamic perspective.Although idea simple, expressions always require reasons. many contexts, expressions really don’t require inference presumed cause. Interactions often based direct spontaneous gesturing, implying responses patterns. direct responding goes fast, based alignment, mirroring, including counterpoint gesturing. Interpreting expression terms presumed cause, largely depends context type interaction. main point expressions always point deep underlying state requires inference capture . Thus, expressive interacting may occur without assuming causes expression.Expression biological largely intuitive. Therefore, rather inferencing latent state (known theory mind theory), appropriate speak gestural responding (based mirroring). real power expression exchange dynamic ability build maintain self-augmented states. Expression theory may thus understood terms exchange expressive gestures patterns (possible inferred underlying states always excluded) steer-interaction towards self-augmented states.clarified , question raises whether Bayesian inference applies patterns causes.\nSorry, Bayesian inference explained next chapter.\nAnyhow, answer applies . Responding expression implies processing patterns assumption particular shape observed pattern can seen prior Bayesian inference pattern. Inferring cause expression also apply Bayesian inference scheme. case, prior focus cause, example, emotion, character.\nshort, Bayesian inference general machinery dealing assumptions observations, regardless whether applies expressive forms expressive causes forms.","code":""},{"path":"chapTheory.html","id":"conclusion","chapter":"1 Theory","heading":"1.7 Conclusion","text":"theory music interaction hands, perspective understanding music people people music, . theory evolved several decades research musicology. However, ’s far established theory needs refinement, even reformulation. biased certain trends cognitive science, future, ’s likely neuroscience neurobiology important contribution allowing refinement theory.book, use theory general framework case studies highlight particular phenomena related timing. believe proper description causal modelling timing may contribute understanding theory.\nyes, timing covers tiny small aspect entire theoretical framework believe timing essential cornerstone. linked neuro-something future research!","code":""},{"path":"chapModelling.html","id":"chapModelling","chapter":"2 Modelling","heading":"2 Modelling","text":"Statistical modelling aims establishing connection data theory, basically capturing data estimated parameters assumed model. Outcomes experiments normal distribution thus captured model whose predictors map onto mean standard variation distribution. better accurate conclusions can drawn models, can also clarify key theoretical insights. parameters known, model can predict data. Statistical modelling thus drives domain forwards terms better understanding data’s underlying parameters.chapter depends following scripts data preparation, plotting, modelling model plotting:","code":"\nsource(\"Code/chapAll_00_Initialization.R\")\nsource(\"Code/chapAll_01_Functions.R\")\nsource(\"Code/chapModelling/chapModelling_02_DataPreparation.R\")\nsource(\"Code/chapModelling/chapModelling_03_DataPlotting.R\")\nsource(\"Code/chapModelling/chapModelling_04_Modelling.R\")\nsource(\"Code/chapModelling/chapModelling_05_ModelPlotting.R\")"},{"path":"chapModelling.html","id":"bayesian-epistemology","chapter":"2 Modelling","heading":"2.1 Bayesian epistemology","text":"book adopt overall Bayesian epistemology knowledge acquisition.\napplies subjects interacting environment.\nbest way introduce approach means graph – simple example.\nFIGURE 2.1: Bayesian model\nConsider figure 2.1 graphical description human subject (left circle), observing pattern (middle circle), making inference state caused pattern (right circle).","code":""},{"path":"chapModelling.html","id":"from-pattern-to-state","chapter":"2 Modelling","heading":"From pattern to state","text":"Say, see dog distance ’re sure ’s friendly aggressive. prior belief dog equally likely friendly aggressive.\ndog friendly, ’s likely relaxed posture, ’s aggressive, ’s likely stiff posture. Based dog’s posture, can calculate likelihood posture given particular belief whether dog friendly aggressive.\ncan combine prior belief likelihood data obtain posterior belief. example, dog’s posture relaxed, posterior belief might dog likely friendly.Now, suppose dog suddenly lunges towards , snarling baring teeth. new observation consistent previous belief dog friendly. However, might biased towards maintaining previous belief, even face contradictory evidence.account new observation, can update posterior belief, time new likelihood reflects dog’s aggressive behavior. example, dog’s behavior aggressive, likelihood behavior given dog friendly low, whereas likelihood behavior given dog aggressive high.\nUsing new likelihood, can obtain new posterior belief reflects evidence dog’s posture behavior. example, new posterior belief might dog likely aggressive.dog example illustrates Bayesian reasoning (inferring posterior likelihood prior), dynamic behind reasoning (posterior becomes new prior). observe data, can continue update beliefs (priors) refine understanding world. Additionally, Bayesian reasoning can applied wide range domains, animal behavior music beyond. Patterns human gestures infer underlying state. musical sounds infer underlying expressive state. Note Bayesian inferences rapid direct, rather based conscious steps.Figure 2.1 also suggests possible probe subject’s experiences, example questionnaires physiological measures indicators experiences.\nquestionnaire assumes subject somehow capable translating experiences verbal descriptions.way subject infers dog, also way – researchers – infer data gathered observations experiments. often prior rather uninformative, sometimes can informed. keep option.book, use Bayesian approach general epistemological framework, necessarily data modelling framework. latter lead us machine learning data-modelling involves Bayesian reasoning cycles. modelling stage machine learning, just plain statistics. Yet, general research strategy may adopt Bayesian updating theory. theory self-augmented interaction states typically updated applied concrete case studies.","code":""},{"path":"chapModelling.html","id":"interactions","chapter":"2 Modelling","heading":"Interactions","text":"Next, consider two subjects interacting . can represented using configuration shown 2.1, now applied two subjects.\nsubject state--expressed via pattern. subject observes pattern subject infers state subject.\nFigure 2.2 shows states--two subjects represented fully colored left right cycles (state 1 state 2).\nFIGURE 2.2: Bayesian model 2 subjects\nlikely subjects mutually influenced interacting. Interestingly, timing – typical musical preoccupation – influence reflected timing . shown chapter 8, influence (called: entrainment) draws upon complex dynamics governed mechanisms embodiment, prediction expression. can understood natural bias humans adapt , thus facilitating formation self-augmented interaction state.short, Bayesian epistemology applies subjects interacting, well researcher studying interaction.\nNow know overall approach, let’s go deeper kind modelling can use, given overall Bayesian epistemology.","code":""},{"path":"chapModelling.html","id":"regression","chapter":"2 Modelling","heading":"2.2 Regression","text":"follows, utilize regression tool analysis.\nRegression analysis based idea variable, known response dependent variable, can predicted variables, known predictors independent variables. prediction relies estimating parameters mathematical model, encapsulates relationship variables. parameters include coefficients signify strength direction relationships.Following Buerckner (2018), write\n\\[\\begin{equation}\ny_i \\sim D(\\theta_{1,},\\theta_{2,}, ...)\n\\tag{2.1}\n\\end{equation}\\]\n\nsay response \\(y\\) predicted parameters \\(\\theta_p\\) response distribution D \\(\\)th observation.\nevery parameter \\(\\theta_p\\) can regressed predictor term \\(\\eta_p\\),\ntransformed inverse link function \\(f_p\\), \\(\\theta_{pi} = f_p(\\eta_{pi})\\). Accordingly, every \\(\\eta_p\\) regressed :\n\\[\\begin{equation}\n\\eta = X\\beta + Zu + \\sum_{k=1}^{K} s_k(x_{k})\n\\tag{2.2}\n\\end{equation}\\]\n\n\\(\\beta\\) \\(u\\) respective coefficients population-level group-level (also known random variables),\n\\(X\\), \\(Z\\) corresponding design matrices.\nterms \\(s_k(x_k)\\) symbolize optional smooth functions unspecified form based covariates \\(x_k\\) fitted via functions (e.g. splines, gaussian processes).\nexample, work normal distribution, model mean standard deviance according Expression (2.2). can use splines capture covariance among data (\\(x_k\\)) occur time.","code":""},{"path":"chapModelling.html","id":"data-as-indicator","chapter":"2 Modelling","heading":"2.3 Data as indicator","text":"Let’s work regression example using timing data.\nAlong way, ’ll introduce relevant concepts return later chapters.go.\nConsider simple question whether humans can synchronize finger tap along regular metronome tic.\nFinger tapping points central phenomenon musical synchronization, namely brain predictive.\nCan use regression say something finger tapping?\n","code":""},{"path":"chapModelling.html","id":"dataset","chapter":"2 Modelling","heading":"Dataset","text":"use data study Rosso et al. (2023), subject instructed tap finger table, along regular metronome tics, heard every \\(0.6\\) seconds, \\(390\\) seconds.\nfinger touches measurement device table, clock time gets registered tap.\nalso registers tic.\ndata can arranged array time values tap tic appeared.\nfirst six rows dataset look like:\nTABLE 2.1: Tic tap times\ncolumn time marks numerical time values names factor two levels: tic tap.\nAnother view variables given :","code":"## 'data.frame':    6 obs. of  2 variables:\n##  $ time : num  0.12 0.6 0.64 1.2 1.21 1.8\n##  $ names: Factor w/ 2 levels \"tic\",\"tap\": 2 1 2 1 2 1"},{"path":"chapModelling.html","id":"period","chapter":"2 Modelling","heading":"Period","text":"\nTABLE 2.2: Periods: inter-tap inter-tic intervals\nvalues dtime based time difference successive tap, well time difference successive tic.\nhistogram periods shown figure 2.3, left panel.\nFIGURE 2.3: Left panel, histogram periods. Right panel, histogram relative phases. blue line shows mean -2.03[rad] according circular model. ocre line shows mean -1.09[rad] according non-circular model. red line shows mean -1.68[rad] according synchronization strength measure\norder able count periods,\nsmall containers covering small ranges (= bins) defined setting binwidth, periods slightly different value fit.\ncurrent purposes binwidth important small enough small, good amount periods fit bin.\nWhenever measured period falls bin, bin count increases.\nhistogram left reveals metronome’s periods, shown gray color, exactly \\(0.6 ~s\\), expected, close. due small differences (milliseconds) tics.","code":""},{"path":"chapModelling.html","id":"relative-phase","chapter":"2 Modelling","heading":"Relative phase","text":"\nTABLE 2.3: Data relative phase\ncalculate relative phase, let’s go back previous table showing tic tap times metronome subject.\ntap event row \\(n\\) (\\(tap_n\\)) considered within two surrounding tic events closest time, found row \\(m\\) row \\(m+\\) (next row find tic).\nrelative phase \\(\\phi\\) \\(tap_n\\) (called: \\(\\phi_n\\)) defined time interval \\(tic_m\\) \\(tap_n\\), divided time interval \\(tic_{m}\\) \\(tic_{m+}\\), multiplied \\(2\\pi\\) represent ratio time intervals \\(radians\\), :\\[\\begin{equation}\n\\phi_n~= ~2\\pi \\left(\\frac{tic_m - tap_n}{tic_m - tic_{m+}}\\right)\n\\tag{2.3}\n\\end{equation}\\]\ntic \\(0.6 s\\), first tap occurs \\(0.64 s\\). tap tic interval \\([0.60,1.20]s\\),\nthus \\(2\\pi[(.6 - .64) / (.6 - 1.2)] = 0.42 [rad]\\).\n(2.3) always get value 0 \\(2\\pi\\).\nobtain value range \\([-\\pi,+\\pi]\\) necessary rotate :\\[\\begin{equation}\n\\hat\\phi_n = [(\\phi_n + \\pi)mod(2\\pi)] -\\pi\n\\tag{2.4}\n\\end{equation}\\]\n\\(\\hat\\phi_n\\) rotated value, \\(mod\\) modulo operation ()modulo(B).\nRotation effect values \\(\\pi\\) go \\(0\\).Accordingly, \\(tap_n\\) occurs half cycle \\(tic_m\\), \\(\\hat\\phi_n\\) positive, indicating delay.\n\\(tap_n\\) occurs half cycle \\(tic_{m+}\\), \\(\\hat\\phi_n\\) negative, indicating anticipation \\(tic_{m+}\\).\nRotating \\(0.42 [rad]\\), \\((.42 + \\pi)\\) modulo \\((2 \\pi)- \\pi\\) get \\(0.42 [rad]\\). case, rotation effect \n’s want. values \\(\\pi\\) get rotated re-appear zero.\nvalue 4[rad], rotation gives -2.28[rad].obtained scale circular scale \\(0\\pi\\) (equal \\(2\\pi\\)) appearing middle interval spanned \\([-\\pi,+\\pi]\\). expresses relative phase cycle marked successive taps. circularity implies values slightly \\(>\\pi\\) can also considered slightly \\(<-\\pi\\).\nrelative phase histogram figure 2.3, peak negative value, meaning , average, taps occur half cycle tic (tics zero). taps anticipating ticks.\nNote histogram distribution looks normal slightly skewed right.","code":""},{"path":"chapModelling.html","id":"polar-representation","chapter":"2 Modelling","heading":"Polar representation","text":"Interestingly, relative phase can represented angle unit length vector polar representation.\nAccordingly, construct vector :\\[\\begin{equation}\nv = e^{(j\\phi)}\n\\tag{2.5}\n\\end{equation}\\]\n\n\\(v\\) unit length vector angle equal relative phase \\(\\phi\\).\n\\(j\\) indicates complex number.Given series relative phases, first turn unit vectors.\nsum unit vectors divide number unit vectors.\nresultant vector \\(V\\) can easily extract polar coordinates, vector length \\(R\\) angle \\(\\alpha\\). ’s .\\[\\begin{equation}\nV = \\frac{1}{N}\\sum_{n=1}^N v_n\\\\\nR = Mod(V)\\\\\n\\alpha = Arg(V)\n\\tag{2.6}\n\\end{equation}\\]\nexample, given relative phases shown table 2.3, first turn unit vectors.\nvectors point several directions along unit circle phases different zero. mean length smaller one.R \\(\\alpha\\) given ","code":"\nV <- (exp(1i *0.38) + exp(1i*0.03) + exp(1i*0.16) + \n        exp(-1i*0.03) + exp(1i*0.06) + exp(-1i*0.13)) /6\nMod(V) ## [1] 0.9871149\nArg(V)## [1] 0.077842"},{"path":"chapModelling.html","id":"synchronization-strength-and-delay","chapter":"2 Modelling","heading":"Synchronization strength and delay","text":"working relative phase, length \\(R\\) can interpreted synchronization strength.\ntap perfectly synchronized tic, \\(R = 1\\).\nangle \\(\\alpha\\) can interpreted synchronization delay.\ntap anticipated, delay, \\(\\alpha = 0 [rad]\\).can now return data table 2.2 shown figure 2.3, right panel.\nTaking data account, synchronization strength \\(R = 0.61\\) synchronization delay \\(\\alpha = -1.68[rad]\\).\nlatter shown right panel figure 2.3 dotted red line.point, analysis stop conclusions drawn subject’s tapping variability.\nnegative mean asynchrony, indicating anticipation tapping.finding confirm theory, tapping proceeds ticking, agreement assumption predictive brain. brain can handle motor prediction asymmetric delay lines (longer) tactile feedback (shorter) auditory feedback compensated tapping earlier, tactile feedback auditory feedback arrive time brain.","code":""},{"path":"chapModelling.html","id":"data-and-model","chapter":"2 Modelling","heading":"2.4 Data and model","text":"course don’t stop .\nfact, fun just starts.\ntapping events can considered indicators continuous hidden process related brain’s prediction time.\nStatistical models can make hidden process visible.","code":""},{"path":"chapModelling.html","id":"circular-axis","chapter":"2 Modelling","heading":"Circular axis","text":"Consider dataset shown table 2.3.\nget interesting graphical representation showing relative phase event time, ilustrated figure 2.4, , time horizontal axis relphase vertical axis.\nfigure shows particular tapping segment 160 175 seconds.\ndashed vertical lines show tics.\ncircles show taps defined relative phase values, depend tap time relative tic time.tics may missing tic selected always first tic tap.\nexample, tap period wider tic period, first tic selected.\nGiven \\(tic_0, tap_1, tic_1, tic_2, tap_2\\), \\(tic_1\\) shown\n\\(tic_0\\) reference \\(tap_1\\) \\(tic_2\\) reference \\(tap_2\\).\nTaps positive relative phase (.e., delayed) fall first half-cycle tic.\nTaps negative relative phase (.e., anticipated) fall first half-cycle next tic.\nFollowing logic, values top figure 2.4,\n163 167 seconds, form actually part U-shaped sequence relative phase values, vertical axis circular.\nFIGURE 2.4: Relative phase values time, using circular vertical axis\n\nFIGURE 2.5: Relative phase values time fitted, using circular model (blue), non-circular model (ocre)\ncomplete tapping sequence shown figure 2.5.\ncontinuous lines smooths generated two different smooth regression models, either taking account circularity response (= blue line), (= ocre line). Smooths fact curves go data optimal fluent way, whose resoluation can define.\nGiven knowledge circularity relative phase, ocre line one just wrong.obtain figure?","code":""},{"path":"chapModelling.html","id":"smooth-regression","chapter":"2 Modelling","heading":"Smooth regression","text":"description smooth regression model based lme4-syntax, used R-packages statistics.\ndefined relation response predictor :\n\n\nformula says relative phase relphase distributed offset (indicated 1) plus smooth time using basis \\(k=30\\) spline-functions.\nrelative phase value \\(\\phi_i\\), occurring particular time \\(t\\), equal offset plus linear combination 30 spline-functions values evaluated \\(t\\), plus residual noise.\nsplines capture correlation among relative phase values time.\nObviously, model come fitted splines \\(\\phi_i\\) .values \\(\\phi_n\\) value circular axis defined interval \\([-\\pi,+\\pi]\\), regression model fitted proper circular link function (family=“von_mises”), predictor gets correctly mapped circular axis response.\nAccordingly, formula brms-package :\n\n\nfamily specified, model assumes relphase non-circular; ’s ocre model.\nnon-circular model (ocre) strongly affected values close \\(\\pi\\).\nconsiders high positive values time-independent mean goes .\ncontrast, circular model (blue) considers points near \\(\\pi\\) circular axis mean lower line estimates.\ntime-independent means shown vertical (blue ocre) lines histogram figure 2.3 (right panel).","code":"\nrelphase ~ 1 + s(time, k=30)\nformula = bf(relphase ~ 1 + s(time, k=30))\nfamily = \"von_mises\""},{"path":"chapModelling.html","id":"uncertainty","chapter":"2 Modelling","heading":"Uncertainty","text":"Figure 2.5 shows predicted mean uncertainty time.\nTaking average time, means -2.03[rad] according circular model -1.09[rad] according non-circular model.\nSince know time tics \\(0.6 s\\), anticipated time \n\\((-2.03 / 2\\pi) 0.6s = -0.194s\\) circular model\nnon-circular model \\(-0.105s\\).\ncircular model uncertainty given critical interval (CI-95%) \\([-2.39,-1.75]\\).\nCI-95% indicates mean appear interval 95% estimations.\nnon-circular model, uncertainty given critical interval (CI-95%) \\([-1.18,-1.00]\\).\nClearly, models uncertainty unresolved parameters regression model.type statistical modelling can called: circular-linear smooth regression.\nname stress fact response circular predictor linear, use smooths.\nSoon, ’ll work circular-linear hierarchical distributional smooth regression.\nDon’t panic, know already circular-linear smooth regression!","code":""},{"path":"chapModelling.html","id":"predictions-of-tapping","chapter":"2 Modelling","heading":"2.5 Predictions of tapping","text":"Given model fitted parameters, can used generate discrete tapping events.\nRecall fitted model gives us estimation continuous hidden process.\ncreate discrete taps make sure relative phase values match time values occur.\n\n\n\nFirst, predict relative phase \\(\\phi^{tap}_n\\) fitted model using sampling rate 100 samples per second.\nthus get predictions relative phase \\(\\phi^{tap}_n\\) time instances\n\\(t_1=0[s], t_2= 0.01[s],...,t_N = 390[s]\\), \\(n\\) index (\\(n=1,2,...,N\\)) samples \\(t_n\\) sample time.First, predict relative phase \\(\\phi^{tap}_n\\) fitted model using sampling rate 100 samples per second.\nthus get predictions relative phase \\(\\phi^{tap}_n\\) time instances\n\\(t_1=0[s], t_2= 0.01[s],...,t_N = 390[s]\\), \\(n\\) index (\\(n=1,2,...,N\\)) samples \\(t_n\\) sample time.Next, calculate generated tap phase \\(\\psi^{tap}_n\\) sum () tic phase \\(\\psi^{tic}_n\\), (ii) relative phase \\(\\phi^{tap}_n\\), (ii) noise \\(\\epsilon_n\\):\n\\[\n\\psi^{tap}_n = \\psi_n^{tic} + \\phi^{tap}_n + 2\\pi\\epsilon_n ~,~\\\\\n\\psi_n^{tic}=\\frac{2\\pi t_n}{0.6},~\\\\\n\\epsilon_n \\sim  N(0,.05).\n\\]\nNote \\(\\psi_n^{tic}\\) phase corresponds time indication given metronome tic \\(tic_n\\).\ndivision \\(0.6\\) guarantees \\(2\\pi\\) (= maximum phase metronome tic) occurs multiples \\(t_n=0.6~[s]\\).\nnoise added predicted relative phase comes normal distribution zero mean 0.05 standard deviation.Next, calculate generated tap phase \\(\\psi^{tap}_n\\) sum () tic phase \\(\\psi^{tic}_n\\), (ii) relative phase \\(\\phi^{tap}_n\\), (ii) noise \\(\\epsilon_n\\):\n\\[\n\\psi^{tap}_n = \\psi_n^{tic} + \\phi^{tap}_n + 2\\pi\\epsilon_n ~,~\\\\\n\\psi_n^{tic}=\\frac{2\\pi t_n}{0.6},~\\\\\n\\epsilon_n \\sim  N(0,.05).\n\\]\nNote \\(\\psi_n^{tic}\\) phase corresponds time indication given metronome tic \\(tic_n\\).\ndivision \\(0.6\\) guarantees \\(2\\pi\\) (= maximum phase metronome tic) occurs multiples \\(t_n=0.6~[s]\\).\nnoise added predicted relative phase comes normal distribution zero mean 0.05 standard deviation.Finally, get discrete tap values \\(\\psi^{tap}_{\\hat n}\\) select samples \\(n\\) \n\\(\\psi^{tap}_n\\) modulo \\(2 \\pi\\) maximum.\nget time value \\(\\psi^{tap}_{\\hat n}\\) occurs:Finally, get discrete tap values \\(\\psi^{tap}_{\\hat n}\\) select samples \\(n\\) \n\\(\\psi^{tap}_n\\) modulo \\(2 \\pi\\) maximum.\nget time value \\(\\psi^{tap}_{\\hat n}\\) occurs:\\[\n\\psi^{tap}_{\\hat n} = max(mod(\\psi^{tap}_{n},2\\pi))\\\\\nt^{tap}_{\\hat n}  = \\frac{0.6 \\psi^{tap}_{\\hat n}  }{2\\pi}\n\\]\n\\(\\psi^{tap}_{\\hat n}\\) selected tap phase \\(2 \\pi\\) value, close value, depending sampling rate, \\(t^{tap}_{\\hat n}\\) time tap \\(\\hat n\\).\nR code calculating predictions found Code/chapModelling/chapModelling_05_ModelPlotting.R.\nFIGURE 2.6: Simulated discrete taps, using underlying process, shown first 100 seconds\nhidden process generated taps first 100 seconds shown figure 2.6.\nObviously, generated taps exactly similar original taps. However, similar statistical structure.sum , used fitted model give us -called counterfactual predictions equal time intervals.\ncounterfactual prediction often needed.\nstraightforward get .","code":""},{"path":"chapModelling.html","id":"note-about-bayesian-statistics","chapter":"2 Modelling","heading":"2.6 Note about Bayesian statistics","text":"Bayesian approach statistics many advantages, also disadvantages.\nAmong advantages flexibility working fitted model. fitted, kinds combinations parameters counterfactuals can investigated drawing samples model’s posterior.disadvantage time takes compute fitted model.\nmentioned illustrated drawing figure 2.1, estimation process Bayesian data modelling revolves around optimizing likelihood function, , probability observing data given parameters model. goal find values parameters maximize likelihood function, thereby providing best fit observed data. optimization can viewed Bayesian perspective, goal find posterior distribution parameters given data prior beliefs.One powerful technique used Bayesian optimization Hamiltonian Monte Carlo (HMC) sampling. HMC combines principles Hamiltonian dynamics Monte Carlo sampling explore parameter space efficiently traditional optimization methods16. However, computational cost considerable.","code":""},{"path":"chapModelling.html","id":"conclusion-1","chapter":"2 Modelling","heading":"2.7 Conclusion","text":"chapter introduced smooth regression applied simple dataset tic tap events, showing timing delicate matter.\naddition showed , based estimated parameters regression model, possible generate counterfactual tap events.\napproach offers many possibilities explored next chapters.","code":""},{"path":"chapListener.html","id":"chapListener","chapter":"3 Listener","heading":"3 Listener","text":"chapter17, delve question music people.\nchapter based theory music appreciation, used developing questionnaire survey, well developing statistical model. modelling aims connecting theory data via refinement , possibly, updated theory. Ultimately, goal theory people reflect music people. sense, viewpoint static, akin reflection self-augmented interactions interaction completed.chapter depends following scripts data preparation, plotting, modelling model plotting:","code":"\nsource(\"Code/chapAll_00_Initialization.R\")\nsource(\"Code/chapAll_01_Functions.R\")\nsource(\"Code/chapListener/chapListener_02_DataPreparation.R\")\nsource(\"Code/chapListener/chapListener_03_DataPlotting.R\")\nsource(\"Code/chapListener/chapListener_04_Modelling.R\")\nsource(\"Code/chapListener/chapListener_05_ModelPlotting.R\")"},{"path":"chapListener.html","id":"workflow","chapter":"3 Listener","heading":"3.1 Workflow","text":"theory-driven modelling applies Bayesian epistemology outlined figure 2.1. subject listener, interacts music sonic moving form. chapter, probe listener questions appreciation motivation.\nanswers indicators listener’s appreciation.fully grasp stucture chapter, instructive consider workflow figure 3.1, also applies Bayesian epistemology.\nFIGURE 3.1: Overview theory statistical modelling\nstarting point theory music appreciation.\nBased theory, questionnaire statistical model generated.\nquestionnaire launched survey, answers questionnaire, data, processed transmitted statistical model.\nstatistical modelling serves feedback theory.follows, hook wagon acceptable stage iteration, ’ll try refine results obtained.","code":""},{"path":"chapListener.html","id":"theory","chapter":"3 Listener","heading":"3.2 Theory","text":"approach draws fields neurobiology, marketing, musicology. framework enables us conceptualize music appreciation rating assigned listeners gratification experience engaging music.Neurobiology suggests gratification reward arises brain’s release dopamine, neurotransmitter diffuses throughout brain, eliciting pleasurable sensation triggering desire —- behavioral pattern akin seeking stimuli induce reward, reminiscent addiction.Neurobiology suggests gratification reward arises brain’s release dopamine, neurotransmitter diffuses throughout brain, eliciting pleasurable sensation triggering desire —- behavioral pattern akin seeking stimuli induce reward, reminiscent addiction.realm marketing, concept wanting linked perceived value product, reflects overall appreciation indicative customer satisfaction regarding product’s functionalities qualities. qualities can assessed series questionnaires designed probe various aspects.realm marketing, concept wanting linked perceived value product, reflects overall appreciation indicative customer satisfaction regarding product’s functionalities qualities. qualities can assessed series questionnaires designed probe various aspects.Finally, domain musicology, proposed music profoundly influences listener’s experience, can analyzed terms embodiment, anticipation, expression – discussed chapter 1.Finally, domain musicology, proposed music profoundly influences listener’s experience, can analyzed terms embodiment, anticipation, expression – discussed chapter 1.Combining insights neurobiology, marketing, musicology, theory music appreciation can outlined follows:\nlistener engages music, dynamic anticipation-reward-motivation loop initiated, leading experiences emotionally moved, deeply absorbed, profoundly touched, listener can subsequently reflect upon. experiences often culminate pleasurable bodily reward, positively evaluated.\nUpon reflection, listener may discern specific qualities music contributed pleasurable experiences.Indeed, comprehensive theory music appreciation must also consider influence context. Factors setting music heard (e.g., live concert versus radio broadcast), listener’s mood, demographic background, environmental variables can significantly impact listeners perceive interpret musical experiences. Therefore, conducting surveys assessments, essential account contextual factors ensure clarity accuracy participants’ responses, thus avoiding potential confusion misinterpretation.’s important note concept appreciation remains independent specific type music listened . example, even sad music can evoke high appreciation scores despite melancholic nature, may trigger intense embodied experiences highly valued listeners. Conversely, happy music may always receive high appreciation fails engage listener compelling rhythm groove.Furthermore, theory appreciation agnostic factors gender age. truly matters activation reward, pleasure, wanting experiences music. Global appreciation reflects inward reflection, focusing nature evaluation experience , outward reflection, directed towards quality music. reflections influenced various contextual factors background, gender, setting.","code":""},{"path":"chapListener.html","id":"causal-model","chapter":"3 Listener","heading":"3.3 Causal model","text":"theory can clarified network variables relationships variables.","code":""},{"path":"chapListener.html","id":"directed-acyclic-graph-dag","chapter":"3 Listener","heading":"Directed acyclic graph (DAG)","text":"\nFIGURE 3.2: Causal model appreciation\nFigure 3.2 shows directed acyclic graph (DAG) theory defined network variables causal relationships. Note use term causal specific meaning context. cause-effect relationship among two variables means () information flow direction, sense cause precedes effect time, (ii) association (correlation) variables, (iii) potential confounding variables account observed association. latter can tested considering logic relations (see ).DAG, Kind_of_Experience affected musical qualities, variables exposed variable, Global_Appreciation outcome.\nrationale musical qualities (Quality) affect listener, causing experiences listener (Kind_of_Experience), including instance, increase dopamine level generating pleasurable feelings wanting urge.\nexperiences set scene assessment (Evaluation), cause scoring Global_Appreciation.aware ellipses marked X associated questions.\nincoming arrow answers questions generated latent variables.Additionally, ’s important note Quality determinant Kind_of_Experience. Essentially, Quality represents musical attributes identified participant contributing type experience .","code":""},{"path":"chapListener.html","id":"confounding-variables","chapter":"3 Listener","heading":"Confounding variables","text":"causal direction plausible association clear concepts, might require careful logical reasoning order prevent confounding variables network.\nFortunately, DAG can tested using tool Daggity. involves evaluating whether assumed causal structure consistent, , whether certain sets variables conditionally independent given sets variables, predicted DAG. lucky, DAG safe. adjustment necessary estimate total effect Kind_of_experience Global_Appreciation, meaning confounding paths variable Kind_of_experience outcome variable Global_Appreciation.can test different interpretations model, example, drawing arrow Kind_of_experience Quality, assuming Kind_of_experience cause quality recognized music.\nHowever, one careful possible open biasing paths, confounding variable bias estimation causal effect Kind_of_experience Global_Appreciation.","code":""},{"path":"chapListener.html","id":"questionnaire","chapter":"3 Listener","heading":"3.4 Questionnaire","text":"Based DAG music appreciation, possible define questions allow us measure variables:Global_appreciation estimated single question, scored scale 1 10. reflects eager listener want music.Global_appreciation estimated single question, scored scale 1 10. reflects eager listener want music.Quality based six yes/questions probe different aspects musical quality, “music qualities like (Y/N)”. assessment quality subjective assessment music, influenced kind experience.Quality based six yes/questions probe different aspects musical quality, “music qualities like (Y/N)”. assessment quality subjective assessment music, influenced kind experience.Evaluation based questions probe value experience, “touched positive sense” “enjoyed experience,” rated scales 1 5.\nassessment influenced kind experience , listener.Evaluation based questions probe value experience, “touched positive sense” “enjoyed experience,” rated scales 1 5.\nassessment influenced kind experience , listener.Kind_of_experience based questions addressing three subcategories immersive, embodied, emotional experiences, “absorbed music,” “moved along music,” “experienced emotions”. questions probe kind experience generated music.Kind_of_experience based questions addressing three subcategories immersive, embodied, emotional experiences, “absorbed music,” “moved along music,” “experienced emotions”. questions probe kind experience generated music.additional questions demography listener’s age, gender, education.\nFinally, two questions arousal valence effects music. particular:\n“music, heard energy, excitement” (rated scale 1 5).\n“music, heard joy, optimism, positive emotions” (rated scale 1 5).utilizing questionnaire, researchers can effectively gather data understand analyze components music appreciation outlined theory.follows, don’t go questionnaire’s specific questions.\nUnsless specified otherwise, use question labels Q1, Q2 …, focus mainly questions structured, pointed figure 3.2.","code":""},{"path":"chapListener.html","id":"survey","chapter":"3 Listener","heading":"3.5 Survey","text":"Using questionnaire, survey conducted collaboration Flemish Radio classical music, VRT-Klara. edition Klara-Top100 2023, listeners invited participate survey, using redirect survey platform (Qualtrix). Approximately 1200 listeners responded survey 800 listeners completed entire questionnaire.questionnaire consisted two parts. first part investigated factors contributing high appreciation, coded Liking Q57, second part, using identical questions, explored factors contributing low appreciation, coded Disliking Q57. Overall, questionnaire comprised 66 questions.\ncurrent analysis, questions score-based responses included, open-ended questions requiring verbal descriptions (e.g. quality, kind experience, evaluation) excluded. dataset used analysis sourced Jacobs et al. (preparation).","code":""},{"path":"chapListener.html","id":"inspect-the-data","chapter":"3 Listener","heading":"3.6 Inspect the data","text":"Exploration data via plotting always useful.","code":""},{"path":"chapListener.html","id":"appreciation","chapter":"3 Listener","heading":"Appreciation","text":"show global appreciation (labelled dataset : Q1) scale 1 10, per category Liking Disliking.\nhighest appreciated music gets mean 9.42, standard deviation 0.88.\nlowest appreciated music gets mean 2.89 standard deviation 1.66.\nApparently, highest appreciated music somewhat better defined lowest appreciated music , case still gets overall appreciation 5/10 rare cases even 6/10.\nFIGURE 3.3: Distribution scorings global appreciation (Q1) music qualified Liking Disliking (Q57), mean standard deviation indicated.\n","code":""},{"path":"chapListener.html","id":"participants","chapter":"3 Listener","heading":"Participants","text":"quick view participants shows striking facts. 43% 61-70 years old 17% younger 50 years old. twice many females compared men. majority low level music education. main interaction music listening, playing.\nprofile might representative classical music radio.\nFIGURE 3.4: info listeners\n","code":""},{"path":"chapListener.html","id":"affect-attribution","chapter":"3 Listener","heading":"Affect attribution","text":"listeners’ attribution arousal valence probed Likert scale 1 5.\nscores can interpreted coordinates -called circumplex model affect, shown figure 3.5.\nuse identify four different attributed affect categories music.High-arousal high-valence defined happyHigh-arousal high-valence defined happyhigh-arousal low-valence defined aggressivehigh-arousal low-valence defined aggressivelow-arousal high-valence defined relaxinglow-arousal high-valence defined relaxinglow-arousal low-valence defined sad.low-arousal low-valence defined sad.horizontal vertical band middle show neutral zone listeners gave score 3 either question.\nInterestingly, relaxing music liked lot, aggressive music mostly disliked, although sometimes liked.\nLikewise, happy music mostly liked, sometimes disliked.\nsad music, seems, often disliked, often also liked.\nFIGURE 3.5: Liked disliked music categorized arousal valence 5-point scale. Jitter used show distributions\nOverall, seems quite structure dataset.\nCronbach’s alpha gives value 0.84, considered good excellent, meaning internal consistency dataset high. mean value correlations among subjects 0.54.\ncan said data restrict minimum needed modelling.\nTABLE 3.1: Cronbach alpha mean\n","code":""},{"path":"chapListener.html","id":"preparing-analysis","chapter":"3 Listener","heading":"3.7 Preparing analysis","text":"steps follow can seen preparatory work statistical modelling.\nrationale view main question global appreciation (Q1), possible \nidentify questions low correlation Q1.\nquestions anyhow really affect Q1.start , consider figure 3.6.\nleft panel shows correlation among questions.\nFIGURE 3.6: Correlation matrices. (left) original, (right) pruned\ncheck contributes Q1, may suffice look first vertical column (Q1 label).\nimportant questions high correlation values.\nQuestions correlation value less \\(.5\\) can deleted – , , set zero.\nleftovers shown right panel.\n: Q2, Q31, Q33, Q35, Q37, Q39, Q41, Q43, Q47, Q48, Q49, Quality:Quality weighted sum six yes/questions18.\nFigure 3.7 suggest Quality indeed correlated Q1.\nFIGURE 3.7: Quality versus product value, coded Q1 (jitter added), fitted straight line smoothing curve\nIndicators latent variable Kind_of_experience :\nQ31, Q33 Q35, probe listeners’ immersive experience terms attention , absorption engagement music.\nQ37, Q39, Q41, probe listeners’ embodied experiences terms moving, participating, physical sensation.\nQ43, probing listeners’ emotional experience.\nQ2, probing listeners’ connection music.\nIndicators latent variable Kind_of_experience :Q31, Q33 Q35, probe listeners’ immersive experience terms attention , absorption engagement music.Q31, Q33 Q35, probe listeners’ immersive experience terms attention , absorption engagement music.Q37, Q39, Q41, probe listeners’ embodied experiences terms moving, participating, physical sensation.Q37, Q39, Q41, probe listeners’ embodied experiences terms moving, participating, physical sensation.Q43, probing listeners’ emotional experience.Q43, probing listeners’ emotional experience.Q2, probing listeners’ connection music.Q2, probing listeners’ connection music.Finally, Q47, Q48, Q49 probe whether listeners’ evaluation experience terms enjoying music, whether touched annoyed music. questions indicators latent variable Evaluation.Finally, Q47, Q48, Q49 probe whether listeners’ evaluation experience terms enjoying music, whether touched annoyed music. questions indicators latent variable Evaluation.short, based simple correlation threshold, pruned version questionnaire obtained.\nquestions pass threshold, leftovers candidates model.","code":""},{"path":"chapListener.html","id":"structural-equation-modelling","chapter":"3 Listener","heading":"3.8 Structural equation modelling","text":"structural equation model (SEM) implements structure shown figure 3.2. use question labels used questionnaire.\nSEM estimates strength significance association variables.\n, can assess fit model observed data, evaluate overall model’s explanatory power.","code":""},{"path":"chapListener.html","id":"model","chapter":"3 Listener","heading":"Model","text":"SEM follows syntax R-package lavaan.\noperator =~ defines confirmatory factor analysis, used created latent variable.\nexample, Evaluation constructed Q47, Q48 Q49.\nSimilarly, Immerson, Embodiment Emotion latent variables, define Kind_of_experience.\noperator ~ defines regression, used relate response variable predictor variables.\nQuality (indicator) link Kind_of_experience Kind_of_experience Evaluation.\n, Evaluation Q2 predictors Q1, called Global_appreciation DAG figure 3.2.","code":"\n  model_1 <- '\nEvaluation =~ Q47 + Q48  + Q49\nImmersion =~ Q33 + Q35 + Q31 \nEmbodiment =~ Q37 + Q39 + Q41\nEmotion =~ Q43\nKind_of_experience =~ Immersion + Embodiment + Emotion\nKind_of_experience ~ Quality \nEvaluation ~ Kind_of_experience\nQ1 ~ Evaluation + Q2'"},{"path":"chapListener.html","id":"covariance-matrix","chapter":"3 Listener","heading":"Covariance matrix","text":"Mathematically speaking, SEM fits covariance matrix \\(\\Sigma(\\theta)\\) model, covariance matrix \\(\\Sigma\\) data. optimal fitting:\n\\[\n\\Sigma = \\Sigma(\\theta),\n\\]\n\\(\\theta\\) parameters model.pruned questionnaire contains 12 questions 800 respondents answered questions. gives us 12x12 covariance matrix questions (\\(\\Sigma\\)), 12x12 covariance matrix questions embedded model parameters, \\(\\Sigma(\\theta)\\).\n, \\(\\Sigma(\\theta)\\) optimized approach \\(\\Sigma\\).\noptimization successful, obtained insight data viewpoint theory music appreciation.Thus, rather just putting data unrelated box, theory suggests data structured.\ndata come measurements using questions relate theory.\nHence, can tested theory justified data.","code":""},{"path":"chapListener.html","id":"cfa-and-regression","chapter":"3 Listener","heading":"CFA and regression","text":"Let us just recall just said.\nStructure among variables, specified DAG, defined confirmatory factor analysis (CFA) regression.\nCFA generates new latent variable weighted sum variables.\nexample, latent variable Immersion generated indicators Q33, Q35, Q31.\nregression associates given variable weighted sum given variables.\nexample, Q1 (response) associated Evaluation Q2 (predictors).\nRecall Quality really latent variable anymore model obtained combining yes/questions pre-processing stage. contrast, Kind_of_experience Evaluation can considered genuine latent variables.","code":""},{"path":"chapListener.html","id":"dataset-and-sem","chapter":"3 Listener","heading":"3.9 Dataset and SEM","text":"Let’s now fit SEM data. Recall goal fitting see whether indeed structure data, defined model.Lavaan lot bells whistles limit simple fitting use Q57 divide database two parts, based Liking Disliking.\ntwo parts database reflect fact listeners filled questionnaire twice. First preferred music, piece like.\nfitting models, obtain weights parameters associate variables.\nHowever, whether fitted model acceptable depends tests check discrepancy \\(\\Sigma\\) \\(\\Sigma(\\theta)\\).","code":"\nsemfit1 <- lavaan::sem(model_1, data = Data, \n                       group = \"Q57\",  meanstructure = TRUE)"},{"path":"chapListener.html","id":"measurement-invariance","chapter":"3 Listener","heading":"Measurement invariance","text":"use technique called called measurement invariance check consistency across different groups conditions simply comparing fit several nested models impose increasingly restrictive constraints parameters measurement model across groups. measurement invariance established, differences observed scores groups may due measurement bias rather true differences underlying construct. summary measurmement invariance.Comparing results different models (semfit1, semfit2, semfit3), can see following trends:Chi-square: models significant chi-square values (p < .05), indicating models perfectly fit data. However, often case large sample sizes, even minor deviations model can lead significant chi-square values.Chi-square: models significant chi-square values (p < .05), indicating models perfectly fit data. However, often case large sample sizes, even minor deviations model can lead significant chi-square values.RMSEA: models RMSEA values around .089-.095, within acceptable range (typically .08 good fit), indicating reasonable fit.RMSEA: models RMSEA values around .089-.095, within acceptable range (typically .08 good fit), indicating reasonable fit.CFI TLI: models CFI values around .81-.85 TLI values around .79-.81, suggesting reasonable fit.CFI TLI: models CFI values around .81-.85 TLI values around .79-.81, suggesting reasonable fit.SRMR: Model semfit1 lowest SRMR (.083), indicating better fit terms standardized root mean square residual.SRMR: Model semfit1 lowest SRMR (.083), indicating better fit terms standardized root mean square residual.AIC BIC: Model semfit1 lowest AIC value among three models, indicating better parsimony.AIC BIC: Model semfit1 lowest AIC value among three models, indicating better parsimony.Based results, conclusion might model semfit1 provides best overall fit data among three models tested. However, given minor differences among three models, measurement invariance can assumed.","code":"## ####################### Model Fit Indices ###########################\n##             chisq  df pvalue rmsea   cfi   tli  srmr        aic        bic\n## semfit1  902.093† 122   .000 .089  .849† .810  .083† 40633.042† 41042.366 \n## semfit2  956.857  130   .000 .089† .840  .811† .085  40671.807  41038.044†\n## semfit3 1125.185  136   .000 .095  .809  .783  .093  40828.134  41162.057"},{"path":"chapListener.html","id":"parameters","chapter":"3 Listener","heading":"Parameters","text":"inspect estimated parameters latent variables regression:\nlatent variables, except Q2, fit well.\ncan seen P(>|z|) Std.columns.\nlooking regression see Q2 doesn’t play role specification Q1.far second part dataset concerned, latent variables fit well.\n, Q2 doesn’t contribute much global result.Overall, model suggests Evaluation relevant predictor Q1.\nMoreover, Evaluation predicted Kind_of_experience \nImmersion strongest contributor Liking Disliking groups.Liking group, Emotion contributes Embodiment, Disliking, Embodiment contributes Emotion.\nQuality less impact Liking group, compared Disliking group.Overall, Liking group Immersion Emotion strong predictors, Disliking group, Immersion Embodiment Quality strong. like music, subjects emotionally touched. dislike music, subjects seem overall less emotionally touched. refer consistently quality music source disliking.","code":"\ns <- summary(semfit1, standardized = TRUE, rsquare = TRUE, ci = T)\nreg <- '\nGroup 1 [Liking]:\n\nLatent Variables:\n                        Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper   Std.lv  Std.all\n  Evaluation =~                                                                                \n    Q47                    1.000                               1.000    1.000    0.315    0.674\n    Q48                    0.848    0.114    7.422    0.000    0.624    1.072    0.267    0.383\n    Q49                   -0.368    0.054   -6.756    0.000   -0.474   -0.261   -0.116   -0.337\n  Immersion =~                                                                                 \n    Q33                    1.000                               1.000    1.000    0.671    0.783\n    Q35                    0.702    0.050   13.968    0.000    0.604    0.801    0.471    0.600\n    Q31                    0.856    0.058   14.747    0.000    0.742    0.969    0.574    0.649\n  Embodiment =~                                                                                \n    Q37                    1.000                               1.000    1.000    0.896    0.727\n    Q39                    0.957    0.104    9.205    0.000    0.753    1.161    0.857    0.672\n    Q41                    0.408    0.052    7.860    0.000    0.306    0.509    0.365    0.381\n  Emotion =~                                                                                   \n    Q43                    1.000                               1.000    1.000    0.681    1.000\n  Kind_of_experience =~                                                                        \n    Immersion              1.000                               1.000    1.000    0.870    0.870\n    Embodiment             0.602    0.094    6.412    0.000    0.418    0.786    0.393    0.393\n    Emotion                0.688    0.075    9.156    0.000    0.540    0.835    0.589    0.589\n\nRegressions:\n                       Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper   Std.lv  Std.all\n  Evaluation ~                                                                                \n    Kind_of_exprnc        0.322    0.040    8.028    0.000    0.244    0.401    0.597    0.597\n  Kind_of_experience ~                                                                        \n    Quality               0.089    0.027    3.300    0.001    0.036    0.142    0.152    0.141\n  Q1 ~                                                                                        \n    Evaluation            1.382    0.160    8.630    0.000    1.068    1.696    0.435    0.497\n    Q2                   -0.015    0.046   -0.318    0.750   -0.105    0.075   -0.015   -0.010\n'\n # summary(semfit1, standardized = TRUE, rsquare = TRUE, ci = T)\nreg <- '\nGroup 2 [Disliking]:\n\nLatent Variables:\n                        Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper   Std.lv  Std.all\n  Evaluation =~                                                                                \n    Q47                    1.000                               1.000    1.000    0.568    0.787\n    Q48                    0.988    0.049   20.044    0.000    0.892    1.085    0.561    0.761\n    Q49                   -0.742    0.067  -11.033    0.000   -0.874   -0.610   -0.421   -0.420\n  Immersion =~                                                                                 \n    Q33                    1.000                               1.000    1.000    0.617    0.837\n    Q35                    1.027    0.040   25.803    0.000    0.949    1.105    0.633    0.854\n    Q31                    0.775    0.059   13.041    0.000    0.659    0.892    0.478    0.467\n  Embodiment =~                                                                                \n    Q37                    1.000                               1.000    1.000    0.766    0.901\n    Q39                    0.904    0.044   20.712    0.000    0.818    0.989    0.692    0.800\n    Q41                    0.413    0.059    6.989    0.000    0.298    0.529    0.317    0.261\n  Emotion =~                                                                                   \n    Q43                    1.000                               1.000    1.000    1.287    1.000\n  Kind_of_experience =~                                                                        \n    Immersion              1.000                               1.000    1.000    0.940    0.940\n    Embodiment             0.917    0.058   15.852    0.000    0.804    1.031    0.694    0.694\n    Emotion                0.664    0.086    7.766    0.000    0.497    0.832    0.299    0.299\n\nRegressions:\n                       Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper   Std.lv  Std.all\n  Evaluation ~                                                                                \n    Kind_of_exprnc        0.840    0.051   16.573    0.000    0.740    0.939    0.857    0.857\n  Kind_of_experience ~                                                                        \n    Quality               0.205    0.017   12.108    0.000    0.172    0.238    0.354    0.453\n  Q1 ~                                                                                        \n    Evaluation            1.517    0.109   13.914    0.000    1.303    1.731    0.861    0.523\n    Q2                   -0.142    0.044   -3.190    0.001   -0.229   -0.055   -0.142   -0.098\n'"},{"path":"chapListener.html","id":"predictions","chapter":"3 Listener","heading":"3.10 Predictions","text":"following sections, show model can used predictions.","code":""},{"path":"chapListener.html","id":"j.s.-bach","chapter":"3 Listener","heading":"J.S. Bach","text":"first example, ’ll predict listeners’ overall appreciation (Q1) Bach pieces.\nCan predict Q1 Bach pieces, given SEM trained dataset Bach pieces included?\ncan happen SEM captures necessary information pieces, can predict Q1 new pieces using indicators Q47, Q48, Q33, Q35, Q31 Quality. words, SEM generalize input Q1 applies Bach.figure , distinction made training-data test-data.\ntraining-data contain data except answers 157 listeners said something Bach.\ntest-data contain Bach pieces.\n, SEM trained training-data, predictions regenerated.\nTABLE 3.2: Prediction Bach pieces, versus original data\nFigure 3.8 shows prediction Bach appreciation Q1_prediction original Bach appreciation data Q1_data (cor =.95).\nFIGURE 3.8: Prediction global appreciation Bach pieces\nmodel gives accurate prediction global appreciation Bach’s pieces.\nApparently, Bach’s pieces always liked.\ndepth analysis needed figure whether depends particular music pieces.","code":""},{"path":"chapListener.html","id":"attributed-affects","chapter":"3 Listener","heading":"Attributed affects","text":"second example, look latent variables viewpoint sad, relaxing, aggressive happy music.\ncategories introduced figure 3.5.\nprediction, figure 3.9 created.\nshows distribution 50 dots per latent variable latent variables scaled -2 2.\ndistributions reflect latent variable contributes Q1 sad, relaxing, aggressive happy music.\nEvaluation Experience display similar distributions, meaning appraisal experiences depends whether experiences high degree immersion.figure reveals distribution relaxing, aggressive, happy tends towards unipolar scoring, 96%, 82% 78% counted dots one side Evaluation. scoring agreement valence.\nHigh valence (relaxing happy) get high scores, low valence (aggressive) gets low scores.\nHowever, distribution sad tends bi-polar balance 62% negative evaluation.\nmeans 38% listeners, decisive opinion arousal-valence questions, attributed high Evaluation sad music thus high overall appreciation (Q1) strongly correlated.\nFIGURE 3.9: Latent variables SEM modelling distributions category happy, aggressive, relaxing, sad, attributed listeners\n","code":""},{"path":"chapListener.html","id":"discussion","chapter":"3 Listener","heading":"3.11 Discussion","text":"Overall, model supports theory music appreciation.\nMusic appreciation rest mainly evaluation pleasurable experiences \nattribution quality plays role depending whether music liked disliked.main findings :listener likes music, quality scores low, compared situation listener dislikes music. can explained fact listener anticipated certain qualities music. liked music, qualities agree anticipation therefore, role less prominent qualities agree anticipation. State otherwise, people dislike music, attributed musical qualities, anticipation.listener likes music, quality scores low, compared situation listener dislikes music. can explained fact listener anticipated certain qualities music. liked music, qualities agree anticipation therefore, role less prominent qualities agree anticipation. State otherwise, people dislike music, attributed musical qualities, anticipation.causes appreciation experiences. Immersion appears important consistent predictor, embodiment emotion different roles depending whether music liked . somewhat surprising literature puts quite lot emphasis emotion. show experience unity absorption consistent strong predictors, compared felt emotions.causes appreciation experiences. Immersion appears important consistent predictor, embodiment emotion different roles depending whether music liked . somewhat surprising literature puts quite lot emphasis emotion. show experience unity absorption consistent strong predictors, compared felt emotions.connection quality experience/evaluation may intricate.\nlistener may find music high quality, example due composition, performance, , music doesn’t appeal pleasant feeling played radio. Probably, get low rating appreciation.Interestingly, dataset don’t examples dis-accordance attributed quality experience/evaluation.\nmay due fact listeners asked give example music dislike hearing radio, finding rationale disliking.listeners asked select piece high quality, rationalize whether piece pleased hearing radio, situation might different.\nreason somebody doesn’t like hear music radio may due intrinsic musical qualities, context. aspect probably needs clarification follow-studies.Finally, happens listeners hear music repeatedly? Can still experience reward anticipation-reward-motivation mechanism becomes saturated? theory suggests affirmative answer.\nListeners may become entrained music. Similar locomotive pulling wagons, music propels listener point reward can consistently experienced. crux lies dynamic binding structure, known sonic moving forms ability dynamically shape anticipation melodic line, harmonic progression, rhythmic flow, tension, resolution. entrained music, embodied experiences anticipative. feeling potent, fostering sense control rewarding , thus, pleasurable (see illusion reversed causality explained chapter 1).","code":""},{"path":"chapListener.html","id":"conclusion-2","chapter":"3 Listener","heading":"3.12 Conclusion","text":"chapter, probed listeners reflect music . Using questionnaire, refined theory music appreciation. Based neurobiology, marketing musicology, causal model tested structural equation modelling approach using data questionnaire.model suggests music can cause experiences listeners immersion important experience contributing appreciation.\nCan linked dynamic concept self-augmented interactions?\nlatter indeed suggests experiences occur interaction music, rather interaction music.\n’s likely immersion fits dynamic idea challenge can measured.\nAnyhow, chapters follow, focus less experiences look music interactions viewpoint timing.\nMoreover, put emphasis encoders (dancers, musicians) decoders (listeners).","code":""},{"path":"chapDancer.html","id":"chapDancer","chapter":"4 Dancer","heading":"4 Dancer","text":"chapter look music dancers classical ballet, assuming roles prescribed narrative.\nmusic constant given audio track \nshow repeats musical structure, repeats musical fragments phrases within fragments, somehow influence micro-timing dancing without aware influence.code can found following scripts data preparation plotting, modelling plotting, contrast analysis plotting:","code":"\nsource(\"Code/chapAll_00_Initialization.R\")\nsource(\"Code/chapAll_01_Functions.R\")\nsource(\"Code/chapDancer/chapDancer_02_DataPreparation.R\")\nsource(\"Code/chapDancer/chapDancer_03_DataPlotting.R\")\nsource(\"Code/chapDancer/chapDancer_04_Modelling.R\")\nsource(\"Code/chapDancer/chapDancer_05_ModelPlotting.R\")\nsource(\"Code/chapDancer/chapDancer_06_Contrasts.R\")"},{"path":"chapDancer.html","id":"theory-1","chapter":"4 Dancer","heading":"4.1 Theory","text":"dance solo Swan Lake (1875–76) Pyotr Ilyich Tchaikovsky taken example study micro-timing. dance forms part narrative Princess Odette’s metamorphosis swan, orchestrated malevolent sorcerer. Accordingly, dancers articulate swan personas movements unfold precise swan-like alignment musical cadence. dance solo known Odile variation recorded, forming starting point studying effect phrase repeats micro-timing dance-music synchronizations. data analysed Tabeli et al. (2023).synchronization body movement musical beat sensory-motor process, guided brain predictions timing. micro-timing level, measured milliseconds centiseconds, synchronization primarily automated, although skilled performers can exert top-influence. instance, experienced jazz musicians can intentionally play laid-back -beat, affecting micro-timing introducing varying levels anticipation synchronization fellow musicians. Given context, focus whether micro-timing can independently influenced mere repetition musical structure, devoid intentional even vaguely intentional acts.mechanisms underlying potential influence micro-timing likely associated memory, anticipation, expression. Repetition choreographic sequences intricately linked memory anticipation/prediction frameworks. theory states training, movement sequences become stored motor memory. Accordingly, cognitive effort required activation performance reduced. However, precise dynamics interaction retrieval high-level (cognitive) sequences execution low-level (sensory-motor) synchronized micro-timing may hinge effectiveness established prediction model.work hypothesis sequence establishes timing model dancer. sequence repeated shortly , established timing model facilitates timing sequence, translates subtle increase anticipation. likely dancer intuitively uses effect expressive element drive create tension. line theory self-augmented music interaction, dancing along music create illusion agency, dancing causes music. illusion may generate arousal turns affects dancing, thus providing ingredients expressivity context self-augmentation.timing can interpreted Bayesian perspective. establishment timing model can understood prior affecting likelihood synchronized events occur time. prior can adapted view past experiences future anticipations, repeated phrases, expression arcs propulse future. outcome likely reflected relative phase, , time difference musical event movement event, probably due intuitions artistic expression rooted.statistical modelling point view, challenge check whether repeated music-dance fragments, repeated phrases within fragments, show differences micro-timing.\nsuitable music-dance representation needed, using events extracted music dance. , suitable statistical model music-dance events developed, phrases can contrasted terms sychronization differences.","code":""},{"path":"chapDancer.html","id":"experiment","chapter":"4 Dancer","heading":"4.2 Experiment","text":"dataset contains recordings 3 ballerinas performing Odile variation, masterpiece female classical ballet occurs Act III Swan Lake ballet. analysis applied dance figure within variation, known Promenade Arabesque. dance figure, dancer performs promenade (turn walk) holding arabesque position. uses turnout motion standing foot leg rotate position solid posture, see figure 4.1 performance19.\nFIGURE 4.1: Arabesque figure ASIL, art science lab UGent\nOdile variation, Promenade Arabesque occurs twice, dance fragments called F1 F2. shown figures 4.2 4.3, fragment repeated phrase. F1 phrase structure form ,B,,B F2 ,B,,C’, C phrase leading different part piece.\nDancers requested perform 12 times Promenade Arabesque isolated figure (.F1), followed entire Odile variation isolation F1 F2 embedded.Note repeats occur, level fragments level phrases within fragments. Moreover, dancers requested perform task 12 times.repeated measures design thus implies 12 trials entire task might interest check whether trials generate additional effect measurement, example, due fatigue.\n12 trials, exclude trial 5 trial 8 trials entailed manipulation relevant present study.\nFIGURE 4.2: Fragment F1\n\nFIGURE 4.3: Fragment F2\n","code":""},{"path":"chapDancer.html","id":"hypotheses","chapter":"4 Dancer","heading":"4.3 Hypotheses","text":"statistical modelling aim figuring whether () fragments different, (ii) phrases within fragments different,\nwhether (iii) bias trials due repeated measures.\nquestions may formulated hypotheses expectations based theoretical considerations:hypothesis 1: fragments different, assume prediction model influence micro-timing, allowing anticipationhypothesis 1: fragments different, assume prediction model influence micro-timing, allowing anticipationhypothesis 2: phrases within fragments different, assume prediction model influence micro-timing allowing anticipationhypothesis 2: phrases within fragments different, assume prediction model influence micro-timing allowing anticipationhypothesis 3: trails show bias towards less anticipation due fatiguehypothesis 3: trails show bias towards less anticipation due fatigue","code":""},{"path":"chapDancer.html","id":"data","chapter":"4 Dancer","heading":"4.4 Data","text":"Given focus timing, performance can reduced time events occur.\nmusical event beat-onset , study, measured manually experts.dance event either heel_up heel_down event. heel_up event occurs vertical displacement heel maximal, heel_down event occurs vertical displacement heel minimal, touching ground. Heel movement measured motion caption system using infra-red reflexive markers allow accurate measurement position millimeters time milliseconds. Given 3-dimensional motion caption signal heel, vertical dimension suffices extract time maximum minimum values occur. time indications heel_up heel_down events.\nTABLE 4.1: Dataset dancer\ncolumn indicated phase holds relative phase, , time heel event relative time previous musical beat event context defined next musical beat event. expressed range \\([0,2\\pi]rad\\), see formula\n(2.3).column indicated time0 holds time events start fragment.\nFragment, Participant, Heel, Trialf.\nFragment 3 levels (“.F1”, “F1”, “F2”) indicating 3 fragments,\nParticpant 3 levels (“P2”, “P3”, “P4”), indicating 3 participants,\nHeel 2 levels (“HeelsUp”, “HeelsDown”), \nTrialf 12 levels (“01”, “02”, “03”, “04”, “05”, “06”, “07”, “08”, “09”, “10”, “11”, “12”). mentioned, trial “05” “08” dataset.visual representation heel_down events per fragment, including participants trials, shown figure 4.4. right panel axis data rotated \\(0 [rad]\\) appears middle vertical axis, using formula rotating axis data, see equation (2.4).\nfollows, use rotated representation represent relative phase.\nFIGURE 4.4: Plot relative phase heel-events fragments IF1, F1 F2, (top) scale 0 $2pi, (bottom) scale -pi +pi.\nview data immediately suggests fragments might indeed different . first sight, difference can observed F1 F2, lower relative phase values F2 F1. Lower values imply shorter delay, eventually larger anticipation, heel-event, given beat event.addition overall trend, different trials per fragment, represented colored vertical circles next , suggest trend towards higher values. implies delay less anticipation respect musical beat. Although trend somewhat prominent .F1 compared F1 F2, doesn’t overrule major difference fragments.\nRecall difference fragments might due anticipation/prediction mechanisms. However, trend trials, clearly visible .F1, may due fatigue.let’s proceed inspection data. Consider heel events evolve time. figure 4.5, view heel-events trial 1 F1 shown next view trials F1. horizontal axis time starting beginning fragment F1.\nvertical axis phase heel-event relative musical beat event, expressed radians. Note dat vertical lines slightly tilted right. ’s time relative phase related.\nFIGURE 4.5: Plot heel-events three different dancers fragment F1, (top) one single trial, (bottom) trials\nfigure reveals relative phase decreases time proceeds, suggesting micro-timing changes performance proceeds. left picture, suggestive see change relative phase values around 8-9 seconds. dots appearing 0 8 seconds seem higher dots appearing 9 16 seconds. correspond phrase 1-2 phrase 3-4 figure 4.3.Overall, visualisation data suggests hypotheses probably confirmed solid quantitative tests using statistical modelling.","code":""},{"path":"chapDancer.html","id":"regression-1","chapter":"4 Dancer","heading":"4.5 Regression","text":"first focus fragments.\nidea extract mean variance fragment data, disregarding variance possibly due repeated measures.\ncomparison reveal whether fragments different among conditions.\nanalysis similar ANOVA, except data circular, use multilevel distributional approach sense group-level variable Trialf model parameters von Mises response distribution model. Additionally, next section, also add time.","code":""},{"path":"chapDancer.html","id":"model-1","chapter":"4 Dancer","heading":"Model","text":"model specification brms shown :first line says Phase response, Fragment, Participant, Heel Trialf predictors. intercept, indicated 1 syntax, captures overall mean data.\npredictors Fragment, Participant, Heel corresponding parameters reveal population-level effects.\npredictor Trialf corresponding parameter reveals group-level effect, , effect among levels Trialf, assuming normal distribution variability.second line says kappa response, using specification predictors top part. Given circular response distribution, link function von_mises, parameter corresponding gaussian sigma called kappa.\ndefined :\n\\[\nf(x | \\mu, \\kappa) = \\frac{1}{2\\pi I_0(\\kappa)} \\exp(\\kappa \\cos(x - \\mu))\n\\]\n:\n\\(x\\) observed value unit circle (angle),\n\\(\\mu\\) mean direction parameter,\n\\(\\kappa\\) concentration parameter (measures dispersion distribution), \n\\(I_0(\\kappa)\\) modified Bessel function order 0:\n\\[\nI_0(\\kappa) = \\frac{1}{\\pi} \\int_{0}^{2\\pi} e^{\\kappa \\cos(\\theta)} d\\theta\n\\]non-circular regression model, used gaussian link function sigma specification variance parameter.alert reader may object data, shown figure 4.4 doesn’t need circular link function data look much gaussian. ’s true therefore, non-circular model gaussian link function may work data. However, considering entire dataset, including heels-events, circularity pops clearly, many data points top figure. reason, circular model better choice apply entire dataset.","code":"\nformula = bf(Phase ~ 1 + Fragment * Participant * Heel + (1| Trialf),\nkappa ~ 1 + Fragment * Participant * Heel + (1 | Trialf))\nfamily = von_mises()"},{"path":"chapDancer.html","id":"model-check","chapter":"4 Dancer","heading":"Model check","text":"useful check good response distribution fitted, using visual tool called pp_check() brms.\nposterior predictive check shows response model’s prediction response.\nsee fit response (yrep y), acceptable.\nFIGURE 4.6: Posterior predictive check\n","code":""},{"path":"chapDancer.html","id":"model-plotting","chapter":"4 Dancer","heading":"Model plotting","text":"Figure 4.7 shows result applying model dataset. cloud points just data. model specified terms big dots error bars. represent predicted means critical interval (CI-95%) means, per group.\nCI-95% means estimates mean fall interval 95% cases.\nFIGURE 4.7: Mean variance heel conditions fragments\nnext figure 4.8 go bit detail looking participant fragments.also plot two error bars.\none large horizontal lines shows CI-95% variance Trialf included.\nerror bar short horizontal lines shows CI-95% variance Trialf excluded.\ndifference gives indication importance group-level effect , case, represents effect repeated measures. now ready calculate contrasts order obtain quantitative picture difference among fragments.\nFIGURE 4.8: Showing mean variance dancer among fragments\nretrieve posterior predictive distributions use brms function epred_draws(). uses fitted model dataset generate draws expected value posterior distribution. use R-package circular calculate mean standard deviation circular scale, CI-95% standard deviation.\nBasically, similar calculations discussed chapter 2. calculate mean,\nobservation treated unit vector, point unit circle. resultant vector observations found, direction resultant vector returned. called synchronization delay \\(\\alpha\\).\nstandard deviation defined square root minus 2 times log mean resultant length \\(R\\) divided number observations.","code":""},{"path":"chapDancer.html","id":"contrasts","chapter":"4 Dancer","heading":"Contrasts","text":"Using R-package brms, contrasts can estimated considering difference two posterior predictive distributions, drawn fitted model’s predictions. prefer method rather looking posterior distributions model parameters distributions can hard interpret model complex. way retrieve posterior predictive distributions via posterior_epred(). computes summaries draws expected value (.e., mean) posterior predictive distribution. Alternatively one use epred_draws() %>% median_qi(). latter takes raw draws summarizes .Figure 4.9 illustrates works contrast two ballet fragments, .F1 F1, using heels-condition.\ntop, posterior predictive distributions mean seg1 seg2, standing .F1 F1, respectively.order get distributions equal number samples – need subtracting distributions (see ) – define two counterfactual datasets equal number time points segment, regardless segment duration original data.Accordingly, fitted model can used generalize specified time points, thus create wanted predictions. Details provided code script 06.seg1, mean \\(0.44 [rad]\\), seg2, \\(0.21 [rad]\\). Subtracting distributions implies equal amount draws distributions take random samples , subtract.\ngives new distribution seg1 - seg2, also radians, indicating contrast seg1 seg2.\nprobability mass distribution zero, mean difference close \\(0.23 [rad]\\).\nmeans strong support contrast segments, meaning seg1 higher values seg2, higher relative phase, implying seg2 anticipative.Assume posterior distributions overlapped , likely many samples one distribution close many samples distribution, generating values zero close zero. Accordingly, zero come picture probability mass positive, negative.\n95% probability mass either positive negative (called: probability direction, pd) strong support high contrast. percentage matter choice20.data panel shows thumbnail events time, just additional check talking : posterior distributions obviously apply means data, regardless time.\nFIGURE 4.9: Contrasts\nTable 4.2 shows contrasts among fragments heels-condition. labels est1 est2 show mean posterior predictive distributions fragments indicated, estdiff mean difference distribution, pd>0 indicating probability mass estdiff zero, expressed percentage.\nTABLE 4.2: Contrasts among fragments heel-condition\n","code":"\nnewdata_seg1 <- data_seg1 %>% \n  data_grid(Timeregion, Trialf, Participant, Fragment, Heel, \n            time0 = seq_range(time0, 25))\nnewdata_seg2 <- data_seg2 %>% \n  data_grid(Timeregion, Trialf, Participant, Fragment, Heel, \n            time0 = seq_range(time0, 25))\npp_seg1 <- posterior_epred(fit, newdata = newdata_seg1, re_formula = NA) \npp_seg2 <- posterior_epred(fit, newdata = newdata_seg2, re_formula = NA)"},{"path":"chapDancer.html","id":"smooth-regression-1","chapter":"4 Dancer","heading":"4.6 Smooth regression","text":"slightly advanced type modelling obtained mean variance calculated time, fragment, trials, participants, using circular representation relative phase heel-beat events.\ncan done smooth regression modelling: () calculate mean time music-dance phrase, (ii) give us mean variance due repeated measures eliminated, allow (iii) contrast checks music-dance phrases.","code":""},{"path":"chapDancer.html","id":"model-2","chapter":"4 Dancer","heading":"4.6.1 Model","text":"model smooth term specified time0, time seconds fragment, starting zero. smooth term accounts factor called HeelFragment, specifies interactions Heel Fragment levels. simple way handle interaction create new column HeelFragment data set interaction defined factor.model specification thus contains general intercept overall mean, intercept per level HeelFragment, smooth term time level HeelFragment. addition, variance modeled per participant, repeated measures related participant. notation 1|Participant/Trialf equal 1|Participant + 1|Participant:Trialf means variance among participants accounted assuming drawn normal distribution. words, trials nested within participant assumed also trials can drawn normal distribution.model computational intensive therefore, ran server rather laptop.\ncalculated model comes code chapter.","code":"\nformula = bf(Phase1 ~ 1 + HeelFragment + s(time0, by = HeelFragment) + \n               (1  |  Participant/Trialf ),\n             kappa ~ 1 + HeelFragment + s(time0, by = HeelFragment) + \n               (1  |  Participant/Trialf ) )\nfamily = von_mises()"},{"path":"chapDancer.html","id":"model-plotting-1","chapter":"4 Dancer","heading":"4.6.2 Model plotting","text":"\nFIGURE 4.10: Showing floating mean variance dancer among fragments\nFigure 4.10 now shows heel events coloured dots, lines indicating mean time, grey bands indicating uncertainty mean (95%-CI).inspection figure suggests plateau 3 8 seconds, another one 9 15 seconds (except F2 data stop 11 seconds). Now question whether plateau’s can substantiated terms statistical contrast.","code":""},{"path":"chapDancer.html","id":"contrasts-1","chapter":"4 Dancer","heading":"4.6.3 Contrasts","text":"Figures 4.11\nshow contrasts two segments, time intervals identified seg1 = \\([2.51, 4.25]sec\\) seg2 = \\([4.26, 6.00]sec\\) fragment F2 heels-.\nfigure shows posterior distribution mean seg1 seg2, well difference distribution seg1 - seg2. panel data shows thumbnails fragments seg1 seg2 indicated red.\ndistribution corresponding seg1 - seg2 include zero, probability mass one side zero equal higher 95% strong support claim means different.\nexample, segments different .\nFIGURE 4.11: Contrast two segments\nsummary table provides information need moment.\nlabel fragment\nindicates fragment segments contrasted,\nlabel contrast shows times segments contrasted, example segment \\([0.00, 4.25]s\\) versus segment \\([9.00, 13.25]s\\).\nlabels est, est2 estdiff show estimated mean first second segment, difference, pd>0 probability direction greater zero.\nTABLE 4.3: Contrasts among time segments heel-condition\nTable 4.3 best understood reference \nfigure 4.2.\nfigure, indicated sections phrases within fragments.\nPhrase 1 repeated phrase 3, phrase 2 repeated phrase 4.time segments defined table 4.3 correspond less phrase indications.\ntable shows \nsegments corresponding repeats phrases show contrast, segments corresponding repeats phrases show contrast.\nfindings support hypothesis 2, phrases within fragments different, assume prediction model influence micro-timing allowing anticipation.Note key aspect computation based drawing posterior predictive distributions segments can compared basis equal number samples spread segment.\ndata_grid() possible generate evenly spaced grid new data points using model. Even segments different intervals time, missing data points, grid can used draw posterior predictive distributions, can compared .","code":""},{"path":"chapDancer.html","id":"conclusion-3","chapter":"4 Dancer","heading":"4.7 Conclusion","text":"Given current knowledge sensory-motor synchronization, memory anticipation/prediction, contrast analysis seems support idea sequence establishes micro-timing model dancer. sequence repeated shortly , established micro-timing model facilitates timing events sequence, translates subtle shift relative phase, direction suggesting increase anticipation. Statistical modelling allows dealing circularity response (relative phase radians) multi-level representation repeated measures nested within subjects different variances conditions. resulting model called circular-linear multi-level distributional smooth regression ’s long name, isn’t ?Overall, question whether repeats musical sequence somehow influence micro-timing synchronization step understanding artistic expression terms interaction cognitive sensory-motor level. useful future technological mirrors, dancers monitor performances order become aware intuitions perhaps fine-tune artistic espression basis.","code":""},{"path":"chapViolinist.html","id":"chapViolinist","chapter":"5 Violin player","heading":"5 Violin player","text":"previous chapter looked music dancers performance, look violinists music performance.\nImagine orchestra string section. Typically, members string section, violinists, bowing movements going synchronized manner, appear one single organism moving together. Less experienced violinists learn play sync principal violinist section. need learn bowing gestures well particular expression associated .Now, imagine audiovisual play-along system visual representation principal violinist orchestra teacher-avatar. Wouldn’t cool system train , violinist? happens teacher-avatar visible 3D, Hololens? benefit learning?ultimate goal present chapter check effectiveness 3D play-back system learning play orchestra, compared 2D play-back system.\nHowever, figure easy matter, due small number participants study different level musical experience.\nOwing reasons, chapter highly exploratory.\nYet shows flexibility Bayesian statistical modelling, even focusing individual musicians.\nSomething useful future projects, data performance available.modelling techniques introduced previous chapter partly repeated present chapter. Data chapter can found Campo et al. (2023a, 2023b), software available Campo et al. (2024).\ncode can found following scripts data preparation plotting, modelling plotting, contrast analysis plotting:","code":"\nsource(\"Code/chapAll_00_Initialization.R\")\nsource(\"Code/chapAll_01_Functions.R\")\nsource(\"Code/chapViolinist/chapViolinist_02_DataPreparation.R\")\nsource(\"Code/chapViolinist/chapViolinist_03_DataPlotting.R\")\nsource(\"Code/chapViolinist/chapViolinist_04_Modelling.R\")\nsource(\"Code/chapViolinist/chapViolinist_05_ModelPlotting.R\")\nsource(\"Code/chapViolinist/chapViolinist_06_Contrasts.R\")"},{"path":"chapViolinist.html","id":"theory-2","chapter":"5 Violin player","heading":"5.1 Theory","text":"believe music playback system 3D teacher-avatar efficient learning 2D version?\nreason probably 3D offers richer feedback motor-control.hypothesis can tested augmented reality setting violinists wearing Hololens.\nunique capabilities allow parallax, visual changes visual scene small head movements, similar everyday life see object different angles estimate size considering close versus nearby features changing due head movements. bowing gestures violin teacher observed circumstances enables nuanced interpretation parallax possible, thus providing better feedback control bowing gestures. Parallax possible avatar seen 2D condition, teacher-avatar just projected screen.\nUsing Hololens bowing gestures can seen without parallax, depending whether scene presented 2D 3D augmented reality.Accordingly, augmented reality setting offers perfect environment testing whether parallax necessary component visual modality feedback motor control.\nFigure 5.1 shows typical measurement setup student (, b), teacher-avatar seen viewpoint student Hololens 2D (c), 3D (d).\nFIGURE 5.1: View teacher-avatar 2D 3D: () student violinist equipped Hololens motion tracking suit, (b) stick figure extracted, teacher-avatar 2D, (c, d) teacher-avatar 2D 3D, seen Hololens\n","code":""},{"path":"chapViolinist.html","id":"experiment-1","chapter":"5 Violin player","heading":"5.2 Experiment","text":"experiment, eleven participants recruited, members Ghent Universitary Student Orchestra GUSO.\nengaged four practice trials spaced evenly course month, student experiencing conditions (2D, 3D). Like real orchestral playing, members string section follow principal violinist, students instructed closely imitate teacher-avatar’s bowing gestures, encompassing bowings, articulations, dynamics.Due limited amount students, design somewhat peculiar sense \nparticipant takes part two conditions (2D 3D), four trials per condition (T1, T2, T3, T4).\nHowever, conditions apply different pieces (F1, F2, F3, F4), F1 F2 first violin players, F3 F4 second violin players. two teacher-avatars, one principal violinist first violin players,\none principal violinist second violin players.\nstructure shown table .Unfortunately, design allow us check conditions per student per piece. students played one piece 2D another piece 3D.\nHowever, piece, can compare students playing 2D students playing 3D.\nexample, piece F1, student P004, P006 P009 playing 2D condition student P001, P002, P0010 playing 3D condition.\nMoreover, subject played four trials, spread four weeks.\ntwo groups, formed condition, can compared per piece.\nTABLE 5.1: Experimental design\nEleven subjects much. reason experiments time-consuming subjects, play orchestra, sometimes hard find, especially participation longitudinal studies. Nevertheless, thanks four trials, consider repeated measures, just border enough statistical power.","code":""},{"path":"chapViolinist.html","id":"data-1","chapter":"5 Violin player","heading":"5.3 Data","text":"study already published Campo et al. (2023a) bowing gesture events can downloaded Campo et al. (2023b) software available Campo et al. (2024).\nfocus aspects statistical modelling explicitly contained publications.metric comes publicly available dataset (Campo.etal_2023a). describes similarity student teacher terms events, , identification bowing gesture subsequent calculation bowing similarity feature student teacher. similarity feature based Procustus distance (PD), quantifies extent deformation needed transform one gesture gesture. based scaling, rotating, translating student’s bowing gesture. Smaller PD values indicate greater similarity bowing gestures. detailed description metric can found (Campo.etal_2023). facilitate statistical fitting, use scaled log PD call log_PD. Note cases hard define bowing events. Accordingly, several passages taken account analysis.\nuse dataset specified following table.\noriginal dataset also contains motion capture, audio, questionnaire data violinists.\nTABLE 5.2: Data procustus distance (PD)\nfirst three columns contain metrics Procustus Distance, PD, (scaled) logarithm logPD.\ncolumns startIndex endIndex contain start end times bowing gesture seconds.\nsample times indicated time bowing gestures sampled every .3 seconds.\ncolumns subject, trial, condition, piece factors levels (11 subjects, 4 trials, 2 conditions, 4 pieces).","code":""},{"path":"chapViolinist.html","id":"data-plotting","chapter":"5 Violin player","heading":"5.4 Data plotting","text":"Basically, good performance defined performance student’s bowing gestures sync teacher’s bowing gestures. lower PD, similar bowing gesture resembles teacher’s bowing gesture.histogram data PD metric reveals Poisson-like distribution PD values, shown left panel figure 5.2.\nright panel shows logarithmic transformation PD values. Low values get bit stretched, high values get squeezed distribution still slightly skewed due data high PD values, especially 2D condition.\nInterestingly, difference 2D 3D mainly seen higher values, 3D fewer values, indicating better alignment.\ndotted lines show medians condition. looks 3D lower 2D.\nFIGURE 5.2: Density PD 2D 3D\nHowever, may differences pieces sections.\nFigure 5.3 shows data time, four different pieces (F1,F2,F3,F4) two conditions (2D, 3D).\nvertical axis shows logPD.\nhorizontal axis shows time.\ndot represents sample logPD value.\nFIGURE 5.3: Data four pieces two conditions\nDifferences 2D 3D subtle things can already observed visual inspection. example, first column (piece F1), first row (condition 2D), quite dots 2 2D condition, whereas dots 2 3D condition. suggests better alignment 3D. However, second column (piece F2), 75 seconds, looks higher logPD values occur 3D, compared 2D.\nFIGURE 5.4: Score excerpt first piece (F1), time indication seconds.\n","code":""},{"path":"chapViolinist.html","id":"smooth-regression-2","chapter":"5 Violin player","heading":"5.5 Smooth regression","text":"focus performance time, develop analysis based smooth regression. approach, estimate similarity/synchronization metric terms smooths time. smooths represent floating mean variance time.\nsmooth regression can specified follows:expression says logPD modeled general intercept (represented “1”) two levels condition (2D, 3D), smooth time levels condition, using basis 30 splines. value logPD certain point time weighted sum spline basis functions. Furthermore, trial subject defined group-level variables, whose variance extracted estimates variables don’t contain variance. Given fact PD 1-R show Poisson-like distribution, take log apply scaling mean data zero. allows us apply gaussian link function calculated mean variance data.smooth regression implemented R-package brms comes high computational cost, due algorithms optimization. Alternatively, R-package mgcv can used. However, brms flexible mgcv offers better grip fitted model.Based fitted model using brms, extract samples posterior. particular, generate posterior predictive distribution posterior difference distribution, similar way chapter 4. posterior predictive distribution can generated using newly defined data grid time sampled, say .5 seconds, variables model accordingly sampled. entire posterior prediction contains one posterior predictive distribution per specified time point, can easily extract distributions 2D 3D condition subtract get posterior difference distribution.probability mass zero can calculated used support difference posterior predictive distribution (2D - 3D). probability mass 90% zero give strong support 2D distinct 3D. Note posterior time instance, performance 2D versus 3D can contrasted time. Obviously, can also summarize time intervals.summarize steps: () run smooth regression model, (ii) generate model-based prediction using dataset counterfactual time (e.g. sampling every .5 seconds), (iii) contrast 2D 3D predictions sampled time.","code":"\nform = bf(logPD ~ 1 + condition + s(time,k=30) + \n            s(time,by=condition,k=30) +  (1 | subject + trial))\nfam = gaussian()"},{"path":"chapViolinist.html","id":"contrasts-2","chapter":"5 Violin player","heading":"5.6 Contrasts","text":"compare performances visual scene 2D 3D, develop contrast analysis shows us contrasts time.","code":""},{"path":"chapViolinist.html","id":"posterior-over-time","chapter":"5 Violin player","heading":"Posterior over time","text":"\nFIGURE 5.5: Piece F1 audio (top panel), logPD posterior predictions 2D 3D conditions (middle panel), posterior difference 2D 3D (bottom panel). Vertical lines show regions interest.\nFigure 5.5 shows audio posterior distributions first piece used experiment.\ntop panel shows audio waveform teacher’s performance. use mainly reference. blocks, marked vertical lines, show relevant sections bow gesture events identified. gray zones show zones bowing gesture events easily defined. Therefore, events deleted analysis.middle panel shows logPD bowing gestures 2D 3D performances subjects trials piece, see table.\nsmooths (2D gray, 3D ocre) show posterior predictive distribution calculated .5 seconds, indicating mean uncertainty condition subjects.\nNote smooths show 25% distribution’s probability mass (critical interval 25%, CI-25%). Taking CI-90% resulted much overlap less clear picture.bottom panel shows posterior difference distribution.\npoint time, 1000 samples randomly drawn (2D, 3D) posterior predictive distributions. , draw, number \\(2D\\) number \\(3D\\) subtracted (: \\(2D-3D\\)), giving 1000 new values used build new distribution, called posterior difference distribution.\nNote calculation entire distribution used, rather CI-25% shown middle panel.\ncalculation applied points time, leading posterior difference distribution CI-90%.\nred dots horizontal line (2D-3D = 0), just indicate whether data samples available point time.Note posterior difference distribution possible based smooths posterior predictive distribution. distribution based data points (rather smooths) face problem bow strokes common onset offset. therefore, compared. smooth allows contrast!\nprevious chapter, key trick define new data grid counterfactual time, use model generalizes time extract samples. R-code based following expressions:can now check probability direction sampled time defined interval time.\n, certain point time, gray band completely zero, , strong support 3D lower logPD 2D, means: 3D offers better alignment teacher.\ngray band completely zero, strong support 2D lower logPD value 3D, means: 2D offers better alignment teacher.\ncrosses zero, depends much probability mass different zero. still 70%, one argue weak trend, 50% certainly indicate difference.\nshort, gray band zero possible conclude student’s bowing gestures better lined 3D teacher’s bowing gestures, confirming theory parallax might offer distinctive feedback sensorimotor control needed bowing.bottom panel shows contrast analysis per time point.\ngraph seems suggest alignment favor 3D, meaning 3D works better 2D.\ntime instances, many.","code":"\nnewdat <- data %>% data_grid(time = seq(time_begin, time_end,by=.5))\npost_pred_distr <- epred_draws(fit, newdat, scale = \"response\", re_formula = NA) "},{"path":"chapViolinist.html","id":"considering-blocks","chapter":"5 Violin player","heading":"Considering blocks","text":"useful look data blocks.\nfigure 5.5 blocks marked time intervals \n\\([3.6, 38.7]\\),\n\\([53, 88]\\),\n\\([97.3, 99]\\),\n\\([127,145]\\),\n\\([165, 180.5]\\) seconds, indicated vertical red lines.First consider block one two.\nreference still bottom panel figure 5.5.\nSee also score figure 5.4, rudimentary indication time.\nblocks, sudden short peak appears 26 77 seconds, corresponding ending phrase longer notes played.\nfirst block almost everywhere significantly different, second block, gray parts can observed, instance 63 seconds.distribution two blocks can plotted density plots, shown figures 5.6 5.7.\nmentioned, can concluded contrast condition block 1 block 2.\nFIGURE 5.6: Contrast block1 [3.6,26]s\n\nFIGURE 5.7: Contrast block 2 [53,77]s\nBased posterior smooths, possible summarize blocks time.\nTable 5.3 shows result.\nlabel left indicates piece selected interval seconds, followed mean posterior difference distribution PD, CI-95% indicated min max, followed probability direction (pd).can observed almost contrasts positive, suggesting 2D higher logPD values 3D thus 2D overall less well aligned compared 3D. However, pd shows sections strong evidence contrast. logPD difference 0.5 least needed strong evidence contrast.\nTABLE 5.3: Contrasts defined segments different Pieces (F1,..,F4)\nConsidering block defined \\([3.6,38.7]s\\), evidence favor contrast. value pd, direction probability, says 96% distribution zero. zero (logPD value 1.00) means 3D condition, student’s performance much better aligned teacher.\nConsidering block defined \\([53,88]s\\). evidence contrast value pd 83%. One argue trend certainly distinctive enough. fact, careful visual inspection blocks 5.5 already suggested result.\nNow numbers!overall conclusion student’s alignment teacher, terms bowing gestures, works better 3D 2D sections showing strong support contrast rare: 4 17 sections. Moreover, seems evidence found piece F1.point, qualitative analysis score bow strokes needed.\nexample, time instances, especially long notes played ending block, difference suddenly prominent. Score associated performance analysis needed investigate origin sudden (dis)alignments student teacher.major point made methodological. analysis illustrates flexibility statistical modelling approach flexibility great value future work domain.","code":""},{"path":"chapViolinist.html","id":"individual-violinists","chapter":"5 Violin player","heading":"Individual violinists","text":"illustrate flexibility type modelling analysis individual violinists, can look performance violinist.\nFigure 5.8 shows individual violinist can visualized.\nline represents smooth data per trial, subject P009 .\nFIGURE 5.8: Piece F1 audio (top panel), logPD posterior predictions\n","code":""},{"path":"chapViolinist.html","id":"continuous-metric","chapter":"5 Violin player","heading":"5.7 Continuous metric","text":"follows, show results different metric.\nmetric discussed detail next chapter (chapter 6).\nsuffices say based continuous comparison bowing movements, using using time differences student teacher captured relative phase. metric ignorant bowing gesture events continuous metric. likely passages bowing teacher student rest shows highest synchronization. Obviously, passages rest can easily extracted audio.\nFIGURE 5.9: Piece F1 audio (top panel), logPD posterior predictions (middle panel), posterior difference 2D 3D. Vertical lines show regions interest\nclearly see contrast favour 3D, except passages indicate rest. indicate points, difference can made 2D 3D. Ideally, student teacher don’t move bow therefore, sync points, contrast zero. See second panel log(1-R) measure lowest regions audio occurs.Figures 5.10 5.11 show two metrics next , now applied second piece (F2).\ntop panel shows similar trend sense beginning piece, 3D offers better synchronization 2D. However, towards end piece, roles reversed 2D offers better synchronization 3D. reason may due fact score different towards end. Accordingly, type analysis calls deeper musicological analysis based additional score analysis. book place provide analysis. merely show statistical representation music performance may interest future work done domain.\nFIGURE 5.10: Comparison Procustus metric piece F2\n\nFIGURE 5.11: Comparison relative phase metric\n","code":""},{"path":"chapViolinist.html","id":"discussion-1","chapter":"5 Violin player","heading":"5.8 Discussion","text":"Several noteworthy aspects merit attention discussing teachers bow gestures. gestures vary expressiveness, ranging effectively convey clear intention less expressive fail effectively communicate intended message. times, gesture may readily anticipated comprehended student, facilitating synchronization teacher student. However, instances gesture unprepared, resulting diminished anticipation understanding part student.Treating gestures equally, irrespective level anticipation, – modelling – potentially impact analysis interpretation specific effects. Difference teachers’ expressiveness can consequently result disparate communicative values, influencing students perceive respond gestures.Moreover, student’s attention resources likely fluctuate time due multitasking, encompassing activities playing instrument, consulting musical score, observing teacher. Given dynamic, remains uncertain student directs attention attention distributed among tasks. Although technologies eye-trackers EEG measurements provide insights, integrating significantly augment volume data introduce numerous challenges subsequent data analysis statistical modeling.Furthermore, additional sources variability arise variations educational backgrounds complexity levels musical compositions. Students exhibit diverse playing skills varying levels experience within orchestra. Moreover, musical pieces present differing degrees difficulty, contributing complexity situation.multitude factors contributing uncertainty data inevitably impacts outcomes statistical modeling. Given limitations, unrealistic anticipate statistical modeling panacea resolving issues. Instead, objective chapter apply statistical modeling available data assess extent findings within context limitations.Primarily, chapter demonstrates efficacy smooth regression adaptability Bayesian statistical modeling. results may yield unequivocal conclusions due inherent uncertainties, methodology presented herein profoundly intriguing holds substantial potential future research music performance analysis.","code":""},{"path":"chapViolinist.html","id":"conclusion-4","chapter":"5 Violin player","heading":"5.9 Conclusion","text":"Overall, found trend favor 3D, least piece F1.\nability use parallax seems help particular circumstances related difficulty playing. However, 2D may offer already decent good visual perception opportunity sufficient control bowing gestures.\nresult, one may wonder whether cost Hololens addition equipment needed play along teacher-avatar really worth effort. merely see least trend favour 3D, line suggestion parallax important feature visual modality order work feedback control bowing gestures.Nevertheless, analysis illustrates flexibility smooth regression Bayesian statistics.\npossible zoom sections, get specific answers whether 2D 3D teacher-avatar condition works better sections.\nmain idea statistical modelling allows predictions equally sampled times, whereas data condition 2D necessarily happing time data condition 3D.Clearly, many things improve study. First , subjects needed, within subject comparisons offer better way somewhat complicated design study. Performance analysis remains difficult due many uncontrolled parameters.","code":""},{"path":"chapExoskeletons.html","id":"chapExoskeletons","chapter":"6 Two violin players","heading":"6 Two violin players","text":"chapter, study effect auditory, visual haptic modalities music playing, going beyond single listener, dancer, musician. Finally, look mutual interactions musicians!normal setting, two violinists playing rely hearing seeing , thus involving auditory visual modality co-regulate actions.\nHowever, violinist gets equipped exoskeleton, mounted around right arm, becomes possible influence bowing movements forces exerted exoskeleton.\nforces stimulate sense touch, haptics.\nhappens two exoskeletons get connected?\npossible test haptic modality can contribute co-regulation, compare visual auditory modality? modality provides best feedback synchronization?\nembodied connection exoskeletons contribute self-augmented interactions?code can found following scripts data preparation plotting, modelling plotting, contrast analysis plotting:","code":"\nsource(\"Code/chapAll_00_Initialization.R\")\nsource(\"Code/chapAll_01_Functions.R\")\nsource(\"Code/chapExoskeletons/chapExoskeletons_02_DataPreparation.R\")\nsource(\"Code/chapExoskeletons/chapExoskeletons_03_DataPlotting.R\")\nsource(\"Code/chapExoskeletons/chapExoskeletons_04_Modelling.R\")\nsource(\"Code/chapExoskeletons/chapExoskeletons_05_ModelPlotting.R\")\nsource(\"Code/chapExoskeletons/chapExoskeletons_06_Contrasts.R\")"},{"path":"chapExoskeletons.html","id":"unidirectional-haptic-feedback","chapter":"6 Two violin players","heading":"6.1 Unidirectional haptic feedback","text":"\nFIGURE 6.1: () Teacher exoskeleton motion capture suit. (b) Student equipped exoskeleton seeing video play-along\nFigure 6.1\nshows setup similar setup chapter 5, sense \nstudent synchronizes bowing gestures teacher.\nHowever, setup, teacher student equipped exoskeleton, teacher sending haptic information student. words, student sees feels teacher. question whether haptic information adds anything student.\nHowever, interesting may , skip analysis, move next level genuine bidirectionality.","code":""},{"path":"chapExoskeletons.html","id":"bidirectional-haptic-feedback","chapter":"6 Two violin players","heading":"6.2 Bidirectional haptic feedback","text":"Indeed, possible go one step consider happens two violinists haptic connection via exoskeletons, bi-directional. latter means violinists feel send haptic information . ultimate goal CONBOTS21 indeed connect humans exoskeletons, allowing mutual haptic information exchange common task can executed. common task : moving heavy table, playing music piece, simple self-augmented interactions.bi-directional connected exoskeletons realize channel mutual haptic feedback (= exoskeleton feedback) among violinist, bowing movements.\n, question whether exoskeleton feedback, haptic control, effective playing (polyphonic) music piece synchronized bowing movements.\nstatistical modelling needed figure modality, combination modalities, works best based techniques explored throughout several chapters.\nchapter much rehearsal techniques, attention signal conditioning, statistical modelling applied.\nFIGURE 6.2: Violinists equipped exoskeletons (photo: Shalan Alhamwy)\n","code":""},{"path":"chapExoskeletons.html","id":"theory-3","chapter":"6 Two violin players","heading":"6.3 Theory","text":"Two violinists playing together act co-regulated way, meaning sensory-motor control coordinated feedback receive others actions.\nnatural setting, violinists co-regulate synchronized bowing movements using auditory visual sensing.\nfeedback control mediated audio-visual modalities, hearing seeing.\nsensory-motor feedback via auditory /visual sensing indirect (mediated) involves translation one modality (audio, visual) another modality (motor).hypothesis exoskeleton feedback haptic control offers additional feedback control effective co-regulated action (bowing movements) exoskeleton offers direct (non-mediated) sensory-motor feedback directly impacting muscle activity.can assumed direct (non-mediated) feedback effective indirect (mediated) feedback.case rather bold hypothesis.\ndemonstration effectiveness exoskeleton feedback co-regulated action unique discovery huge implications domains movement synchronization via co-regulated sensory-motor control joint actions required.","code":""},{"path":"chapExoskeletons.html","id":"experiment-2","chapter":"6 Two violin players","heading":"6.4 Experiment","text":"good thing hypothesis can tested rather straightforwardly.\ncan done.\ntest hypothesis, experiment set four conditions involving different feedback modalities.\nTABLE 6.1: Experimental setup\nexoskeleton feedback effective, synchronization violins can characterized terms synchronization strength synchronization delay (see chapter 2).\nstrength synchronization can defined length average phase vector. provides information well violinists synchronizing.\ndelay synchronization can defined angle average phase vector. provides information preferred time delay violinists.\nsynchronization strength synchronization delay values can extracted bowing movements, using motion caption recording duet performances.\nRegression modelling (based R-package brms) used check whether conditions different.total, 20 violin dyads participated study.","code":""},{"path":"chapExoskeletons.html","id":"data-2","chapter":"6 Two violin players","heading":"6.5 Data","text":"follows, highlight () signal conditioning, (ii) feature extraction, (iii) statistical modelling.","code":""},{"path":"chapExoskeletons.html","id":"signal-conditioning","chapter":"6 Two violin players","heading":"Signal conditioning","text":"raw input signal coming motion caption system needs processed manipulated prepare statistical analysis, especially dealing phase, relative time among musicians.raw motion data interest come markers attached violin violin bow. data come infra-red camera’s send infra-red light reflected small mirrors surface marker. Based reflected infra-red light, motion caption system can determine position marker system coordinates X, Y Z, rate 120 samples per second.determine synchronization among two violinists useful prepare data gives use efficient measure synchronization.First focus marker closest frog bow.\nLet’s call bow-marker. However, marker alone enough.\nbody movement, even moving without moving bow, move bow-marker.\nTherefore, need relative movement based difference bow-marker marker violin, violin-marker.\ncan apply following signal conditioning steps:","code":""},{"path":"chapExoskeletons.html","id":"filtering","chapter":"6 Two violin players","heading":"Filtering","text":"first step, raw data filtered raw motion caption data X, Y Z coordinates may contain small irregularities, even missing data, due measurement. Raw data therefore impeded filtered (smoothed). Luckily data don’t contain missing values just apply filter, using Nadaraya–Watson kernel regression estimate, bandwidth .3. filter applied raw signals coming recorded performance. use 3 coordinates bow-marker 3 coordinates violin-marker, 2 violinists. Accordingly, filtering done 12 signals coming duet performances. goal now reduce 12 signals 2 signals, one per violinist, can compare terms synchronization.\nFIGURE 6.3: Displacement signals 120 sa/sec X, Y Z dimension bow-marker (left) violin-marker (right) provided mocap recording, smoothed signal top signal avoid peaks\nFigure 6.3 shows X, Y Z axis one single bow-marker one single violin-marker. horizontal axis time seconds, vertical axis displacement millimeter. ’s hard see, red color original signal grey color filtered signal. Due filtering, red extremes become smoother. work time, try avoid deformation signal. follow original much possible., calculate per coordinate, difference bow-marker violin-marker, get 6 signals, three per violinist.","code":""},{"path":"chapExoskeletons.html","id":"pca","chapter":"6 Two violin players","heading":"PCA","text":"next step, goal reduce 3 coordinates per violinist one coordinate per violinist. assumption bowing movement one direction, relative violin. can done rotating coordinate system capture bowing movement principal component rotated coordinate system. approach called PCA (principal component analysis).\nGiven filtered coordinates (Xs1,Ys1,Zs1 Xs2,Ys2,Zs2) direction largest variance determined, scorings computed first principal component. output signals \\(s1 = s1_n (n=1...N)\\) \\(s2 = s2_n (n=1...N)\\), \\(n\\) index sample.Figure 6.4 shows signals three coordinates single violinist relate extracted signal (gray).\nFIGURE 6.4: PCA-extracted signal (gray) compared original X, Y, Z signals (red)\nFigure 6.5 shows extracted signal two violin players dyad, one performance, time, correlated.\nFIGURE 6.5: Comparing extracted bowing gesture movements two violin players, (left) time, (right) correlated\nresulting CONBOTS_exo2_dataset Dat contains data dyads, conditioned signals s1 s2 form basis feature extraction.","code":"## tibble [4,382,362 × 42] (S3: tbl_df/tbl/data.frame)\n##  $ Placeholder: Factor w/ 560 levels \"D03_B1_T1_AE\",..: 1 1 1 1 1 1 1 1 1 1 ...\n##  $ Dyad       : Factor w/ 20 levels \"D03\",\"D07\",\"D09\",..: 1 1 1 1 1 1 1 1 1 1 ...\n##  $ Block      : Factor w/ 7 levels \"B1\",\"B2\",\"B3\",..: 1 1 1 1 1 1 1 1 1 1 ...\n##  $ Trial      : Factor w/ 6 levels \"T1\",\"T2\",\"T3\",..: 1 1 1 1 1 1 1 1 1 1 ...\n##  $ Condition  : Factor w/ 6 levels \"A\",\"AE\",\"AV\",..: 2 2 2 2 2 2 2 2 2 2 ...\n##  $ Tempo      : Factor w/ 2 levels \"100BPM\",\"72BPM\": 2 2 2 2 2 2 2 2 2 2 ...\n##  $ Time       : num [1:4382362] 21.2 21.2 21.2 21.2 21.2 ...\n##  $ Expertise  : Factor w/ 3 levels \"amateur\",\"professional\",..: 1 1 1 1 1 1 1 1 1 1 ...\n##  $ BOW1_1 X   : num [1:4382362] -894 -894 -894 -894 -894 ...\n##  $ BOW1_1 Y   : num [1:4382362] -105 -105 -105 -105 -105 ...\n##  $ BOW1_1 Z   : num [1:4382362] 967 967 967 967 967 ...\n##  $ BOW2_1 X   : num [1:4382362] 1136 1138 1139 1141 1143 ...\n##  $ BOW2_1 Y   : num [1:4382362] -96.7 -97.1 -97.4 -97.7 -97.9 ...\n##  $ BOW2_1 Z   : num [1:4382362] 961 963 966 969 972 ...\n##  $ VIOLIN1_3 X: num [1:4382362] -910 -910 -910 -910 -910 ...\n##  $ VIOLIN1_3 Y: num [1:4382362] 24.6 24.6 24.6 24.6 24.5 ...\n##  $ VIOLIN1_3 Z: num [1:4382362] 1037 1037 1037 1037 1037 ...\n##  $ VIOLIN2_3 X: num [1:4382362] 1250 1250 1249 1249 1249 ...\n##  $ VIOLIN2_3 Y: num [1:4382362] -41.5 -41.6 -41.6 -41.8 -42.1 ...\n##  $ VIOLIN2_3 Z: num [1:4382362] 1071 1071 1071 1071 1070 ...\n##  $ BX1        : num [1:4382362] -894 -894 -894 -894 -894 ...\n##  $ BY1        : num [1:4382362] -106 -106 -106 -106 -106 ...\n##  $ BZ1        : num [1:4382362] 969 969 969 969 969 ...\n##  $ BX2        : num [1:4382362] 1150 1151 1151 1152 1152 ...\n##  $ BY2        : num [1:4382362] -98.9 -98.9 -98.9 -99 -99 ...\n##  $ BZ2        : num [1:4382362] 987 988 988 989 990 ...\n##  $ VX1        : num [1:4382362] -909 -909 -909 -909 -909 ...\n##  $ VY1        : num [1:4382362] 24.1 24.1 24.1 24 24 ...\n##  $ VZ1        : num [1:4382362] 1037 1038 1038 1038 1038 ...\n##  $ VX2        : num [1:4382362] 1249 1249 1249 1249 1249 ...\n##  $ VY2        : num [1:4382362] -44.1 -44.2 -44.3 -44.4 -44.5 ...\n##  $ VZ2        : num [1:4382362] 1069 1069 1069 1068 1068 ...\n##  $ X1         : num [1:4382362] -15.3 -15.3 -15.3 -15.3 -15.3 ...\n##  $ Y1         : num [1:4382362] 130 130 130 130 130 ...\n##  $ Z1         : num [1:4382362] 68.9 68.8 68.8 68.7 68.6 ...\n##  $ X2         : num [1:4382362] 99.1 98.7 98.3 97.9 97.4 ...\n##  $ Y2         : num [1:4382362] 54.8 54.7 54.6 54.6 54.5 ...\n##  $ Z2         : num [1:4382362] 82 81.2 80.3 79.4 78.5 ...\n##  $ s1         : num [1:4382362, 1] -107 -107 -107 -107 -107 ...\n##  $ s2         : num [1:4382362, 1] 109 108 107 106 105 ...\n##  $ ss1        : num [1:4382362, 1] 117 117 117 117 117 ...\n##  $ ss2        : num [1:4382362, 1] 62.3 63.1 64 64.8 65.7 ..."},{"path":"chapExoskeletons.html","id":"feature-extraction","chapter":"6 Two violin players","heading":"6.6 Feature extraction","text":"Given conditioned movement signals violin, synchronization strength \\(R\\) synchronization delay \\(\\alpha\\) values calculated using following steps:First turn signals s1 s2 analytic signals (phasors) signals extract phase, ignoring amplitude. done Hilbert transformation extraction instantaneous phase \\(\\phi1\\) \\(\\phi2\\).First turn signals s1 s2 analytic signals (phasors) signals extract phase, ignoring amplitude. done Hilbert transformation extraction instantaneous phase \\(\\phi1\\) \\(\\phi2\\).focus timing, can captured relative phase \\(\\phi = \\phi1 - \\phi2\\) (\\(\\phi_n\\) relative phase sample \\(n\\)). , turn relative phase complex unit vector: \\(v_n = e^{j\\phi{_n}}\\). Accordingly vector, represented polar coordinates, defined phase length. latter simply equal one. Accordingly, one vector unit length per sample.focus timing, can captured relative phase \\(\\phi = \\phi1 - \\phi2\\) (\\(\\phi_n\\) relative phase sample \\(n\\)). , turn relative phase complex unit vector: \\(v_n = e^{j\\phi{_n}}\\). Accordingly vector, represented polar coordinates, defined phase length. latter simply equal one. Accordingly, one vector unit length per sample.take mean complex unit vectors: \\(V = \\frac{1}{N}{\\sum_{n=1}^N}v_n\\). vectors pointed point circle, length mean vector equal 1. phase equal phases sample. vectors point different points spread circle, length mean vector zero different directions cancell .take mean complex unit vectors: \\(V = \\frac{1}{N}{\\sum_{n=1}^N}v_n\\). vectors pointed point circle, length mean vector equal 1. phase equal phases sample. vectors point different points spread circle, length mean vector zero different directions cancell .Accordingly, extract mean vector length mean vector angle: \\(R = \\left|V\\right|\\) \\(\\alpha = arg(V)\\).\nmean vector length \\(R\\) synchronization strength. two violinists synchronize perfectly, \\(R=1\\). (variance synchronization strength defined \\(1-R\\).)\nmean vector angle \\(\\alpha\\) synchronization delay, expressed radians. two violinists delay, \\(\\alpha = 0\\). one goes systematically faster , reflected \\(\\alpha = 0\\) higher lower zero. expect around zero.Accordingly, extract mean vector length mean vector angle: \\(R = \\left|V\\right|\\) \\(\\alpha = arg(V)\\).\nmean vector length \\(R\\) synchronization strength. two violinists synchronize perfectly, \\(R=1\\). (variance synchronization strength defined \\(1-R\\).)\nmean vector angle \\(\\alpha\\) synchronization delay, expressed radians. two violinists delay, \\(\\alpha = 0\\). one goes systematically faster , reflected \\(\\alpha = 0\\) higher lower zero. expect around zero.\nFIGURE 6.6: () Upper panel: PCA-signal two violins (blue ocre). (b) Lower panel: relative phase.\nfeature extraction applied trial, .e., melody played.\nresulting CONBOTS_exo2_dataset Vector_Condition1234 contains following factors:Dyad levels: “D03” “D04” “D05” “D06” “D07” “D08” “D09” “D10” “D11” “D12” “D14” “D15” “D16” “D19” “D20” “D21” “D22” “D23”Dyad levels: “D03” “D04” “D05” “D06” “D07” “D08” “D09” “D10” “D11” “D12” “D14” “D15” “D16” “D19” “D20” “D21” “D22” “D23”Block levels: “B1” “B2” “B3” “B4” “B5” “B6”Block levels: “B1” “B2” “B3” “B4” “B5” “B6”Condition levels: “” “AE” “AV” “AVE”Condition levels: “” “AE” “AV” “AVE”Tempo levels: “100BPM” “72BPM”Tempo levels: “100BPM” “72BPM”Expertise levels: “amateur” “professional” “semiprofessional”Expertise levels: “amateur” “professional” “semiprofessional”","code":"## 'data.frame':    480 obs. of  12 variables:\n##  $ R          : num  0.591 0.871 0.957 0.898 0.88 ...\n##  $ alpha      : num  0.0906 0.2174 0.1471 0.1609 0.1615 ...\n##  $ abs_alpha  : num  0.0906 0.2174 0.1471 0.1609 0.1615 ...\n##  $ c          : num  0.645 0.82 0.926 0.852 0.833 ...\n##  $ count      : num  1 2 3 4 5 6 7 8 9 10 ...\n##  $ Placeholder: Factor w/ 480 levels \"D03_B1_T1_AE\",..: 1 2 3 4 5 6 7 8 9 10 ...\n##  $ Dyad       : Factor w/ 20 levels \"D03\",\"D04\",\"D05\",..: 1 1 1 1 1 1 1 1 1 1 ...\n##  $ Block      : Factor w/ 6 levels \"B1\",\"B2\",\"B3\",..: 1 1 1 1 2 2 2 2 3 3 ...\n##  $ Trial      : Factor w/ 4 levels \"T1\",\"T2\",\"T3\",..: 1 2 3 4 1 2 3 4 1 2 ...\n##  $ Condition  : Factor w/ 4 levels \"A\",\"AE\",\"AV\",..: 2 3 4 1 3 2 1 4 4 3 ...\n##  $ Tempo      : Factor w/ 2 levels \"100BPM\",\"72BPM\": 2 2 2 2 1 1 1 1 2 2 ...\n##  $ Expertise  : Factor w/ 3 levels \"amateur\",\"professional\",..: 1 1 1 1 1 1 1 1 1 1 ..."},{"path":"chapExoskeletons.html","id":"statistical-modelling","chapter":"6 Two violin players","heading":"6.7 Statistical modelling","text":"Next use hierarchical distributional regression model allowing flexible modeling entire distribution response variable, using nesting groups, relaxing assumptions variance among groups.\nspecification model :response (either synchronization strength \\(R\\), synchronization delay \\(\\alpha\\)) modeled predictors Condition Tempo, interaction.\nInformation Dyads nested sense Dyads either amateur, professional, semiprofessional, Dyad performs certain Blocks. hierarchy captured group-level predictor.\nvariance sigma estimated using predictors.\nGiven slightly skewed distribution data, skew_normal link function used.\nfitting, analysis can based contrast measures population-level group-level predictions, given posterior distributions.","code":"form <- bf(response ~ Condition*Tempo + (1|Expertise:Dyad:Block)\nsigma ~ Condition*Tempo + (1|Expertise:Dyad:Block))\nfam <- \"skew_normal\""},{"path":"chapExoskeletons.html","id":"model-checking","chapter":"6 Two violin players","heading":"6.8 Model checking","text":"visual check modelling fitting shows model simulations can predict data distribution.\nFIGURE 6.7: Posterior prediction check, (left) R, (right) alpha\n","code":""},{"path":"chapExoskeletons.html","id":"synchronization-strengh-r","chapter":"6 Two violin players","heading":"6.9 Synchronization strengh R","text":"Posterior predictions synchronization strengh R calculated compared data, leaving effects group-levels.\nFIGURE 6.8: Posterior predictions R\nFigure 6.8 shows modelling comparison data. dot represents performance.\nvertical axis shows R, horizontal axis shows four conditions, tempo 72 BPM 100 BPM.\nDots error bars show mean uncertainty mean critical interval 95% (CI-95%).contrasts relevant, except AE-AVE 100BPM.\nstrong evidence condition lower R conditions, tempi.\nstrong evidence conditions AE AVE higher R conditions AV.\nweak evidence 72 BPM higher R 100 BPM.following tables show calculated differences detail.","code":""},{"path":"chapExoskeletons.html","id":"population-level-effects-model-1-fit_r","chapter":"6 Two violin players","heading":"6.9.1 Population-level effects model 1 (fit_R)","text":"\nTABLE 6.2: Contrasts population effects alpha\n","code":""},{"path":"chapExoskeletons.html","id":"group-level-effects-model-1-fit_r-expertise","chapter":"6 Two violin players","heading":"6.9.2 Group-level effects model 1 (fit_R): Expertise","text":"\nTABLE 6.3: Contrasts group effects (Expertise) R\ngroup-level effect Expertise.\nNevertheless, may interest reader see extracted group-level distributions posterior. ’s bit technical, though. See code 07.","code":""},{"path":"chapExoskeletons.html","id":"group-level-effects-model-1-fit_r-blocks","chapter":"6 Two violin players","heading":"6.9.3 Group-level effects model 1 (fit_R): Blocks","text":"\nTABLE 6.4: Contrasts group effects (Blocks) R\ngroup-level effects Blocks.","code":""},{"path":"chapExoskeletons.html","id":"posterior-predictions-model-2-fit_log_abs_alpha","chapter":"6 Two violin players","heading":"6.10 Posterior predictions model 2 (fit_log_abs_alpha)","text":"\nFIGURE 6.9: Posterior predictions R\nvertical axis shows alpha (radians), horizontal axis shows four conditions values tempo 72 BPM 100 BPM.\nDots error bars show mean uncertainty mean critical interval 95% (CI-95%).\nvalues centered closely around zero, suggesting considerable phase delay.","code":""},{"path":"chapExoskeletons.html","id":"population-level-effects-model-2-synchronization-delay-log_abs_alpha","chapter":"6 Two violin players","heading":"6.10.1 Population-level effects model 2 (synchronization delay log_abs_alpha)","text":"\nTABLE 6.5: Contrasts population effects alpha\n","code":""},{"path":"chapExoskeletons.html","id":"group-level-effects-model-2-fit_log_abs_alpha-expertise","chapter":"6 Two violin players","heading":"6.10.2 Group-level effects model 2 (fit_log_abs_alpha): Expertise","text":"\nTABLE 6.6: Contrasts group effects (Expertise) alpha\neffect.","code":""},{"path":"chapExoskeletons.html","id":"group-level-effects-model-2-fit_log_abs_alpha-blocks","chapter":"6 Two violin players","heading":"6.10.3 Group-level effects model 2 (fit_log_abs_alpha): Blocks","text":"\nTABLE 6.7: Contrasts group effects (Blocks) alpha\neffect.","code":""},{"path":"chapExoskeletons.html","id":"discussion-2","chapter":"6 Two violin players","heading":"6.11 Discussion","text":"chapter introduced interactive context two violin players.\nanalysis reveals clear effect bi-directional feedback via exoskeletons synchronization violin bowing gestures.\nConditions, ordered according synchronization strength \\(\\ll AV \\ll AE \\ll AVE\\), reveal importance exoskeleton feedback. Conditions exoskeletons better synchronization among violinists.quite remarkable indeed audio-visual condition surpassed audio-haptic (AE) condition.\nsuperiority AVE synchronization delay may due combination three modalities, audio, visual, haptic.exoskeleton feedback raises number interesting questions related role anticipation sensory-motor control, particularly, question whether exoskeleton feedback immediate control effect, whether predictive capacity.","code":""},{"path":"chapExoskeletons.html","id":"conclusion-5","chapter":"6 Two violin players","heading":"6.12 Conclusion","text":"remarkable result present study confirms hypothesis distinctive feature exoskeleton feedback may due direct influence sensory-motor control, due motor modality operates.\ncontrast, audio visual feedback mediate sensory-motor control, thus affecting synchronization strength.\ninteresting finding view self-augmented interaction hypothesis. shows embodied connection may facilitate co-regulated synchronization, assume beneficial establishing self-augmented interaction.terms modelling chapter applied techniques introduced previous chapters context two player mutually influence . mutual influence needs attention.","code":""},{"path":"chapTappers1.html","id":"chapTappers1","chapter":"7 Two finger tappers – dynamic system","heading":"7 Two finger tappers – dynamic system","text":"chapter deals mutual influences interacting.\nexample, two subjects perform timing task seeing performing timing task differently.\nperformances affecting , terms timing?\nmutual influence work? ?analyse data two persons interacting , previous studies used methods cross-correlation, cross-recurrence analysis, quantification analysis, delay-coupled oscillators, among others22.\napproach inspired compartmental models state units (subjects metronomes) changed flow among them23. goal identify flow find parameters govern flow among units. parameters explain predict happens.\n’s cool idea feasible?chapter also introduce Stan24, probabilistic programming language underneath R-package brms. show program Stan, order calculate regression dynamic system predictor.code contained :","code":"\nsource(\"Code/chapAll_00_Initialization.R\")\nsource(\"Code/chapAll_01_Functions.R\")\nsource(\"Code/chapTappers/chapTappers_02_Simulation.R\")\n#source(\"Code/chapTappers/chapTappers_04_Modelling.R\")\n# source(\"Code/chapTappers/chapTappers_05_ModelPlotting.R\")\n# source(\"Code/chapTappers/chapTappers_06_Contrasts.R\")\n# source(\"Code/chapTappers/chapTappers_07_ContrastPlotting.R\")"},{"path":"chapTappers1.html","id":"theory-4","chapter":"7 Two finger tappers – dynamic system","heading":"7.1 Theory","text":"theoretical background chapter based two principles: entrainment dynamic systems.","code":""},{"path":"chapTappers1.html","id":"entrainment-1","chapter":"7 Two finger tappers – dynamic system","heading":"Entrainment","text":"First consider entrainment, rhythmic entrainment. can defined adaptation timing, due influences.\nstudy mutual influences, , entrainment persons interacting .\nEntrainment probably factor facilitates self-augmented interactions (see chapter 1).\nprobably works automatic adaptation collaborative activities towards joint goal.\npower may huge, even emotional effect humans involved activities., key idea focus entrainment timing.\ndemonstrating near inevitability entrainment controlled circumstances, Rosso et al. (2024) created incongruency feedback controlling actions. done creating conditions hearing seeing inform timing differently. Rosso et al. (2024) collected super-interesting data want use next chapter. able use data, ask entrainment can captured dynamic system.","code":""},{"path":"chapTappers1.html","id":"dynamic-system","chapter":"7 Two finger tappers – dynamic system","heading":"Dynamic system","text":"fact, entrainment can understood principle tends solve incongruent feedback actions. Entrainment lead congruent perception due adaptation actions cause perceptions. viewpoint, ’s interest consider dynamic framework understanding.idea capture entrainment terms dynamic system challenging, human behavior complicated details action-perception mechanisms leading entrainment specific individual, far known. , deal ?Well, dynamic systems approach assumes interaction ruled higher-level parameters matter interaction. Therefore, level, reduction underlying action-perception mechanisms necessary behavior can globally described. Accordingly, unit involved interaction can handled black box whose inputs outputs known (estimated) without knowing black box functions. order words, drop reductionism adopt holistic perspective. Ultimately, approaches may integrated.\nlet’s see far get holistic perspective.","code":""},{"path":"chapTappers1.html","id":"drifting-metronomes","chapter":"7 Two finger tappers – dynamic system","heading":"7.2 Drifting metronomes","text":"drifting metronomes paradigm, developed (Rosso et al., 2021, 2023), clever way uncover entrainment, controlling incongruency. works detail.Two subjects engage synchronized tapping listening metronome headphones. metronomes slightly detuned tempo, phase drifting. particular, one metronome tics every 600 ms, tics every 610 ms. Initially, metronomes start ticking together (-phase), time evolves, tics become wider apart (-phasing), eventually reaching anti-phase state ticking comes closer time (-phasing). cycle completed, metronomes one tic exactly together. One complete outphasing inphasing cycle takes \\(36.6\\) seconds (\\(600 * 610/ 10\\)). subjects asked perform 10 cycles row one performance. instructed follow metronome hear headphones.conditions interest : () seeing (ii) seeing .25Rosso et al. (2023) found subjects’ tapping behavior influenced seeing tapping, despite instruction follow metronome. words, visual coupling individuals led entrainment effect tapping behavior, even task implied anti-entrainment (resistence entrainment). suggests incongruent visual cues partner’s tapping influenced synchronization subjects can particularly strong, overriding intended synchronization metronome heard.interest offer causal explanation phenomenon level phase flow, change timing among subjects. goal build dynamic system predict entrainment, using control parameters covern causal flow among interacting units.","code":""},{"path":"chapTappers1.html","id":"causality","chapter":"7 Two finger tappers – dynamic system","heading":"Causality","text":"type modelling suggests causal level tapping/ticking basically understood terms coupling strength, (), phase delay, among persons metronomes involved. Conceptually speaking, approach different smooth regression, modelling based basis expansion using many splines. , number parameters limited parameters straightforward physically interpretation terms attention time. Moreover, knowledge dynamics causal flow. don’t need go deeper subcomponents interacting units. don’t model oscillators!\ndynamics pops (less well understood) action-perception mechanisms characterize timing interacting units, dynamics described higher level coupling strength phase delay physical meaning.restriction measure coupling strength phase delay directly.\nRather infer values data.","code":""},{"path":"chapTappers1.html","id":"approach","chapter":"7 Two finger tappers – dynamic system","heading":"Approach","text":"development dynamical system, regression model, implies several steps sumarize figure 7.1:\nFIGURE 7.1: Methodological approach (see text explanation)\nBlock 1 defines dynamic system (ODE-system) regression (ODE-regression). causal flow among interacting units defined coupling strength (K) phase delay (D) parameters. regression estimates value parameters using data.Block 1 defines dynamic system (ODE-system) regression (ODE-regression). causal flow among interacting units defined coupling strength (K) phase delay (D) parameters. regression estimates value parameters using data.Block 2 aims validating regression model simulated tic tap data, parameters K D defined order generate data. goal retrieve parameters simulated data. parameters used generating data parameters obtained estimation correspond.Block 2 aims validating regression model simulated tic tap data, parameters K D defined order generate data. goal retrieve parameters simulated data. parameters used generating data parameters obtained estimation correspond.Block 3 applies regression model real human tapping data. goal estimate parameters generate process generates data. point can contrast parameters seeing versus non-seeing conditions check whether different.Block 3 applies regression model real human tapping data. goal estimate parameters generate process generates data. point can contrast parameters seeing versus non-seeing conditions check whether different.chapter focus Block 1 2, next chapter focus Block 3.","code":""},{"path":"chapTappers1.html","id":"dynamic-system-1","chapter":"7 Two finger tappers – dynamic system","heading":"7.3 Dynamic system","text":"Let us start defining dynamic system context drifting metronomes paradigm.\ncontain four units: two metronomes synchronize two subjects interacting.\nAccordingly, dynamic system can described units arrows, shown figure 7.2.Metronome 1, subject 1, metronome 2 subject 2 represented units \\(m1,s1,m2\\) \\(s2\\) \ncoupling represented arrows pointing one unit another unit. arrow \\(s1\\) pointing \\(m1\\) means subject 1 coupled metronome 1, described combination coupling strength phase delay.\narrow show subject coupled metronome, subject.follow convention arrows point direction influence comes . Accordingly, subject points metronome subject.\nFIGURE 7.2: Dynamic system\n","code":""},{"path":"chapTappers1.html","id":"coupling-parameters","chapter":"7 Two finger tappers – dynamic system","heading":"Coupling parameters","text":"arrow defined two parameters: coupling strength phase delay.coupling strength prefix \\(k\\). value ranges 0 1, value 0 indicates coupling, value 1 indicates full coupling. coupling strength \\(ks1m1\\) captures strongly \\(s1\\) coupled \\(m1\\) thus, strongly \\(m1\\) affecting tapping \\(s1\\).important feature model coupling parameters constrained fact , one subject, coupling parameters always sum \\(1\\). words: \\(1 = ks1m1 + ks1s2\\).rationale constraint subject limited attention resources (0 1) define coupling. Accordingly, attention devoted \\(s2\\) cost attention devoted \\(m1\\). Therefore, attention \\(m1\\) /\\(s2\\) works system communicating vessels, constant volume distributed two focus points.Accordingly, can represent coupling strength length arrows, suggested figure 7.3.\nleft block subjects devote attention metronome (\\(ks1m1 = ks2m2 = 1\\)). typical situation condition subjects hear metronome don’t see .\nright block, subjects divide attention partly metronome, partly partner.\ntypical situation condition subjects hear metronome see .\nfigure suggests \\(s1\\) attention metronome partner (say, \\(ks1m1 = .7\\) \\(ks1s2 = 1-.7 =.3\\)), \\(s2\\) attention partner metronome (say, \\(ks2m2 = .3\\) \\(ks2s1 = 1-.3 = .7\\)).\nFIGURE 7.3: Assumed coupling strength parameters uncoupled coupled condition\nphase delay prefix \\(d\\) (figure 7.2) value ranges \\(-\\pi\\) \\(\\pi\\).\n\nspecifies average time lag entire outphasing-inphasing cycle 36.6 seconds.\nphase delay can interpreted average synchronization offset.\nStricly speaking can deleted model introducing gives flexibility model.","code":""},{"path":"chapTappers1.html","id":"phase-and-phase-flow","chapter":"7 Two finger tappers – dynamic system","heading":"Phase and Phase flow","text":"dynamic system describes change phase time, connected units network.\nfocus phase work events (taps tics ) occurring fixed time intervals metronomes, varying time intervals subjects. time interval covers \\(2\\pi\\). phase proportion \\(2\\pi\\), dynamic system describes much phase changes time units.\nNote phase increases continuously can wrapped scale \\(2\\pi\\), interval \\([0, 2\\pi]\\), rotated, interval \\([-\\pi,+\\pi]\\).Let us now look detail change phase among components dynamic system.","code":""},{"path":"chapTappers1.html","id":"phase-flow-metronomes","chapter":"7 Two finger tappers – dynamic system","heading":"Phase flow metronomes","text":"change phase time metronomes notated \\(\\dot{\\theta}_{m}\\) \\(\\frac{d\\theta_m}{dt}\\). eigen-frequency units radians per second \\([\\frac{rad}{sec}]\\). Accordingly, \\(m1\\) runs ticking phase cycle (\\(2\\pi\\)) \\(.6 sec\\), \\(m2\\) \\(.61 sec\\). metronomes fixed phase cycle influences acting upon . outward pointing arrows. dynamic equations :\\[\n\\dot{\\theta}_{m1} = \\omega_{m1} =  \\frac{2\\pi}{.6}\\\\\n\\dot{\\theta}_{m2} = \\omega_{m2} =  \\frac{2\\pi}{.61}\n\\]","code":""},{"path":"chapTappers1.html","id":"phase-flow-subjects","chapter":"7 Two finger tappers – dynamic system","heading":"Phase flow subjects","text":"phase flow subjects bit demanding, due outgoing arrows represent influences.\nsubjects varying phase cycle due influences.\ndynamic equations \\(s1\\) \\(s2\\) :\\[\\begin{equation}\n\\begin{array}{rl}\n\\dot{\\theta}_{s1} = & \\omega_{m1} + \\\\\n& ks1m1 \\cdot sin(\\theta_{m1} - \\theta_{s1} + ds1m1) + \\\\\n& (1-ks1m1) \\cdot sin(\\theta_{s2} - \\theta_{s1} + ds1s2)\\\\\n\\end{array}\\\\\n\\begin{array}{rl}\n\\dot{\\theta}_{s2} = & \\omega_{m2} + \\\\\n& ks2m2 \\cdot sin(\\theta_{m2} - \\theta_{s2} + ds2m2) +\\\\\n& (1-ks2m2) \\cdot sin(\\theta_{s1} - \\theta_{s2} + ds2s1)\\\\\n\\end{array}\n\\tag{7.1}\n\\end{equation}\\]Let’s focus \\(s1\\).\nsubject requested follow \\(m1\\) therefore eigen-frequency set equal eigen-frequency metronome.\nsubject devoting attention \\(m1\\), \\(ks1m1 = 1\\) subject tap phase metronome, apart possible phase delay.\nIdeally, zero contribution second third term right hand side equation. keep mind.subject devoting attention \\(s2\\),\n\\(ks1m1 < 1\\) influence exerted.first consider second term, simplify \n\\[sin(\\theta_{m1} - \\theta_{s1}).\\]\nfirst part outphasing-inphasing cycle, \\(s1\\) influenced \\(s2\\) therefore phase difference \\(\\theta_{m1s1} = \\theta_{m1} - \\theta_{s1}\\) increasing time reaches maximum \\(\\theta_{m1s1} = \\frac{\\pi}{2}\\). point, pulling force phase \\(s1\\) comes back phase \\(m1\\). second part outphasing-inphasing cycle, phase difference decreasing minimum (\\(-1\\)) \\(\\theta_{m1s1} = \\frac{3\\pi}{2}\\).Next, consider third term, simplified :\n\\[sin(\\theta_{s2} - \\theta_{s1}).\\]\nfirst part outphasing-inphasing cycles, \\(s2\\) tapping slower \\(s1\\) phase difference \\(\\theta_{s2s1} = \\theta_{s2} - \\theta_{s1}\\) descreasing. increasing second part. minimum appear \\(\\theta_{s2s1} = \\frac{\\pi}{2}\\), maximum \\(\\theta_{s2s1} = \\frac{3\\pi}{2}\\).words, \\(m1\\) \\(s2\\) pull opposite direction due outphasing inphasing \\(s2\\), one may expect , typically, anti-phase zero-crossing point delayed \\(s2\\) \\(m1\\). slowed , later zero-crossing point occur outphasing-inphasing cycle.Since sinusoids add, curve become asymmetrical time amplitude. Don’t forget \\(sin(.)\\) first multiplied coupling strength. extreme parameter settings (e.g., \\(ks1m1\\) < .4) zero-crossing effect disappears (see examples ).Finally, also consider effect phase delay parameters.\nSince parameters constant entire outphasing-inphasing cycle, affect entire curve shift values.\neffect also best illustrated means examples.","code":""},{"path":"chapTappers1.html","id":"understanding-the-dynamic","chapter":"7 Two finger tappers – dynamic system","heading":"Understanding the dynamic","text":"point instructive consider phase flow using simulation dynamic equation.\nFirst take dynamic equations define differential equation function called dydt.first four equations define dynamic system depicted figure 7.2.\nNext retrieve components contribute \\(ds1\\).\nfact, re-calculate \\(ks1m1* sin(m1 - s1 + ds1m1)\\) \\(ds1a\\) \n\\((1-ks1m1)* sin(s2 - s1 + ds1s2)\\) \\(ds1b\\).\nsolve equations numerically using R-package deSolve.data frame looks like:solution comes time indicator, phases \\(m1, s1, m2, s2, s1a\\) \\(s1b\\), phase changes \\(dm1, ds1, dm2, ds2, ds1a\\) \\(ds1b\\) - prefix \\(d\\) refers differential, delay.Note example, coupling strengths defined \\(ks1m1 = .9, ks2m2 = .7\\) delay parameters set zero.\nHowever, instructive vary coupling strengths systematic way see happens.\nlet us look \\(s1a\\) \\(s1b\\), components contribute phase change \\(s1\\).\nFIGURE 7.4: Phase change s1 due competing influences m1 s2. columns show five different values ks1m1, rows show two different values ks2m2. thick line average thin lines, representing instantaneous frequency (without eigen-frequency)\nfirst row shows phase change \\(s1\\), different values \\(ks1m1\\) influences due \\(s2\\), \\(ks2m2 = 1\\). second row shows phase change \\(s1\\) \\(ks2m2 = .75\\).see contrasting sinusoids \\(m1\\) \\(s2\\) (shown thin lines) define phase change (shown thick line). dotted vertical line marks anti-phase time metronomes.\nNote furthermore \\(ks1m1 = .4\\) curve flipped. marks fact tapping line \\(s2\\) \\(s1\\).\nsimilar way, possible calculate change phase \\(s2\\) based pulling metronome partner subject.Next show phase change \\(s1\\) \\(s2\\).\ngraph represent inverse instantaneous frequency, known instantaneous period, period vertical axis. Accordingly, \\(ks1m1 = ks2m2 = 1\\), subjects follow metronomes therefore instantaneous period tapping 600 ms 610 ms. Note blue curves (\\(s1\\)) reversed curves figure 7.4.\nFIGURE 7.5: Instantaneous period s1 s2. columns show five different values ks1m1, rows show two different values ks2m2\nfigure reveals blue curves (\\(s1\\)) become slightly different mutual influence due \\(ks2m2 = .75\\). now see clearly instantaneous period \\(s1\\) comes close instantaneous period \\(s2\\) \\(ks1m1 = .4\\) \\(ks1m1 = .2\\).Next, shown relative phase, rather instantaneous period.\nHowever, phase continuously increasing practical look phase relative metronome, example taking phase metronome minus phase subject. rotate axis interval covers \\([-\\pi,+\\pi]\\).\nFIGURE 7.6: Relative phase s1 s2. columns show five different values ks1m1, rows show two different values ks2m2\nviewpoint interest phase delays enter picture.\nnext figure shows relative phase \\(ds1m1 = ds2m2 = 1\\).\nFIGURE 7.7: Relative phase s1 s2, phase delay ds1m1 = ds2m2 = 1. columns show five different values ks1m1, rows show two different values ks2m2\nNote phase delay tends shift curve downward, implying anticipation, similar figures appear, except beginning curves point, start state zero position.examples reveal complex character dynamical system. Despite fact composed simple sinusoids, final behavior can rather surprising.","code":"\n# Define the differential equation do_dydt\ndydt <- function(t, y, parms) {\n  with(as.list(c(y, parms)), {\n    ############################## dynamic system\n    dm1 = 2*pi*1000/600\n    ds1 = 2*pi*1000/600  + \n          .5*(ks1m1* sin(m1 - s1 + ds1m1) + \n             (1-ks1m1)* sin(s2 - s1 + ds1s2) )\n    \n    dm2 = 2*pi*1000/610\n    ds2 = 2*pi*1000/610  + \n          .5*(ks2m2* sin(m2 - s2 + ds2m2) + \n             (1-ks2m2)* sin(s1 - s2 + ds2s1) )\n    ############################## retrieve components for ds1\n    ds1a = ks1m1 * sin(m1 - s1 + ds1m1)\n    ds1b = (1-ks1m1) * sin(s2 - s1 + ds1s2)\n    \n    return(list(c(dm1,ds1,dm2,ds2,ds1a,ds1b)))\n  })\n}\n# define time points\ndt = 1/100\ntime_points <- seq(0, 36.6, by = dt)\n# define initial state\nstate <- c(m1 = 0, s1 = 0, m2 = 0, s2 = 0, s1a = 0, s1b = 0)\n# define the parameters\nparm = c(ks1m1 = .9, ks2m2 = .7, ds1m1 = 0, ds2m2 = 0, ds1s2 = 0, ds2s1 = 0)\n# solve the ODE\nsolution <- ode(y = state, times = time_points, func = dydt, parms = parm) %>% \n      data.frame()\n# calculate the phase change over time = instantaneous frequency\nsolution <- solution %>% mutate(\n  dm1 = c(NA,diff(m1)),\n  ds1 = c(NA,diff(s1)),\n  dm2 = c(NA,diff(m2)),\n  ds2 = c(NA,diff(s2)),\n  ds1a = c(NA,diff(s1a)),\n  ds1b = c(NA,diff(s1b))\n)## 'data.frame':    3661 obs. of  13 variables:\n##  $ time: num  0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 ...\n##  $ m1  : num  0 0.105 0.209 0.314 0.419 ...\n##  $ s1  : num  0 0.105 0.209 0.314 0.419 ...\n##  $ m2  : num  0 0.103 0.206 0.309 0.412 ...\n##  $ s2  : num  0 0.103 0.206 0.309 0.412 ...\n##  $ s1a : num  0.00 1.93e-09 1.15e-08 3.65e-08 8.34e-08 ...\n##  $ s1b : num  0.00 -8.58e-07 -3.43e-06 -7.71e-06 -1.37e-05 ...\n##  $ dm1 : num  NA 0.105 0.105 0.105 0.105 ...\n##  $ ds1 : num  NA 0.105 0.105 0.105 0.105 ...\n##  $ dm2 : num  NA 0.103 0.103 0.103 0.103 ...\n##  $ ds2 : num  NA 0.103 0.103 0.103 0.103 ...\n##  $ ds1a: num  NA 1.93e-09 9.61e-09 2.50e-08 4.69e-08 ...\n##  $ ds1b: num  NA -8.58e-07 -2.57e-06 -4.28e-06 -5.99e-06 ..."},{"path":"chapTappers1.html","id":"general-specification","chapter":"7 Two finger tappers – dynamic system","heading":"General specification","text":"possible generalize dynamical system units, arranged different constellations don’t go topic .\nInstead, want check whether dynamic system worth effort.\nproceed, may interest generalize approach using equation (7.2):\\[\\begin{equation}\n\\frac{d\\theta_{}}{dt} = \\omega_{} + \\sum_j K_{,j} sin(\\theta_{t,j} - \\theta_{t,} + D_{,j}),~\n~ \\theta_i(0) = 0 \\tag{7.2}\n\\end{equation}\\]\\(\\theta\\) phase,\n\\(,j\\) index elements \\(\\left\\{ m1,s1,s2,m2 \\right\\}\\), \n\\(\\omega\\) instantaneous frequency, set \\(\\omega_i = \\frac{2\\pi*}{.6}~[\\frac{rad}{sec}]\\), \\(=1,2\\) \\(\\omega_i = \\frac{2\\pi}{.61}~[\\frac{rad}{sec}]\\) \\(=3,4\\).","code":""},{"path":"chapTappers1.html","id":"design-matrices","chapter":"7 Two finger tappers – dynamic system","heading":"Design matrices","text":"matrix \\(K\\) contains coupling parameters rows (index \\(\\)) columns (index \\(j\\)), parameters range \\([0,1]\\).\nAccordingly, \\(K(2,1) = K_{s1,m1} = ks1m1\\).\nmatrix \\(D\\) contains delay parameters range \\([-\\pi,\\pi]\\).Matrices K D design matrices define dynamic system. Dots mean parameter created. parameter created (e.g. \\(ks1m1\\)), two possibilities: either parameter gets defined value data can generated , value parameter estimated given data. chapter, ’ll first define , estimate . can check whether estimation correctly done.\\[\nK = \\begin{matrix}   \n&m1~~~~~~~~~~s1~~~~~~~~~~m2~~~~~~~~~~s2\\\\\n\\begin{matrix}   \n   &m1 \\\\\n   &s1 \\\\\n   &m2 \\\\\n   &s2 \\\\\n\\end{matrix} &\n\\begin{bmatrix}\n. &. &. &. \\\\\nks1m1 &. &. &1-ks1m1 \\\\\n. &. &. &. \\\\\n. &1-ks2m2  &ks2m2 &.\\\\\n\\end{bmatrix}\n\\end{matrix}\n\\]\\[\nD = \\begin{matrix}   \n&m1~~~~~s1~~~~~m2~~~~~s2\\\\\n\\begin{matrix}   \n   &m1 \\\\\n   &s1 \\\\\n   &m2 \\\\\n   &s2 \\\\\n\\end{matrix} &\n\\begin{bmatrix}\n. &. &. &. \\\\\nds1m1 &. &. &. \\\\\n. &. &. &. \\\\\n. &.  &ds2m2 &.\\\\\n\\end{bmatrix}\n\\end{matrix}\n\\]","code":""},{"path":"chapTappers1.html","id":"simulating-phase-flow-dynamics","chapter":"7 Two finger tappers – dynamic system","heading":"7.4 Simulating phase flow dynamics","text":"Equation (7.2) non-linear therefore useful explore simulations. refer shiny application here26, readers may explore.\nGiven explanation, believe tool self-explanatory.","code":""},{"path":"chapTappers1.html","id":"generating-data","chapter":"7 Two finger tappers – dynamic system","heading":"7.5 Generating data","text":"Now dynamic system goal generate tics taps, three steps:Continuous phase-function generation. dynamic equations generate curves unit dynamic system. curves, phase-functions, represent underlying ticking tapping process, either relative phase instantaneous frequency (period) consider generating series dynamic systems, defined parameters. dynamic system, ’ll get phase functions unit.Continuous phase-function generation. dynamic equations generate curves unit dynamic system. curves, phase-functions, represent underlying ticking tapping process, either relative phase instantaneous frequency (period) consider generating series dynamic systems, defined parameters. dynamic system, ’ll get phase functions unit.Extraction event times. Using generated phase-functions can extract time phase-functions becomes multiple \\(2\\pi\\). time instances correspond tics taps metronomes subjects.Extraction event times. Using generated phase-functions can extract time phase-functions becomes multiple \\(2\\pi\\). time instances correspond tics taps metronomes subjects.Addition tap time noise. Given human variability finger tapping tasks, possible introduce noise extracted tap times.Addition tap time noise. Given human variability finger tapping tasks, possible introduce noise extracted tap times.steps generate dataset discrete metronome tics subject taps used regression retrieve parameters generated tics taps.","code":""},{"path":"chapTappers1.html","id":"constraints-in-parameters","chapter":"7 Two finger tappers – dynamic system","heading":"Constraints in parameters","text":"Based drifting metronomes paradigm, subjects asked tap along metronome heard headphones, assume subjects indeed able adhere metronome. implies coupling strength \\(ks1m1\\) \\(ks2m2\\) rarely < .4 case actually follow partner (illustrated figures). Furthermore, assume testing purposes subjects distribution coupling strength. Accordingly, first generate coupling strength values subject 1. reshuffle values assign coupling strength values subject 2.Constraints phase delays can justified studies showing humans tend anticipate beat.\npoint, however, define phase delay metronomes, set phase delay among subjects zero.","code":""},{"path":"chapTappers1.html","id":"generate-phase-functions","chapter":"7 Two finger tappers – dynamic system","heading":"Generate phase-functions","text":"phase-functions generated using parameters coupling strength phase delay using samples distributions shown figure 7.8.\nFIGURE 7.8: Densities coupling parameters \\(ks1m1\\) \\(ks2m2\\), delay parameters \\(ds1m1\\) \\(ds2m2\\)\ncoupling strength parameters based beta distribution. phase delay based skewed normal distribution, accounting small anticipation \\(ds1m1\\) \\(ds2m2\\). distribution allows capturing asymmetry slight anticipation commonly observed tapping behavior27\n.Table 7.1 shows parameters 40 randomly generated dynamic systems.\ncolumns represent number parameters \\(ks1m1, ks2m2, ds1m1, ds2m2\\).\nNote first 20 dynamic systems, specified parameters, zero phase delay, second 20 coupling strength non-zero phase delay:\nTABLE 7.1: Parameters 40 dynamic systems\nnumber dynamic systems (n = 40) purely arbitrary conforms practical concerns keeping regression calculations (done later) within reasonable amount time.Given parameters, generate dynamic systems using code similar ode-solver code shown . However, phase-functions calculated high sampling rate 10,000 samples per second order get precise time indications tics taps.","code":""},{"path":"chapTappers1.html","id":"extract-tics-and-taps","chapter":"7 Two finger tappers – dynamic system","heading":"Extract tics and taps","text":"unit, time values taken multiples \\(2\\pi\\), using phase-function calculated previous step.\nresulting data set, rows \\(n=1...N\\), contains time, phases metronomes subjects, simulation number (= defined matrices) reference unit, illustrated figure 7.2.\nexample, time 0.6, metronome 1 (see column names) produced tick, phase (\\(6.283185\\), \\(2pi\\)) shown column phi_m1.\ntime 0.61, metronome 2 produced tic. phase (\\(2\\pi\\)) shown phi_m2.\ntime 0.6006, subject 1 produced tap, shown phi_s1. phase close \\(2\\pi\\), small acceptable peak extraction error.\n.\nTABLE 7.2: Tappers data\n","code":""},{"path":"chapTappers1.html","id":"adding-noise","chapter":"7 Two finger tappers – dynamic system","heading":"Adding noise","text":"Finally, extracted taps tics , noise added time values.\nnoise characteristic \\(2\\pi N(0, \\sigma)\\), \\(\\sigma\\) defined \\(0.0045\\) [s].","code":""},{"path":"chapTappers1.html","id":"examples","chapter":"7 Two finger tappers – dynamic system","heading":"Examples","text":"Figure 7.9 shows phase functions discrete taps dynamic system 1, whose parameters defined first row table 7.1).\nparameters indicated top.\ntop panel shows relative phase subject tapping respect associated metronome ticking.\ndotted vertical line indicates one completed outphasing-inphasing cycle. Three cycles shown.\nbottom panel shows instantaneous periods units (subjects metronomes).\nNote metronomes form straight lines 600 610 ms.\nFIGURE 7.9: Dynamic system 1. Generated phase-functions tapping data\nNote introduction delay results offset shown figure 7.10. inclusion delay lines dynamic system 21, can observed two relative phase curves longer overlap (compared ODE-system 1) relative phase subject 2 zero, reflecting anticipation metronome 2.\nFIGURE 7.10: Dynamic system 21. Generated phase-functions tapping data\nNext consider parameters ODE-system 26.\nFIGURE 7.11: Dynamic system 26. Generated phase-functions tapping data\ncoupling parameters dynamic system 26 result subject 2 strongly coupled subject 1, causing positive bias relative phase subject 2 towards subject 1. Conversely, subject 1 strongly coupled metronome less influenced subject 2, resulting relatively constant relative phase time. similar behavior actually reflected instantaneous period representation.Additionally, important note dynamic system constrained start \\(0 [rad]\\). indicated dashed red line, beginning second de-phasing/-phasing cycle, phase deviates \\(0 [rad]\\) dynamics cycles becomes stable (cf. cycle 2 cycle 3). Note dashed red line marks end first cycle.observations highlight intricate dynamics deviations perfect synchrony tapping process, influenced coupling parameters, delay lines, initial conditions dynamic system.\nUsing interactive tool odetappers2, figures can replicated setting parameters accordingly.","code":""},{"path":"chapTappers1.html","id":"regression-with-dynamic-system","chapter":"7 Two finger tappers – dynamic system","heading":"7.6 Regression with dynamic system","text":"specified dynamic system, discrete tap data can extracted generated phase-functions, now turn attention regression.\nobjective estimate parameters dynamic system using data, predict phase function based observed discrete taps.\nworks, super cool regression model dynamical system predictor.","code":""},{"path":"chapTappers1.html","id":"data-3","chapter":"7 Two finger tappers – dynamic system","heading":"Data","text":"Let us first define dataset, created, gives input regression.\n’s list times names tics/taps occur, notated \\(\\theta_n = \\theta_{t,}\\), \\(n=1,2,3...\\) indicating row \\(\\) index unit (\\(\\left\\{ m1,s1,s2,m2 \\right\\}\\)), \\(t\\) time tics/taps occur\ndataset shown table 7.2, time names selected.\nTABLE 7.3: Simulated tappers data\ntimes mark tic/tap therefore, phase time instance \\(2\\pi = 0 [rad]\\), indicating start new phase cycle lasts next tic/tap.\ncomputational purposes, tics/taps represented phase rotated scale, \\([-\\pi,+\\pi]\\).","code":""},{"path":"chapTappers1.html","id":"equation","chapter":"7 Two finger tappers – dynamic system","heading":"Equation","text":"regression defined fitting based :\\[\\begin{equation}\n\\theta_n \\sim f(\\eta_n, \\kappa)\n\\end{equation}\\]\\(\\theta_n\\) response row \\(n\\), containing time information phase \\(2\\pi\\) \\(0 [rad]\\).\n\\(f\\) von-Mises distribution, mean \\(\\eta_n\\), precision \\(\\kappa\\), realizing mapping circular representation phase \\(\\theta_n\\).\\(\\eta_n\\) outcome ODE-solver \\(Z\\) time indicated row \\(n\\). Modulo \\(2\\pi\\) (fmod) used prevent undefined growing phase value:\\[\n\\eta_n = fmod(Z(t_n;\\Theta),2\\pi).\n\\]\nODE-solver \\(Z\\) returns successive phases estimates unit \\(\\) defined set parameters \\(\\Theta\\)\\[\n\\Theta = (\\theta_i(0),K_{,j}, D_{,j})\n\\]\n\n\\(\\theta_{m1,m2}(0) = 0\\) \\(\\theta_{s1,s2}(0)\\) estimated.\nObviously, parameters design matrices K D also estimated.\nFinally, solution ODE-solver, gives phase value \\(t_n=T\\), can specified \n\\[\n\\\\\n\\begin{aligned}\n&\\theta_{t_n > 0,} =  \\theta_i(0) + \\int_{t>0}^{T} \\left[ \\omega_{} + \\sum_{j=1}^4 K_{,j} sin(\\theta_{t,j} - \\theta_{t,} + D_{,j}) \\right]~ dt &\\\\\n&\\theta_i(0) =  0&\\\\\n\\end{aligned}\n\\]","code":""},{"path":"chapTappers1.html","id":"priors","chapter":"7 Two finger tappers – dynamic system","heading":"Priors","text":"priors parameters K D defined using previous available knowledge.\nsubjects requested follow metronome, prior coupling strength parameter obeys beta distribution peak towards 1. Accordingly, beta specified \\(beta(19,2)\\).\nPhase delay parameters unknown assume normal distributed standard deviation 0.5.\nKappa defined \\(lognormal(.1,.15)\\).\nFinally, initial phases \\(s1\\) \\(s2\\) defined occur neighborhood zero, \\(normal(.0,.15)\\).\\[\n\\begin{aligned}\n& ks1m1 &\\sim &beta(19,2) &\\text{Prior coupling strength s1 m1, range: [0,1] }\\\\\n& ks2m2 &\\sim &beta(19,2) &\\text{Prior coupling strength s2 m2, [0,1]  }\\\\\\\\\n& ds1m1 &\\sim &normal(.0,.5) &\\text{Prior phase delay s1 m1},[-\\pi,\\pi]\\\\\n& ds2m2 &\\sim &normal(.0,.5) &\\text{Prior phase delay s2 m2}, [-\\pi,\\pi]\\\\\n& ds1s2 &\\sim &normal(.0,.5) &\\text{Prior phase delay s1 s2}, [-\\pi,\\pi]\\\\\n& ds2s1 &\\sim &normal(.0,.5) &\\text{Prior phase delay s2 s1}, [-\\pi,\\pi]\\\\\\\\\n& \\kappa &\\sim &lognormal(0.1,1.0) &\\text{Prior precision} \\\\\\\\\n& \\theta_{s1}(0) &\\sim &normal(.0,.15) &\\text{Prior initial phase s1} \\\\\n& \\theta_{s2}(0) &\\sim &normal(.0,.15) &\\text{Prior initial phase s2} \\\\\n\\end{aligned}\n\\]","code":""},{"path":"chapTappers1.html","id":"running-stan","chapter":"7 Two finger tappers – dynamic system","heading":"7.7 Running Stan","text":"now turn Stan, need order calculate regression.\nStan probabilistic programming language used primarily statistical modeling Bayesian inference. provides flexible framework specifying fitting wide range statistical models, including linear regression, hierarchical models, time series models, complex models involving latent variables hierarchical structures. fact, R-package brms translates lme4-syntax Stan code, run Stan engine. book, Stan us indirectly, via brms. program directly Stan.Recall objective assess feasibility retrieving coupling parameters simulated data. values coupling parameters, can compare parameter estimates terms posterior distributions.\naddition, can also compare phase-functions, also known posterior predictions.facilitate evaluation, randomly selected third outphasing/inphasing cycle simulated data input.input Stan list containing number observations (n_times), number generated time instances (n_gen_times), initial time (time0), phase (phase), time phase appears (time), generated time instances (time_gen), unit (name_indicator) (1=\\(m1\\), 2=\\(s1\\), 3= \\(m2\\), 4= \\(s2\\)). list looks like:call Stan function R following specification:Inside Stan code, reader can retrieve code ./Code/chapTappers, call ODE function :ODE-function defined according dynamic system :phases retrieved :Basically, defines regression implemented Stan.\n’s rather compact half page code28.","code":"## List of 7\n##  $ n_times        : int 487\n##  $ n_gen_times    : num 100\n##  $ time0          : num 0\n##  $ phase          : num [1:487] 0 0 0 0 0 0 0 0 0 0 ...\n##  $ time           : num [1:487] 0 0.0127 0.0177 0.5689 0.5895 ...\n##  $ time_gen       : num [1:100] 0.0001 0.3698 0.7395 1.1092 1.4789 ...\n##  $ names_indicator: int [1:487] 1 4 2 2 2 1 1 4 3 3 ......\nvector[4] omega[n_times] = ode_rk45(do_dt, y0, time0, time, ks1m1, ks2m2, ds1m1, ds2m2, ds1s2, ds2s1) ;\n\n...\n  \n for (n in 1:n_times){\n     phase[n] ~ von_mises(fmod(omega[n,names_indicator[n]] + pi(), 2*pi()) - pi(), kappa) ;\n   }functions {\n  vector do_dt(real t, vector y,  real ks1m1, real ks2m2,  real ds1m1, real ds2m2,\n  real ds1s2, real ds2s1){\n    real pi600 = 2*pi()/.6; // Eigenfrequency s1, m1\n    real pi610 = 2*pi()/.61;  // Eigenfrequency s2, m2\n\n    real dm1dt = pi600; \n    real ds1dt = pi600 + \n              .5*( \n              ks1m1 * sin(y[1] - y[2] + ds1m1) + \n              (1-ks1m1) * sin(y[4] - y[2] + ds1s2)  ); \n    real dm2dt = pi610;\n    real ds2dt = pi610 + \n              .5*( \n              ks2m2 * sin(y[3] - y[4] + ds2m2) + \n              (1-ks2m2) * sin(y[2] - y[4] + ds2s1)  ); \n    return to_vector([dm1dt,ds1dt,dm2dt,ds2dt]);\n  }\n}vector[4] phase_gen[n_gen_times] = ode_rk45(do_dt, y0, time0, time_gen, ks1m1, ks2m2, ds1m1, ds2m2, ds1s2, ds2s1) ;"},{"path":"chapTappers1.html","id":"evaluation","chapter":"7 Two finger tappers – dynamic system","heading":"7.8 Evaluation","text":"defined dynamic system, generated data 40 dynamic systems, set regression model, run 40 regression models order estimate parameters 40 dynamic systems,\nnow ready \ndevoted attention evaluation.mentioned, two options evaluating output regression.\nfirst option consider posterior distributions estimated parameters.\nsecond option consider posterior predictions, phase-function.","code":""},{"path":"chapTappers1.html","id":"evaluating-the-posterior-distributions-of-parameters","chapter":"7 Two finger tappers – dynamic system","heading":"Evaluating the posterior distributions of parameters","text":"look parameters 40 fitted models.\nFigure 7.12 shows posterior distributions (estimated mean 95%CI), compared designed parameters (cicles).top panel shows coupling strengths 40 dynamic models tested.\nWhite circles imply match designed estimated parameter values.\nRecall designed K-parameters exactly models 1 20, models 21 40.\nmiddle panel shows phase delay metronome, zero models 1 20 randomly assigned models 21 40. seems match K-parameters somewhat less good phase delay forced zero.\nbottom panel shows phase delay partner. Overall, values rather small around zero.\nFIGURE 7.12: Posterior distributions fitted parameters, compared designed parameters (cicles). Top: coupling strength. Middle: phase delay metronome. Bottom: phase delay partner\ntable 7.4 show parameters models.\nTABLE 7.4: Defined fitted parameters 40 dynamic systems.\nColumn names following coding convention:\nDefined parameters : \\(k1 = ks1m1\\), \\(k2 = ks2m2\\),\n\\(d1 = ds1m1\\), \\(d2 = ds2m2\\), \\(d3 = ds1s2\\), \\(d4 = ds2s1\\).\nFitted parameters : \\(K1 = ks1m1\\),\n\\(K2 = ks2m2\\),\n\\(D1 = ds1m1\\),\n\\(D2 = ds2m2\\),\n\\(D3 = ds1s2\\),\n\\(D4 = ds2s1\\).\nDifferences :\n\\(Kk1 = K1 - k1\\),\n\\(Kk2 = K2 - k2\\),\n\\(Dd1 = D1 - d1\\) \n\\(Dd2 = D2 - d1\\)\nTable 7.5 gives summary \nerror designed estimated parameters.\ncolumns show mean absolute value errors,\nstandard deviation absolute value errors,\nlower boundary 95% errors, upper boundary 95% errors, phase delay (, Yes) parameter (K, D).\nK parameters mean absolute value errors 0.04 standard deviation 0.03 (0.02 phase delay specified).\nvalues suggest error 3% coupling strength (interval \\([0,1]\\)).\nD parameters error \\(100* .10 / (2\\pi) = 1.6 \\%\\) phase delay (interval \\([-\\pi,+\\pi]\\)).\nTABLE 7.5: Mean absolute value errors, standard deviation absolute errors, Q95 range designed estimated compling strength K phase deley D, without designed phase delay\nOverall, can concluded dynamic models quite successful retrieving K D parameters.\ndynamic model might useful real data.","code":""},{"path":"chapTappers1.html","id":"evaluating-the-posterior-predictions","chapter":"7 Two finger tappers – dynamic system","heading":"Evaluating the posterior predictions","text":"look posterior predictions know already phase-functions: either relative phase shown, instantaneous period shown.\ncomparison qualitative, showing pictures designed phase-functions fitted phase-functions.\nshown examples:\nFIGURE 7.13: Dynamic systems 1 21. Left: Generated data (circles) defined phase functions (dotted lines) versus fitted phase functions (full lines gray band showing mean 95% confidence posterior predictions). estimations cover one single tapping cycle, using cycle 3 generated data. Right: Instanteneous period fitted model\n","code":""},{"path":"chapTappers1.html","id":"discussion-3","chapter":"7 Two finger tappers – dynamic system","heading":"7.9 Discussion","text":"error defined estimated coupling strength parameters 2% less coupling strength scale, great difference accuracy coupling strengths without defined phase delay. Good news applications dynamic system approach.However, several limitations shortcomings evaluation mentioned well.First, dynamic system assumes attention either devoted metronome heard subject seen. One may question whether realistic. Perhaps human subjects get distracted events outside timing task. Distraction something model doesn’t capture.Second, current model, coupling strength model fixed time human coupling strength changes time.Finally, modelling needs accurately reflect physical setup. slightly different paradigm studying rhythmic entrainment (e.g. spontaneous tapping without metronomes) require careful adaptation dynamic system defined chapter.","code":""},{"path":"chapTappers1.html","id":"conclusion-6","chapter":"7 Two finger tappers – dynamic system","heading":"7.10 Conclusion","text":"chapter studied entrainment dynamic system defined network timing units (metronomes subjects) whose phase flow can described differential equations.\ndynamic system can generate phase-functions possible extract discrete events, standing tics taps.developed regression model dynamic system used predictor estimating parameters generate tic tap data. used designed tic tap date input regression model order estimate parameters dynamic system.Finally, estimated parameters can compared designed parameters, predicted phase-functions can compared designed phase functions.Overall, non-linear regression modelling seems offer \nvaluable tool acquiring insight rhythmic entrainment terms causal dyadic interactions level phase flow.","code":""},{"path":"chapTappers2.html","id":"chapTappers2","chapter":"8 Two finger tappers","heading":"8 Two finger tappers","text":"chapter follow-previous chapter. now apply dynamic model analyse human finger tapping data. primary objective figure whether two persons’ synchronized tapping becomes influenced, entrained, seeing tapping.define entrainment terms set non-linear equations, specified previous chapter.\nregression modelling, estimate coupling strength phase delay parameters equations, individual performance. parameters gives us insight entrainment individual dyadic performances (two persons tapping)., using averages parameters, possible get view entrainment population dyads. parameters define dynamic model, can always generate phase-functions bonus, show modelling can nicely explain earlier findings based smooth regression recurrence analysis.code can found following scripts data preparation plotting, modelling plotting, contrast analysis:","code":"\nsource(\"Code/chapAll_00_Initialization.R\")\nsource(\"Code/chapAll_01_Functions.R\")\nsource(\"Code/chapTappers2/chapTappers2_02_DataPreparation.R\")\nsource(\"Code/chapTappers2/chapTappers2_03_DataPlotting.R\")\nsource(\"Code/chapTappers2/chapTappers2_04_Modelling.R\")\nsource(\"Code/chapTappers2/chapTappers2_05_ModelPlotting.R\")\nsource(\"Code/chapTappers2/chapTappers2_06_Contrasts.R\")"},{"path":"chapTappers2.html","id":"theory-5","chapter":"8 Two finger tappers","heading":"8.1 Theory","text":"Based previous chapter, can specific theoretical concepts entrainment, leader-follower, anticipation.Entrainment can now defined coupling strength partner:\n\\[\nE_{s1} = ks1s2 = 1 - ks1m1\\\\\nE_{s2} = ks2s1 = 1 - ks2m2\n\\]\nEntrainment \\(s1\\) \\((E_{s1})\\), coupling strength \\(s2\\).\nEntrainment \\(s2\\) \\((E_{s2})\\), coupling strength \\(s1\\).However, given fact \n\\(ks1s2 = 1 - ks1m1\\) \\(ks2s1 = 1 - ks2m2\\), definition also uses adherence metronome (requested task). clarify , believe useful distinguish entrainment-coupling strength adherence-coupling strength, specify whether coupling strength applies subject metronome. One argue adherence-coupling strength characterizes anti-entrainment force competing entrainment force pulling synchronization.Next, leader–follower relation can defined difference entrainment-coupling strength two subjects. makes sense coupled condition (C):\n\\[\nLF_{s1s2} = ks1s2 - ks2s1 =  ks2m2 - ks1m1\n\\]\n\\(LF_{s1s2}\\) positive negative depending whether \\(s1\\) \\(s2\\) leading.Note concept leader–follower, defined terms strength coupling, really tell us locally leading tapping. fact, start early phase outphasing-inphasing cycle, \\(s1\\) typically leading, simply due fact \\(s2\\) taps slower speed. roles reversed subjects passed anti-phase tap. moment , appears \\(s2\\) leading shortest phase interval now initiated \\(s2\\). Accordingly, concept leader–follower actually interpreted terms adherence strength (anti-entrainment). leader one better synchronizes metronome, better resists entrainment.","code":""},{"path":"chapTappers2.html","id":"anticipation","chapter":"8 Two finger tappers","heading":"Anticipation","text":"Another useful term anticipation, anticipation bias subject. defined terms phase delay metronome:\\[\nA_{s1} = ds1m1\\\\\nA_{s2} = ds2m2\n\\]\nvalue phase delay parameter positive means anticipation, otherwise delay. Given context, anticipation expected line previous studies finger tapping (see chapter 2). Note also use phase delay partner, defined \\(ds1s2\\) \\(ds2s1\\). Due non-linearity equations, phase delays necessarily identical mainly used allow flexibility model.","code":""},{"path":"chapTappers2.html","id":"setup","chapter":"8 Two finger tappers","heading":"8.2 Setup","text":"now ready look tapping data experiment described Rosso et al. (2023). thereby limit uncoupled (U) coupled (C) conditions experiment.29The experimental setup implements drifting metronomes paradigm. uncoupled condition (U), subjects requested tap sync metronome heard headphones 600 ms 610 ms. coupled condition (C) subject 1 hears 600 ms sees hand subject 2, presumably tapping 610 ms, subject 2 hears 610 ms sees hand subject 1, presumably tapping 600 ms. creates incongruency subjects’ syncing may influenced seeing partner tapping.","code":""},{"path":"chapTappers2.html","id":"raw-tapping-data","chapter":"8 Two finger tappers","heading":"Raw tapping data","text":"Figure 8.1 shows raw tapping data dyads two conditions.\nfinger tap times subtracted metronome tick times, represented proportion metronome tick intervals giving phase. show (rotated) phase interval \\([-\\pi,+\\pi]\\).\nSubjects zero relative phase tap exactly time tick.\nFIGURE 8.1: Overview raw tapping data (represented relative metronome). horizontal axis time, vertical axis relative phase. (Top panel) Uncoupled condition (U). (Bottom panel) Coupled condition (C).\ntop panel gives rough idea subjects’ capabilities uncoupled condition. dots expected smoothly fluctuate around zero, bit lower due anticipation.However, dyads, subjects dyads, show rather extreme fluctuations suggesting de-sychronization metrome.\nexample, dyad_1 (subjects), dyad_6 (subject 1), dyad_14 (subject 2) show extreme fluctuation entire performance (10 cycles).\ndyad_4 seems subject 2 distracted cycle 6 couldn’t catch metronome later cycles.lower panel gives rough idea subjects’ capabilities coupled condition.\nexpect see change relative phase due dynamic adaption, ideal cases, structure less constrasting, dyad_12 dyad_20.However, panels show remarkable pattern, example dyad_8 cycles dyad_15 dyad_13, figure means.can squeeze cycles one single cycle shown figure 8.2.\ndyads seem entrain, despite request follow metronome. Apparently, dyad_9 can resist entrainment. Now see strange behavior subject 2 dyad_8 dyad_15 rather consistent. Dyad_13 similar, see happening subject 1, direction.deeper analysis needed get clearer view phenomena.\nFIGURE 8.2: Overview raw tapping data, squeezed one cycle, coupled condition (C).\nOverall, inspection raw data suggests interaction outcomes vary among dyads subjects within dyads behave differently. subjects capable sync metronome uncoupled condition, subjects apparently overwhelmed interaction coupled condition. ’s can say far.modelling want go step .\nexample, dyad cycle, want get dynamic parameters phase-functions see whether trend dyads. averaging dynamic parameters, can always generate corresponding phase-functions.","code":""},{"path":"chapTappers2.html","id":"smooth-regression-of-relative-phase","chapter":"8 Two finger tappers","heading":"Smooth regression of relative phase","text":"However, embark dynamic modelling, interest try good old smooth regression approach. give us smooth curve, capturing underlying dynamic tapping, similar smooth regression modelling used chapters 4 6?use following model specification:relphase relative phase subject metronome, subjectcondition interaction two subject two conditions, dyad:cycle group-level variable cycle per dyad, kappa second parameter von_mises model fitting function.Figure 8.3 shows smooth regression solution.\nRecall vertical axis relative phase horizontal axis time one cycle.\nfigure suggests flat line uncoupled condition (U) subjects.\ncontrast, figure shows curved lines coupled condition (C), suggesting entrainment.\ncurve asymmetrical sense delayed respect metronomes anti-phase point.\nMoreover, also observe anticipation sense curves zero.\nThanks explorations dynamic model previous chapter, meanwhile know works.\nFIGURE 8.3: Overview raw tapping data, squeezed one cycle, coupled condition (C).\nSmooth regression limitations mainly purely descriptive, based expansion data hyper-space spline functions. goal develop dynamic model replicate figure, using dynamic parameters can interpreted coupling strength phase delay.\nfact, result comes close , see figure XXXX.","code":""},{"path":"chapTappers2.html","id":"recurrence-analysis","chapter":"8 Two finger tappers","heading":"Recurrence analysis","text":"alternative approach processing tapping data based recurrence analysis (Rosso et al.,2023). analysis, phase sample time \\(\\phi_t\\) expanded phase vector, \\(d\\) delay \\(\\tau\\) defining expansion. :\\[\n\\hat{\\phi}_t = <\\phi_{t + (d-1)\\tau}>\n\\]\n\\(\\hat{\\phi}_t \\R^d\\) \n\\(d\\) estimated embedding dimension, \n\\(\\tau\\) estimated delay phases.time-delayed versions phase can thought coordinates point \n\\(d\\)-dimensional space.\nexample, choose \\(d=3\\) \\(\\tau=1\\), time-delayed versions phase time \\(t=1\\) \\(x(1),x(2)\\), \\(x(3)\\). three values can thought \\(x,y,z\\) coordinates point three-dimensional space.matrix \\(R_{t,s}^{d,\\tau}\\) defined \n\\[\nR_{t,s}^{d,\\tau} = \\Theta(\\epsilon - \\left\\| x_t - x_s \\right\\|), ~~~x_t \\R^d, ~~~t,s = 1, ..., T\n\\]\n\\(\\epsilon\\) threshold distance, \\(\\Theta\\) Heaviside function, \\(\\left\\| . \\right\\|\\) length vector difference, can interpreted phase difference, instantaneous frequency.\nmatrix contains \\(1\\) difference phase-vectors \\(x_t\\) \\(x_s\\) falls within ball defined \\(\\epsilon\\), \\(0\\) otherwise.Given matrix \\(R_{t,s}^{d,\\tau}\\), sum samples \\(t\\) results counts sample instance \\(s\\).\nAccordingly, resulting graph can interpreted histogram phase differences.joint recurrence analysis two subjects, figure 8.4, matrix first calculated subjects separately, giving \\(Rs1_{t,s}^{d,\\tau}\\) \\(Rs2_{t,s}^{d,\\tau}\\), whose notation can simplified \\(Rs1\\) \\(Rs2\\).Taking intersection \\(Rs1 \\cap Rs2\\) (cells \\(1\\) \\(Rs1\\) \\(Rs2\\) \\(1\\), \\(0\\) otherwise) summing rows, obtain histogram represents instantaneous frequency difference among subjects. Figure 8.4 10 cycles, 19 dyads folded one single cycle.Figure 8.4 (Rosso et al., 2023) shows result dyads, time series squeezed one cycle. figure histogram, shows number times two subjects phase difference (tolerance \\(\\epsilon\\)) time, within time interval corresponding bin.\ntwo subjects different instantaneous frequencies, synchronization two subjects unstable. frequency differences vary time, peaks histogram wider.\nFIGURE 8.4: Recurrence analysis. blue lines considered. show uncoupled (1P Uncoupled) coupled (2P Coupled) conditions.\nRecurrence analysis limitations mainly purely descriptive doesn’t capture parameters dynamic model. Likewise, goal develop dynamic model replicate figure, using dynamic parameters can interpreted coupling strength phase delay.\nAlso , result comes close , see figure XXXX.","code":""},{"path":"chapTappers2.html","id":"data-from-dynamic-model","chapter":"8 Two finger tappers","heading":"8.3 Data from dynamic model","text":"get figures?\nnow proceed analysis based dynamic model.\nRecall configuration figure 7.2.\nMoreover, apply configuration interaction conditions U C.\nrequires word explanation using dynamic system configuration conditions implies test modelling.Given fact interaction \\(s1\\) \\(s2\\) non-existing uncoupled condition (U), model find interaction. interactions found spurious accidental patterns subjects deviate tapping task. Overall can therefore expect adherence metronome close 1, subject asked sync metronome doesn’t see anybody else tapping. influence detected, ’s spurious influence.","code":""},{"path":"chapTappers2.html","id":"modelling-with-stan","chapter":"8 Two finger tappers","heading":"Modelling with Stan","text":"modelling Stan exactly previous chapter, follows logic Block 3, shown figure\n7.1.\nAccordingly, estimated parameters 380 dynamic systems, one dynamic system performance, given condition (n=2), dyad (n=19), cycle (n=10).outcome time consuming calculation parameter dataset, shown Table 8.1.\nlabels value parameter refer values parameters, , coupling strength phase delay. point important realize set six parameters (two coupling strength four phase delay parameters) define phase-functions units defined dynamic system configuration.\nTABLE 8.1: Dataset parameters, dynamic models fitteed tapping data\n[[[[[\nfollows, work models \\(Rhat > 1.05\\) parameters30.\nUsing criterium, found 6.8% models fully converge.\nfollows, work fully converged models, 354 fitted 380 models.\nTABLE 8.2: Dataset parameters, dynamic models fitteed tapping data\n]]]]","code":""},{"path":"chapTappers2.html","id":"global-histograms","chapter":"8 Two finger tappers","heading":"Global histograms","text":"Let’s look parameter dataset.\nfirst thing can plotting histograms coupling strength phase delays.\nFIGURE 8.5: Histograms parameter dataset. Left panel coupling strength values; middle panel phase delay metronome; right panel phase delay partner\nFigure 8.5 (top panel) suggests dynamic models captured adherence-coupling strength uncoupled condition (U) line expectations, although performances show adherence-coupling strength < .7, considered poor.\nadherence-coupling strength coupled condition (C) shows variability, suggesting subjects influenced seeing partner tapping, values way .5, suggesting loss adherence, meaning partner followed instead metronome. also coupling strengths close 1, suggesting influence neglected.Figure 8.5 (middle panel) shows phase delays metronome, suggesting anticipation variance coupled condition.\nFinally, figure 8.5 (bottom panel) shows phase delays partner.\nmean values around zero, although slightly zero coupled zero uncoupled condition. variance uncoupled condition higher.summary found table @ref(tab:chapTappers2_parmsMeanStd), mean standard deviation per parameter per condition.\n(#tab:chapTappers2_parmsMeanStd)Summary parameters\n","code":"## `summarise()` has grouped output by 'condition'. You can override using the\n## `.groups` argument."},{"path":"chapTappers2.html","id":"histograms-uncoupled-condition-u","chapter":"8 Two finger tappers","heading":"Histograms uncoupled condition (U)","text":"can take detailed view dataset parameters.\n\nFigure 8.6 (top panel) shows posterior distributions retained models terms median \\(.25/.75\\) quantiles cycles, figure 8.6 (bottom panel) shows summary cycles.\ncan done delay parameters, shown figure 8.7.\nFIGURE 8.6: Estimated coupling strength uncoupled condition (U), (top panel) cycles, (bottom panel) summary cycles\n\nFIGURE 8.7: Estimated phase delay uncoupled condition (D), (top panel) cycles, (bottom panel) summary cycles\nFigure 8.6 reveals coupling strength mostly close one, expected due fact subjects don’t see . Also, almost models converged, except cycle 10 dyad_1 dyad_14.Figure 8.7 reveals phase delay metronome mostly zero. However, considerable differences subjects within dyads.\nreally low adherence-coupling values can observed, suggesting entrainment-coupling, dyad_1-6-14. looking phase delays, also see variability cycles dyads.Obviously, uncoupled condition (U), subjects don’t see , entrainment captured model spurious entrainment. reason can loss attention inability tap accurately.","code":""},{"path":"chapTappers2.html","id":"histograms-coupled-condition-c","chapter":"8 Two finger tappers","heading":"Histograms coupled condition (C)","text":"next figures 8.8 8.9 show coupling strength delay parameters uncoupled condition U.\nFigure 8.8 reveals average coupling strength somewhere .5 1, suggesting entrainment. notice models converge, cycle_1, cycle_2, cycle_9 dyad_1, well dyads (see table 8.2).\nFIGURE 8.8: Estimated coupling strength coupled condition (C)\nFigure 8.9 reveals coupling delay zero, cycles consistent dyads others.\nFIGURE 8.9: Estimated phase delay coupled condition (C)\n","code":""},{"path":"chapTappers2.html","id":"leader-follower","chapter":"8 Two finger tappers","heading":"Leader-follower","text":"Based parameter dataset possible get view leader-follower relationship.\nFigure 8.9 reveals uncoupled condition U coupled condition C show normal distribution around zero, mean standard deviation -0.03 (0.1) U 0.06 (0.3) C. Recall zero means subject 1 leading, zero subject 2 leading.\nFIGURE 8.10: Leader-folllower values. zero means subject 1 leading, zero: subject 2.\nNote leader-follower relation (LF) difference based adherence coupling strength subjects dyad, value doesn’t capture whether subjects good performance.\nexample, know coupling strength values dyad_1 low subjects,\ndifference small subjects low values.Overall, standard deviation three times larger C, meaning due entrainment larger variability leader-follower relationships.\nLF values C pronounced U.\nexample, dyads 8, 14, 15, 17 19, values mostly positive, whereas dyads 9, certainly 13, values mostly negative, meaning subjects become consistent leader follower cycles, due entrainment!\nslight bias towards positive interesting suggests \\(s1\\) advantage compared \\(s2\\).","code":""},{"path":"chapTappers2.html","id":"plots-of-dynamic-models","chapter":"8 Two finger tappers","heading":"Plots of dynamic models","text":"now go deeper phase-functions generated dynamic models considering instantiations phase-functions relative phase instantaneous period representations.\\(k\\) high adherence, \\(\\hat{\\phi}\\) fluctuating along straight horizontal line, whose distance metronome depends \\(d\\). example, top panel figure 8.11 shows high adherence \\(ks1m1 = 0.84\\) \\(ks2m2 = 0.96\\) (summarized \\(k=0.84,0.96\\) figure) anticipative bias: \\(ds1m1 = 0.49[rad], ds1s2 = 1.37\\) \\(ds2m2 = 1.02[rad], ds2s1 = -0.58\\) (summarized \\(d=0.49,1.37, 1.02, -0.58\\) figure). uncoupled condition (U), lines straight, see small bias subject 1, captured model spurious interaction.anticipative bias can observed left panel, zero. .5 \\(s1\\) 1.02 \\(s2\\).\nbottom panel shows instantaneous period.figures can generated http://odetappers.shinyapps.io/odetappers2/.\nFIGURE 8.11: Estimated phase delay coupled condition (C), dyad 9, cycle 8\nFigure 8.12 shows phase-functions dyad_2 cycle_6, randomly selected demonstrate coupled condition (C). Now \\(k=0.57,0.42\\) \\(d=0.6,0.16,-0.63,0.13\\). instantaneous phase reveals \\(s2\\) frequency rather close \\(m1\\), least first part outphasing-inphasing cycle.\nFIGURE 8.12: Estimated phase delay coupled condition (C), dyad 2, cycle 6\nextreme example asymmetric entrainment shown figure 8.13.\nperformance, \\(s2\\) almost completely following \\(s1\\). instantaneous period \\(s2\\) becomes almost equal instantaneous period \\(s1\\).\nFIGURE 8.13: Estimated phase delay coupled condition (C), dyad 8, cycle 8\ntapping data contain lot fluctuation, irregularities, may difficult find proper solution . Consider example Figure 8.14.\nsolution difficulties beginning cycle.\nsudden jump offers problem reflects circularity data.\nHowever, problem start tapping.\nfailure model capture tapping start may due priors starting value.\npriors constrained around zero (see previous chapter).\nmodel thus assumes start around zero, around 2 -2.\nFIGURE 8.14: Estimated phase delay coupled condition (C), dyad 1, cycle 5\n","code":""},{"path":"chapTappers2.html","id":"regression-2","chapter":"8 Two finger tappers","heading":"8.4 Regression","text":"data visualization figure 8.5 suggested difference conditions.\nregression model can estimate means accurately.\nmodel parameter response \ncondition (U, C) names (\\(s1\\) \\(s2\\)) predictors, dyad:cycle group-level predictor.\nlatter implies cycles within dyad modeled random variable.","code":""},{"path":"chapTappers2.html","id":"syntax-specification","chapter":"8 Two finger tappers","heading":"Syntax specification","text":"coupling strength parameters, beta link function can used, flat priors.\nalso check whether mixture beta functions actually work better distributional model (form_K02).\nThus syntax two models specified :first model distributional model mean variance fitted. second model also distributional model based mixture beta functions. Accordingly two means variances fitted. models can compared using loo_compare() checks log pointwise predictive density two models (elpd_diff). higher value indicates model K02 better predicting data.phase delays use similar model assuming gaussian distribution.","code":"\n  form_K00 = bf(parameter ~ condition * names + ( 1 + condition * names| dyad:cycle),\n     phi ~ condition * names + ( 1 +condition * names | dyad:cycle))\n  \n  form_K02 = bf(parameter ~ 1,\n               mu1 ~ condition * names + (1 | dyad:cycle),\n               mu2 ~ condition * names + (1 | dyad:cycle),\n               phi1 ~ condition * names + (1 | dyad:cycle),\n               phi2 ~ condition * names + (1 | dyad:cycle))Model comparisons:\n        elpd_diff se_diff\nfit_K02   0.0       0.0  \nfit_K00 -63.3      12.7 \n  form_D00 = bf(parameter ~ condition * names + ( 1 | dyad:cycle),\n                sigma ~ condition * names + ( 1  | dyad:cycle))"},{"path":"chapTappers2.html","id":"results","chapter":"8 Two finger tappers","heading":"Results","text":"Figure 8.15 shows posterior predictions coupling strength phase delay parameters.\nFIGURE 8.15: Estimated parameters per condition, excluding group effects cycle dyad. (Top panel) Coupling strength. (Bottom panel) Phase delay.\nTable 8.3 shows summary parameters.\n’ll need plug dynamic equations.\nTABLE 8.3: Estimated phase delay per condition\n","code":""},{"path":"chapTappers2.html","id":"contrasts-3","chapter":"8 Two finger tappers","heading":"Contrasts","text":"far contrasts concerned, mainly interested constrast coupling strength parameters. Although contrast rather evident figure 8.15, summarize explicit contrast test \ntable 8.4.\nTABLE 8.4: Estimated coupling strength per condition, excluding group effects cycle dyad. column names d1 d2 show means two distributions, d12 shows mean difference, min max, pd probability direction dicated Hyp\n","code":""},{"path":"chapTappers2.html","id":"estimating-coupling-strength-per-dyad","chapter":"8 Two finger tappers","heading":"Estimating coupling strength per dyad","text":"can go details estimate coupling strength parameters per dyad.\ncan done averaging cycles.\nFigure 8.16 based repression model per dyad, extract mean CI-95% per subject condition. Now get rather clear picture estimated adherence-entrainment dyad.red line marks value 0.765, obtained taking lower bound 75% estimated mean coupling strength values uncoupled condition (U). line, one say spurious entrainment effect.looking coupled condition (C), argue line, subjects don’t entrain.\nDyad_9 pops dyad subjects don’t entrain. fact, far best dyad task non-entrain dyad succeeded. dyads one two subjects couldn’t resist influence seeing partner tapping.\nDyad_8 one one subjects doesn’t entrain subject fully entrained.\nFIGURE 8.16: Estimated coupling strength per dyad\nsimilar way, phase delays can calculated per dyad. like generate phase functions per dyad need . However, limit generating phase functions entire dyad population.","code":""},{"path":"chapTappers2.html","id":"generating-phase-functions","chapter":"8 Two finger tappers","heading":"Generating phase functions","text":"interested coupled condition (C) plug associated coupling strength values table 8.4 (\\(ks1m1\\) \\(ks2m2\\)) dynamic equations defined previous chapter. shown .\nFIGURE 8.17: Generated phase-functions average dyad interaction. (Top panel) Relative phase. (Middle panel) Instantaneous frequency. (Bottom panel) instantaneous frequency difference\nresults shown figure 8.17.\ntop panel shows relative phase representation, similar figure 8.3.\nmiddle panel shows instantaneous frequency.\nbottom panel shows instantaneous frequency difference, similar blue curved line figure 8.4.Recall model assumes starting position tapping close zero.\nActually, applies first cycle experiment subsequent cycles start phase obtained first cycle, phase necessarily zero.\nreason, may interest generate two subsequent cycles.","code":"\ndydt <- function(t, y, parms) {\n  with(as.list(c(y, parms)), {\n    dm1 = 2*pi*1000/600\n    ds1 = 2*pi*1000/600  + \n      .5*(ks1m1* sin(m1 - s1 + ds1m1) + \n            (1-ks1m1)* sin(s2 - s1 + ds1s2) )\n    \n    dm2 = 2*pi*1000/610\n    ds2 = 2*pi*1000/610  + \n      .5*(ks2m2* sin(m2 - s2 + ds2m2) + \n            (1-ks2m2)* sin(s1 - s2 + ds2s1) )\n    return(list(c(dm1,ds1,dm2,ds2)))\n  })\n}\n\ndt = 1/100\ntime_points <- seq(0, 36.6, by = dt)\nstate <- c(m1 = 0, s1 = 0, m2 = 0, s2 = 0)\n\n# plug in the estimated parameter values here:\nparm = c(ks1m1 = 0.6870682, ks2m2 = 0.5896415, \n         ds1m1 = 1.0933175, ds2m2 = 0.9126510, \n         ds1s2 = -0.3637655, ds2s1 = -0.0205270)\n\nsolution <- ode(y = state, times = time_points, func = dydt, parms = parm) %>% \n  data.frame()\nsolution <- solution %>% mutate(\n  dm1 = c(NA,diff(m1)),\n  ds1 = c(NA,diff(s1)),\n  dm2 = c(NA,diff(m2)),\n  ds2 = c(NA,diff(s2))\n)\n\ndo_rotate <- function(value){\n  return =  (value + pi)%%(2*pi)-pi\n}\n\np0 <- solution %>% group_by(time) %>% ggplot() +\n  geom_line(aes(x= time,y = do_rotate(m1-s1)), color=\"#56B4E9\",size=1) +\n  geom_line(aes(x= time,y = do_rotate(m2-s2)), color = \"#E69F00\",size=1) +\n  ylim(-pi,pi) +\n  theme_bw() +\n  labs(x=\"time of one cycle\", y = \"rel. phase\") +\n  labs(y=\"relative phase\")\n\np1 <- solution %>% group_by(time) %>% ggplot() +\n  geom_line(aes(x= time,y = ds1),color=\"#56B4E9\",size=1) +\n  geom_line(aes(x= time,y = ds2),color = \"#E69F00\",size=1) +\n  geom_vline(xintercept = 36.6/2, color = \"#D55E00\", linetype = \"dotted\") +\n  labs(x=\"time of one cycle\", y = \"inst. frequency\") +\n  #ylim(585,635) +\n  theme_bw() \n\np2 <- solution %>% group_by(time) %>% ggplot() +\n  geom_line(aes(x= time,y = ds2 - ds1),color = \"black\",size=1, linetype = \"dotted\") +\n  geom_vline(xintercept = 36.6/2, color = \"#D55E00\", linetype = \"dotted\") +\n  labs(x=\"time of one cycle\", y = \"freq difference\") +\n  theme_bw() \n\np0 / p1 / p2\n# \\@ref(fig:chapTappers2dynEq2)"},{"path":"chapTappers2.html","id":"summary","chapter":"8 Two finger tappers","heading":"Summary","text":"summarize obtain result, started discrete dyadic tapping data 380 performances, estimated parameters dynamical system. worked models converged Stan engine dynamic models perform calculation.Using estimated parameters can generate continuous functions fit discrete tapping data. functions can also generated using averages parameters, ’s figure @ref(fig:chapTappers2_dynEq2). phase-functions can represented relative phase, instantaneous frequency instantaneous period Finally, can produce instantaneous frequency difference. functions represent average dyads, show high similarity smooth regression solutions recurrence analysis performed entire population.hypothesis uncoupled condition (U) higher adherence coupling strength coupled condition (C) confirmed, showing contrast (U > C) 23% (see d12 table 8.4). adherence coupling strength uncoupled condition close \\(ks1m1 = .86\\) \\(ks2m2 = .87\\), coupled condition close \\(ks1m1 = 0.69\\) \\(ks2m2 =  0.59\\).\nresult implies two subjects coupled seeing tapping, dramatic reduction 1/4 adherence coupling strength, despite request adhere metronome. implies considerable entrainment coupling strength (defined \\(1-k\\)) subject.Apparently, average (dyads) subject \\(s2\\) lower coupling strength 10% metronome \\(m2\\), compared \\(s1\\) \\(m1\\) coupled condition (C).\nuncoupled condition (C), coupling strength \\(k\\) exactly 100%, meaning spurious entrainment detected due fluctuation tapping. , difference exists \\(s1\\) \\(s2\\).\nTherefore, plausible coupled condition (C), \\(s1\\) advantage due tapping speed.","code":""},{"path":"chapTappers2.html","id":"conclusion-7","chapter":"8 Two finger tappers","heading":"8.5 Conclusion","text":"chapter, explored synchronized finger tapping can entrained seeing partner tapping differently. fact non-voluntary entrainment can override intended audio-based synchronization shows entrainment extremely powerful phenomenon.Apparently, entrainment hard resist. seems brain determined solve incongruent feedback, degree resistance entrainment might require specific training targetted neglecting cause incongruency.Entrainment believed play crucial role activities require joint collaboration, music playing. context, entrainment added value dynamic adaptation activities. Entrainment fits well idea self-augmented interaction, can seen facilitator stirrs interaction.showed entrainment can understood, basically, control competing dynamic forces, informed hearing (voluntary) seeing (non-voluntary). Statistical modeling helped us capture entrainment holistically, , parameters (coupling strength phase delay) dynamic system describes causal flow timing. ends journey non-linear regression.","code":""},{"path":"chapConclusion.html","id":"chapConclusion","chapter":"9 Conclusion","heading":"9 Conclusion","text":"book, two parallel pathways mutually support : theory modelling.\nbriefly overview main findings.","code":""},{"path":"chapConclusion.html","id":"contribution-to-theory","chapter":"9 Conclusion","heading":"9.1 Contribution to theory","text":"Music interaction primarily studied viewpoint timing, dancers, violin players finger tappers.\nTiming clearly involves subconscious processing, sensorimotor adaptation structure dancing, sensorimotor feedback based parallax modality effectiveness, last least, entrainment mutual adaptation finger tapping interactions.phenomena can related predictive processing, embodiment expression individual subjects, seems reductionist understanding insufficient. order understand music interaction, also need holistic understanding level dynamic system multiple interacting units. showed timing-related emerging effects interacting units can based phase flow among interacting units.However, also assume states emerging embodied interactions, affect brain processing, plausibly related dynamic interactions brain regions. didn’t address book ’s super-cool assumption, albeit speculative, fact brain engages interactions among neurons augment . Another super-cool assumption certain interaction states empowering effect individual.main hypothesis self-augmented interaction states fact overall dynamic concept covers assumptions. end book, claim proven , evidence explorations hypothesis. fact, evidence explorations support hypothesis. example, entrainment indeed facilitates collaboration makes easier co-regulate actions view common goal.However, major difficulty studying self-augmented interaction states concerned generating states laboratory setting. challenge future research clever paradigms needed generate interaction states controlled conditions.","code":""},{"path":"chapConclusion.html","id":"contribution-to-modelling","chapter":"9 Conclusion","heading":"9.2 Contribution to modelling","text":"focused behavior timing, explored use different modelling techniques based regression, umbrella global Bayesian epistemologic paradigm.showed curve fitting interesting modelling technique capturing assumed underlying process. regression based smooths, data expanded larger space defined functions (splines) modelling fits data combinations functions, obtain weights functions. regression based dynamic system, fit data functions generated dynamic system, obtain parameters represent functions. approach powerful parameters express causal components understanding.word said datasets modern musicology.\nDatasets contain data multiple modalities, auditory, visual, tactile, haptic sensing, well body movement, brain activity, questionnaires.\ndata come different media, \nrecording devices audio video, motion capture systems, EEG brain scan devices.Furthermore, data high-dimensional. Apart high resolution time space – speak milliseconds millimeter ranges – modality may involve different markers sensors: full-body motion tracking requires easily >30 markers. EEG cap may 64 electrodes. Audio can measured multiple microphones . fine-resolution spatiotemporal data thus get multiplied number markers /sensors. require perfect synchronization different measuring devices involved.","code":""},{"path":"chapConclusion.html","id":"our-limitations","chapter":"9 Conclusion","heading":"9.3 Our limitations","text":"book modest attempt explore music interactions. reached end, feel just started understanding little pieces, even little pieces understanding suffer limitations.Firstly, focus primarily revolved around behavioral data analysis using regression techniques, neglected promising advancements neurobiology neuroscience, well availability high-dimensional data (including EEG types body sensing).Secondly, controlling variables data collection, potentially compromised ecological validity music interactions. use specific technologies augmented reality (e.g. hololens), haptic connection (e.g. exoskeletons) allow unique control action-perception loops governing interactions, confronted question self-augmented interaction states can controlled, even important, perhaps, can sure human really experiencing self-augmented interaction state. Apparently, lot variability humans engage mutual interactions, facilitated music.Lastly, provide exhaustive account statistical modeling techniques. Rather, focused selected range methods, primarily regression-based, deemed relevant understanding data music interactions. hope listeners can appreciate fact music research deals small datasets, subtle effect sizes, considerable uncertainty stemming complexities natural music interaction contexts.","code":""},{"path":"chapConclusion.html","id":"outlook","chapter":"9 Conclusion","heading":"9.4 Outlook","text":"exploration music interaction R, mainly based regression modelling, turned useful connecting theory data.\nOverall, insights obtained explorations suggest timing key feature music interaction. draw discourse close, worth reiterating immense challenge better understanding dynamics underlies music-based transformative powers.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"Bader, R. (Ed.). (2018). Springer handbook systematic musicology. Springer.Bonicco-Donato, D. (2016). Une archéologie de l’interaction. De David Hume à Erving Goffman. Paris: Vrin.Bürkner P. C. (2021). Bayesian Item Response Modelling R brms Stan. Journal Statistical Software. doi:10.18637/jss.v100.i05Bürkner P. C. (2018). Advanced Bayesian Multilevel Modeling R Package brms. R Journal. doi:10.32614/RJ-2018-017Bürkner P. C. (2017). brms: R Package Bayesian Multilevel Models using Stan. Journal Statistical Software. doi:10.18637/jss.v080.i01Campo, ., Michałko, ., Van Kerrebroeck, B., Stajic, B., Pokric, M., Leman, M. (2023a). assessment presence performance AR environment motor imitation learning: case-study violinists, Computers Human Behavior, Volume 146, 2023, 107810, ISSN 0747-5632, https://doi.org/10.1016/j.chb.2023.107810.Campo, ., Michałko, ., Van Kerrebroeck, B., Leman, M. (2023b).\nDataset assessment presence performance augmented reality environment motor imitation learning: case-study violinists. Data Brief 51 109663.\nhttps://10.1016/j.chb.2023.107810Campo,., Van Kerrebroeck, B., Leman, M. (2024).\nMC-AR — software suite comparative mocap analysis augmented reality environment\nSoftware Impacts 19 100605. https://doi.org/10.1016/j.dib.2023.109663.Carpenter, B. (2018). Predator-Prey Population Dynamics:\nLotka-Volterra model Stan.\nhttps://mc-stan.org/users/documentation/case-studies/lotka-volterra-predator-prey.htmlClayton, M., Sager, R., & , U. (2005). time music: concept entrainment significance ethnomusicology. European meetings ethnomusicology.(Vol. 11, pp. 1-82). Romanian Society Ethnomusicology.Collins, T., Tillmann, B., Barrett, F. S., Delbé, C., & Janata, P. (2014). combined model sensory cognitive representations underlying tonal expectations music: audio signals behavior. Psychological review, 121(1), 33.Demos, . Palmer, C. (2023).\nSocial nonlinear dynamics unite: musical group synchrony,\nTrends Cognitive Sciences. https://doi.org/10.1016/j.tics.2023.05.005Dunn, P. Smyth, G. (2018). Generalized linear models examples R. New York: Springer.Gelman, ., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, ., & Rubin, D. B. (2014). Bayesian Data Analysis (3rd ed.). CRC Press.Gesmann, M., Morris, J. Hierarchical Compartmental Reserving Models. Casualty Actuarial Society, CAS Research Papers, 19 Aug. 2020, https://www.casact.org/sites/default/files/2021-02/compartmental-reserving-models-gesmannmorris0820.pdfKruschke, J. K. (2015). Bayesian Data Analysis: Tutorial R, JAGS, Stan (2nd ed.). Academic Press.Langner, G. D. (2015). neural code pitch harmony. Cambridge University Press.Leman, M. (2007). Embodied music cognition mediation technology. MIT press.Leman, M. (2016). expressive moment: interaction (music) shapes human empowerment. MIT press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press. See https://github.com/rmcelreath/stat_rethinking_2020.Repp, B., Su, YH (2013). Sensorimotor synchronization: review recent research (2006–2012). Psychonomic Bulletin & Review 20, 403–452. https://doi.org/10.3758/s13423-012-0371-2Reybrouck, M., & Van Dyck, E. (2024). music drug? music listening may trigger neurochemical responses brain. Musicae Scientiae, 0(0). https://doi.org/10.1177/10298649241236770Roback, P. Legler, J. (2021). Beyond multiple linear regression. Applied generalized liear models multilevels models R. CRC press. See https://bookdown.org/roback/bookdown-BeyondMLR/Robbins, T, Everitt, B, Nutt, D. (2010). neurobiology addiction. Oxford University Press.Rosso, M., Maes, P.J. & Leman, M. (2021). Modality-specific attractor dynamics dyadic entrainment. Sci Rep 11, 18355. https://doi.org/10.1038/s41598-021-96054-8Rosso, M., Van Kerrebroeck, B., Maes, P-J & Leman, M. (2023). Embodied perspective taking enhances interpersonal synchronization. body-swap study. iScience. (accepted)Rosso, M., Maes PJ. & Leman, M. (preparation). (Tentative title) Estimating coupling phase delay parameters entrainment body-swap study.Schneider, . (2018a). Pitch pitch perception. Springer Handbook Systematic Musicology (pp. 605-686). Springer, Berlin, Heidelberg.Schneider, . (2018b). Perception timbre sound color. Springer Handbook Systematic Musicology (pp. 687-725). Springer, Berlin, Heidelberg.Sears, D. R., Pearce, M. T., Spitzer, J., Caplin, W. E., & McAdams, S. (2019). Expectations tonal cadences: Sensory cognitive priming effects. Quarterly Journal Experimental Psychology, 72(6), 1422–1438. https://doi.org/10.1177/1747021818814472Seth, . K. (2015). cybernetic Bayesian brain - interoceptive inference sensorimotor contingencies.\nT. Metzinger & J. M. Windt (Eds). Open MIND: 35(T). Frankfurt Main: MIND Group. doi: 10.15502/9783958570108Singer, J. Willett, J. (2003). Applied longitudinal data analysis. Modeling change event occurrence. Oxford University Press.Talebi, M. , Campo, ., Aarts, N. & Leman, M. (2023).\nInfluence musical context sensorimotor synchronization classical ballet solo dance. Plos one 18 (4), e0284387.\nhttps://doi.org/10.1371/journal.pone.0284387Trost, W. J., Labbé, C., & Grandjean, D. (2017). Rhythmic entrainment musical affect induction mechanism. Neuropsychologia, 96, 96-110.Vuust, Peter & Heggli, Ole & Friston, Karl & Kringelbach, Morten. (2022). Music brain. Nature Reviews Neuroscience. 23. 10.1038/s41583-022-00578-5.","code":""}]
