[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"online home Exploring music interactions, book musical data analysis, visualization modeling.Data code provided soon.\ncomments can send Marc.Leman@ugent.","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"preface.html","id":"description","chapter":"Preface","heading":"Description","text":"","code":"\nsource(\"Code/chapAll_00_Initialization.R\")"},{"path":"preface.html","id":"goal","chapter":"Preface","heading":"Goal","text":"Many people experience music positive force lives. people music, affect ? probably based precarious interaction states high value, refer “self-augmented interactions.”book, delve deeper self-augmented interactions. goal show statistical modeling can increase understanding self-augmented interactions.research focuses musical domain, applies many domains human interactive activity, conversations, sports, teamwork.\nstudy interactions rather new calls explorative approaches.\nHence book.\nhope can interest readers inside outside field music research.","code":""},{"path":"preface.html","id":"limitations","chapter":"Preface","heading":"Limitations","text":"Every book limitations, important transparent outset.First, focus exclusively behavioral data. recognize importance neurobiology, focus lies behavioral data. hope others build work incorporating neurobiological data fully support theoretical claims.Second, analysis behavioral data, focus primarily timing. Specifically, examine people act time one another, music playing dancing. chose focus timing crucial building maintaining interactions, music provides excellent domain understanding self-augmented interactions.Third, book textbook, rather guide navigating space theory data. exploring music interactions, acknowledge research area still infancy.Finally, book applications technologies, although personally interested biofeedback applications. data collected using technologies augmented reality, virtual reality, exoskeletons, delve deeply topics.Given limitations, , limited capacities musicologists, offer book open contribution field. welcome suggestions improvement readers.","code":""},{"path":"preface.html","id":"overview","chapter":"Preface","heading":"Overview","text":"\nTable 0.1: Overview chapters\nTable 0.1 gives overview chapters.first two chapters theory methodology. Chapter 1 introduces theory self-augmented interactions Bayesian perspective developed subsequent chapters.\nChapter 2 introduces regression modelling main analysis tool.first two chapters theory methodology. Chapter 1 introduces theory self-augmented interactions Bayesian perspective developed subsequent chapters.\nChapter 2 introduces regression modelling main analysis tool.Chapter 3 accesses listener’s music appreciation using questionnaires. chapter shows questionnaires used structural equation model validating theory appreciation. chapter timing.Chapter 3 accesses listener’s music appreciation using questionnaires. chapter shows questionnaires used structural equation model validating theory appreciation. chapter timing.Chapter 4 shows synchronization movement music can influenced narrative defines classical ballet dancing. chapter applies circular-linear smooth regression approach contrast musical phrases selected time.Chapter 4 shows synchronization movement music can influenced narrative defines classical ballet dancing. chapter applies circular-linear smooth regression approach contrast musical phrases selected time.Chapter 5 effect parallax, using 3D versus 2D music play-along system violin, training synchronized bowing gestures orchestra. reduces bowing gesture discrete events applies regression way similar previous chapter, including approach contrast musical phrases.Chapter 5 effect parallax, using 3D versus 2D music play-along system violin, training synchronized bowing gestures orchestra. reduces bowing gesture discrete events applies regression way similar previous chapter, including approach contrast musical phrases.Chapter 6 effect auditory, visual haptic modalities synchronized playing two violinists, connected via exoskeletons. go deeper feature extraction use regression categorical predictors.Chapter 6 effect auditory, visual haptic modalities synchronized playing two violinists, connected via exoskeletons. go deeper feature extraction use regression categorical predictors.Chapters 7 8 synchronized finger tapping.\nchapters, develop state-space model phase flow among interacting units described ordinal differential equations. use predictor regression capture entrainment coupling strength. chapters bit advanced show type non-linear regression powerful promising future work field.Chapters 7 8 synchronized finger tapping.\nchapters, develop state-space model phase flow among interacting units described ordinal differential equations. use predictor regression capture entrainment coupling strength. chapters bit advanced show type non-linear regression powerful promising future work field.brief concluding chapter 9 offers perspectives future work field.brief concluding chapter 9 offers perspectives future work field.","code":""},{"path":"preface.html","id":"usage","chapter":"Preface","heading":"Usage","text":"recommended first read chapters theory methodology.\noffer overall theoretical methodological framework subsequent chapters.\nChapter 7 chapter 8 closely related can best read order.\nchapters can read order reader’s preference.book organized reader can easy access code R Stan.\nReference code scripts given beginning chapter.\nreference parts code specified text.\nchapter follow logic: first data preparation data plotting, modelling plotting modelling outcomes, contrast testing sometimes plotting tests. try maintain logic much possible reflects workflow statistical modelling well structure chapter.access code use file name convention whose form X_Y_Z.R:X indicates shortname chapter, chapListener, chapDancer. names shortcuts full chapter names.X indicates shortname chapter, chapListener, chapDancer. names shortcuts full chapter names.Y sequence number, 02, O3, indicates order script processed.Y sequence number, 02, O3, indicates order script processed.Z processing name, Initialization, DataPreparation, DataPlotting, Modelling, indicates kind processing dealt .Z processing name, Initialization, DataPreparation, DataPlotting, Modelling, indicates kind processing dealt ..R just extension indicate fact file pure R-script. one point use .san specify Stan-script..R just extension indicate fact file pure R-script. one point use .san specify Stan-script.example, filename chapListener_02_DataPreparation.R R-script data preparation chapter listener. ’s sequence number 02 suggests 01, even 00 script executed first.\nscript chapListener_05_ModelPlotting.R plotting results modelling. executed running modelling script script_chapListener_04_Modelling.R. script requires least scripts 00, 01, 02 03 considered well.scripts run chapters called: chapAll_00_Initialization.R chapAll_01_Functions.R.","code":""},{"path":"preface.html","id":"level","chapter":"Preface","heading":"Level","text":"word said level book.\nwritten MA-students, PhD-students, interested researchers, don’t offer didactical approach scratch. Instead, level statistics knowledge might required order able read book, code particular.\nHowever, self-learning can largely profit explorations code provided.\nmay find example code developing explorations.","code":""},{"path":"preface.html","id":"our-inspiration","chapter":"Preface","heading":"Our inspiration","text":"Much statistical inspiration comes McElreath (2020), Kruschke (2015), Gelman et al. (2014). useful consult books regression, example, Roback Legler (2021), Singer Willet (2003), Dunn Smyth (2018), well book structual equation modelling (Bollen, 1989).","code":""},{"path":"preface.html","id":"setting-up","chapter":"Preface","heading":"Setting up","text":"use R several R-packages RStudio. get initialized Code/chapAll_00_Initialization.R. sure packages installed system.\ninstallation R package rstan, interface Stan probabilistic programming language, also required R package brms. recommend look Stan documentation follow link RStan documentation.statistical modelling can computational intensive, intensive.\noffer fitted models think computation intensive ordinary laptop.server disposal used parallel processing.\nserver runs R version 4.2.3 (2023-03-15) R-Studio Server 2023.03.0 build 386 Ubuntu 22.04.2 LTS. hardware consists dual AMD Epyc 74F3 CPU (48 cores total, 96 threads), 128 GB (8x16GB) ECC DDR4 RAM Nvidia RTX 3090TI graphics card.","code":""},{"path":"preface.html","id":"finding-sources","chapter":"Preface","heading":"Finding sources","text":"Sources found Data/, Code/, Figures/, Fitted/, subdirectories main directory chapters exist formatted text R markdown files (.Rmd).\ntry things R, code found Code/, data Data/. larger pre-processed models used, ’ll find Fitted/. also use Fitted/ subdirectory storing calculated models, Figures/ store calculated figures. Sometimes use Data/ store calculated data.","code":""},{"path":"preface.html","id":"about-the-author","chapter":"Preface","heading":"About the author","text":"Marc Leman emeritus professor Ghent University, specialized epistemology methodology music research. served Methusalem research professor, head department Art History, Teater Studies, Musicology, founder ASIL.","code":""},{"path":"preface.html","id":"acknowledgements","chapter":"Preface","heading":"Acknowledgements","text":"work supported Methusalem grant Ghent University, grant number 01M00208, BOF UGent.","code":""},{"path":"chapTheory.html","id":"chapTheory","chapter":"1 Theory","heading":"1 Theory","text":"assumptions – call hypotheses – tested book refer theory music interaction. theory based something grandmothers told us1, namely achieve something life, improve physical effort endurance.Applied music, means need alert active engagement gain something music, feeling beauty power. Musicians may recognize ; good performances build precision focus.Now, chapter attempt reformulate grandmothers’ advice perspective modern music research.","code":""},{"path":"chapTheory.html","id":"self-augmented-interactions","chapter":"1 Theory","heading":"1.1 Self-augmented interactions","text":"book, assume people urge engage particular interactions music derive benefits . example, discover new musical features, improve accuracy movements dance, perform better ensemble, experience positive emotions. benefits experienced relate learning, self-improvement, enriching experiences. Alertness, attention, focus crucial elements reaching level interaction experienced beneficial. Unlike taking drugs, approach passive; quite opposite. requires physical effort endurance experience benefits become aware .book, discuss self-augmented interactions, people tend create interactions voluntarily, choice decision. interactions, augment , performing better experiencing beneficial long-term effects (days, weeks, beyond). claim long-term effects conditional upon self-augmented interactions music. words, self-augmented interactions necessary effects occur. However, due confounding variables, may easy predict effects.Currently, far able predict long-term effects music, research domain still young yet mature enough address enormous complexity subject. comprehensive review evidence power music, Hallam Himonides conclude: “evidence stands moment, clear \nmusical activities might beneficial promoting particular\noutcome. Currently, much evidence mixed, extent\nexplicable terms different musical activities studied \nresearch methods used. research wider benefits music \nhigh priority research funders, may many years \npossible provide clear guidance musical interventions\nmight lead particular outcomes, qualities delivery \ninterventions key success.” (p. 595)2Given interaction involvement bodily functions, envision complex system whose states can built time, maintained period, decline back normal. Rather focusing -line effects music, happens listening, dancing, playing music, interested examining -line effects—, happens interaction music. relatively new domain, mentioned, understanding -line effects prerequisite comprehending -line effects. Therefore, primary focus understanding happens interaction music.Evidence can drawn behavioral neuroscience studies, neurobiology playing necessary role complete picture. Indeed, increased alertness, reduced stress, pleasure, motivation suggest involvement neurotransmitters hormones norepinephrine, oxytocin, cortisol, dopamine, regulate brain functions affect behavioral activities interactions3.However, book rather focused scope. contribution theory centers primarily timing performances. Additionally, concentrate statistical processing timing data.Consequently, aim achieve book small part grand dynamics play. Therefore, claims modest.believe timing interesting distinctive, measurable, partly controllable feature interaction. mentioned, focus -effects timing neuroplasticity effects. Instead, return basics study fundamental aspects using statistical processing tools. examine preconditions plausible effects performance parameters, aiming better understand dynamics music interaction.paradigmatic example musical tempo played ensemble musicians. feature timing, created maintained collaborative effort, involving co-regulation individual musicians’ actions within ensemble. Tempo delicate state associated ensemble’s musical quality. stable tempo crucial, except changes tempo required. tempo interesting feature timing, certainly important. can measured, instance, identifying onsets audio calculating underlying distribution inter-onset intervals. intended stable timing achieved, ensemble can said special interaction state.co-regulation actions maintain intended stable tempo requires alertness, physical effort, fine sensory-motor control member. mistake can disrupt moment. However, effort pays : good performance brings relief satisfaction.short, theory self-augmented interaction improving music, performing. requires optimal performance action perception processes, involves effort – pleasure – reward – motivation, draws upon intentions, goals collaborative actions.\ncomplete theory self-augmented interaction might yet within reach, goal contribute , firstly proposing elements contribute theory, secondly, perhaps important book, offering data-analysis tools sharpen details contributing insights may lead us towards theory. Thereby, don’t focus effects music, rather properties interaction.short, theory self-augmented interaction improving musical performance. requires optimal integration action perception processes, involving effort, pleasure, reward, motivation, draws upon intentions, goals, collaborative actions. complete theory self-augmented interaction may yet within reach, goal contribute two main ways: first, proposing elements contribute theory; second, importantly book, offering data-analysis tools refine understanding key insights guide us toward theory. , focus effects music, rather properties interaction .","code":""},{"path":"chapTheory.html","id":"supporting-theories","chapter":"1 Theory","heading":"1.2 Supporting theories","text":"ultimate theory draws upon number theories humans interacting environment.\ntheories relate embodiment, prediction expression.","code":""},{"path":"chapTheory.html","id":"embodiment","chapter":"1 Theory","heading":"Embodiment","text":"Embodiment holds idea humans repertoire gestures actions, use coding decoding music4.musical performance (coding), various bodily gestures shape phrasing, articulation, intonation, overall structure sound. Consequently, musical sound reflects traces gestures patterns, known moving sonic forms.musical performance (coding), various bodily gestures shape phrasing, articulation, intonation, overall structure sound. Consequently, musical sound reflects traces gestures patterns, known moving sonic forms.listening dancing (decoding), individuals draw upon repertoire bodily gestures align moving sonic forms. alignment enables experience music gestural action-oriented perspective, essentially embodying gestural traces within music.listening dancing (decoding), individuals draw upon repertoire bodily gestures align moving sonic forms. alignment enables experience music gestural action-oriented perspective, essentially embodying gestural traces within music.Coding decoding can understood components expressive communication process. Coding translates gestures sound, decoding converts sound back gestures. communication, people share common repertoire information, conveyed gestures actions. repertoire biological cultural nature. biological people share similar biological biomechanical foundation. cultural due codified ways people move behave within specific cultural contexts. Therefore, shared repertoire enables individuals encode decode information music using biological culturally codified gestures. context communication, music serves vehicle mediating gestures actions carry expressive forms.Consider role timing. bodily actions generate sound cues timing, intrinsic relationship timing body movement. Timing encoded sound can decoded sound, allowing us experience perceive timing. Consequently, sound music serves vehicle mediating timing gestures, carry expressive forms can experienced interpreted.link sound gestures can crucial measurement timing, even though detecting timing sound can challenging. Consider, example, onsets violin tones timing induce. can difficult detect timing cues violin audio alone. However, likely timing cues can extracted violin bowing gestures, movement goes point point B space. turning points B may provide important cues timing. measured sound recording, movement recording, using motion capture system5.","code":""},{"path":"chapTheory.html","id":"prediction","chapter":"1 Theory","heading":"Prediction","text":"Embodiment closely linked prediction, moving sonic forms can anticipated human encoder/decoder (Seth, 2015). Often, anticipation based gesturing. Interestingly, dancing beat music, gestural alignment body movement typically initiated ahead beat. initiated ahead, crucial timing movement come late.Moving sync musical beat demonstrates embodiment fundamentally predictive. Consider conducting favorite piece music CD6. conducting likely ahead music due brain’s predictive processing. deeply engaged conducting, probably evokes feeling agency power. ?due reverse causality illusion7. illusion, appears gestures cause music—movements cause music effect. reason illusion correlation contiguity gestural musical events: gestural events precede musical events.Clearly, perception reverse causality illusory, music continues even gesturing suddenly stops. Nevertheless, experiencing illusion may create strong feeling control (agency). may feel gestures influence music, providing sense power satisfaction. effects occur musical interaction performance. Whether effects persist performance another matter.connection self-augmented interaction evident. Establishing reverse causality creates self-augmented interaction state. ability generate state crucial human decoder create empowering effects.However, reverse causality effect. Prediction enables co-regulation one’s actions heard musicians, allowing establishment stable tempo collaboration. Prediction ubiquitous thus crucial element understanding self-augmented interaction states maintained. Effects reverse causality illusion can seen consequences prediction.","code":""},{"path":"chapTheory.html","id":"expression","chapter":"1 Theory","heading":"Expression","text":"Embodiment prediction, considered perspective social interaction, support expression. Gestures serve social signals, grounded human biology culturally codified social actions. gesture becomes expressive signal receiver responds expressive signal 8. exchange expressive signals via gestures, sender receiver typically trigger embodied predictions, arousal, enhanced attention, focus, emotional engagement. exchange can lead ritualized behavior gestures become habituated.Expression thus vital human interactions. Expressive timing refers use timing signal evokes responses audience. mutual exchange gestural expressions predictions, humans can interact coordinated manner. Musical rhythms enhance exchanges bodily expressions, facilitating formation co-regulated interactions paving way self-augmentation.Together, three constructs—gestural, anticipatory, expressive dynamics—provide framework understanding musical self-augmentation. dynamic ultimately leads enhanced state senses, cognitive abilities, emotional engagement sharpened function optimally. particularly interested behavioral features dynamic expressed timing. Although specific domain musical interaction, challenging intriguing.","code":""},{"path":"chapTheory.html","id":"music-as-moving-sonic-forms","chapter":"1 Theory","heading":"1.3 Music as moving sonic forms","text":"Given theories human interactive abilities, valuable examine music , particularly music can understood moving sonic forms. perspective based notions pattern emergence endowed expression, vital understanding interaction.9","code":""},{"path":"chapTheory.html","id":"pattern-emergence","chapter":"1 Theory","heading":"Pattern emergence","text":"Pattern emergence concept pattern possesses structural features aligned human capacity emergence. alignment, along pattern’s structure, facilitates emergence perceptual phenomena. Consider auditory system: capacity transform pattern specific structural features perceptual experience. instance, harmonic structure composed 600, 800, 1000, 1200 Hz may perceived pitch 200 Hz due auditory system’s transformative ability10.. pattern perceived structure allows pitch perception, auditory system performs transformation.auditory system can also integrate multiple harmonic patterns single perceived chord. harmonic patterns played sequence, integration may generate expectations, leading tonal tensions relaxation dynamics11. Furthermore, auditory system can process slightly altered structures, resulting shifts pitch perception.Interestingly, bottom-mechanisms pattern emergence may compete top-mechanisms driven habitual patterns. competition can influence perception tonal tension relaxation. precise contributions sensory (bottom-) cognitive (long-term memory) processing still debated 12, considerable understanding mechanisms. Pitch emergence arises structure patterns underlying dispositions, involving auditory brain mechanisms.similar observation can made rhythms. Rhythms consist pulses collectively form meter, acting super-structure emerging lower-level pulse structure. Similarly, timbres can blend form emergent textural patterns, phenomenon well-known orchestration. Thus, domains rhythm timbre, super-structures emerge underlying structures processing mechanisms.However, clear distinction music speech terms degree depth pattern emergence. Blending timbres less common speech, may blur signal hinder semantic understanding. Moreover, music, performers often co-regulate actions generate joint pattern emergence rhythmic, pitch, timbre levels. joint emergence far less prominent speech; instance, heated debates, moderator may intervene ensure one speaker talks time.examples illustrate music, compared speech, extraordinary capacity pattern emergence. capacity strong asset (self-)augmentation, allows emergence achieved, might otherwise non-existent. striking example Sardinian throat singing (cantu tenore), self-augmentation physically perceived quality blending. style typically performed groups four male singers standing close circle.","code":""},{"path":"chapTheory.html","id":"endowed-expression","chapter":"1 Theory","heading":"Endowed expression","text":"Emergent patterns exist isolation. produced humans, patterns become endowed expression, referring gestures involved encoding decoding sounds13. Gestures define movements expressive, encoding sounds, gestural traces become integral part sound pattern emergent features. instance, singing, musical pitch exhibits portamento intonation, intervals certain pitches may shortened lengthened articulate rhythms.essence, gestural traces sound define articulations (e.g., legato staccato), sound color, musical narrative, dynamics (e.g., crescendo diminuendo), either complementing integrating emergent patterns. Consequently, human gestures become embedded musical structure, creating emergent patterns endowed gestural expression.argue endowment emergent patterns expression provides another incentive creating self-augmented interaction states. Emergent patterns endowed expression facilitate augmentation. Emergence form augmentation, expression enhances otherwise perceived mere bodily movement.","code":""},{"path":"chapTheory.html","id":"interaction-capacities","chapter":"1 Theory","heading":"1.4 Interaction capacities","text":"point, recognize theory self-augmented interaction remains somewhat vague undefined. However, theories environmental interaction nature music (emergent patterns endowed expression) point towards Gestalt theory. theory posits parts combined, result sum parts. Essentially, theory reinterpretation Gestalt principles lens modern cognitive science.complete set concepts introduced earlier chapter, add three additional concepts: affordance, entrainment, narration. brief mention concepts suffice.","code":""},{"path":"chapTheory.html","id":"affordance","chapter":"1 Theory","heading":"Affordance","text":"affordance property music (sonic form), ability act upon affordance offered music called affordance capacity. Therefore, music possesses affordance capacity; guides action. Affordances sometimes linked notion frozen emotion, composers performers encode emotions music, listeners capacity decode emotions. affordances, frozen emotions activated music. fact, possible replace “emotion” “gesture,” idea still holds: sound traces set gestures action. Good music, believe, possesses strong affordance capacity.","code":""},{"path":"chapTheory.html","id":"entrainment","chapter":"1 Theory","heading":"Entrainment","text":"Entrainment capacity adapt align music, either continuously, movement flows music, discretely, movement marks musical events14. term suggests, entrainment implies something music attracts listener, acting driver human activity. motion, expression, emotion.context book, entrainment specifically defined (co-regulated) sensorimotor synchronization. Notably, entrainment linked subliminal bias reduces prediction errors aligning body movement sound cues15. Similar tempo maintained musical ensemble, entrainment can understood either error-correction mechanism dynamic adaptation system.final chapters (see 7 8) demonstrate entrainment, context two individuals interacting , involves error-correction dynamic adaptation. process engages contrasting dynamic intentionally acted events perceived events. goal operationalize concept. However, important note entrainment can also defined broadly capacity respond cues brain principle acting neuronal oscillations.","code":""},{"path":"chapTheory.html","id":"narration","chapter":"1 Theory","heading":"Narration","text":"Last least, must mention narration, one least understood yet important principles music research. Narration refers storytelling often associated human encoder. instance, jazz musicians use patterns previously trained playing gestures kind alphabet construct larger arcs phrases, binding larger structures—stories music. manner telling narrative, .e., performance, equally important, builds anticipation, entrainment, affordance capacity.prime example Clifford Brown, legendary jazz trumpeter composer tragically died age 25 car crash. Brown renowned ability tell stories music, using patterns trained playing gestures construct larger arcs phrases. One famous improvisations Joy Spring. several recorded solos piece, similar phrase components arranged differently. One solos widely regarded one best solo improvisations ever played. Brown’s work jazz striking architectonic structure emotional immediacy.Unfortunately, narration often integrated musicological studies embodiment, prediction, expression. small contribution chapter 4 ’s limited work needed domain sensorimotor cognitive capacities intersect.short, music involves several capacities necessary interact environment. capacities well-suited process dynamic structure music, return, emergent patterns.","code":""},{"path":"chapTheory.html","id":"music-addiction","chapter":"1 Theory","heading":"1.5 Music addiction","text":"\nFigure 1.1: Engine self-augmented interaction\nLet us return idea, often espoused grandmothers, physical effort endurance necessary self-improvement. people engage interactions demand physical effort? likely answer pays , compelling explanation may lie biological processes govern reward pleasure. prefer view form pro-social addiction16.Figure 1.1 offers rough model suggesting interaction music engages physical effort, expression, prediction mechanisms. Together co-engage arousal, valence, agency, trigger reward-related processes, based dopamine-spread brain, drive human subjects engage music. addiction.\ncycle may support realization self-augmented interaction states. states rewarding pleasurable, probably sets scene states. pro-social addiction.propose emergent patterns endowed expression facilitate generation self-augmented interaction states. patterns align human capacity capture affordances engage entrainment. co-regulation actions among multiple individuals creates social context can motivating, formation musical narrative can compelling. Moreover, process can rewarding numerous ways.theory thus posits music, due human disposition, offers facilitates opportunities self-augmented interaction states. previously mentioned, book aims investigate specific elements broader theoretical claim, primary focus statistical modeling.","code":""},{"path":"chapTheory.html","id":"note-about-expression-theory","chapter":"1 Theory","heading":"1.6 Note about expression theory","text":"close chapter, something said expression theory often, like narrative, often neglected misunderstood.Briefly stated, expression theory based idea expression person calls expressive response person B, turn serves stimulus expression , thus leading mutual exchange expressions might result particular interaction state.\nindeed suggested figure 2.2 (see next chapter), dynamic perspective.Although idea simple, scholars find hard understand expressions always require reasons expressing. many contexts, expressions really don’t require inference presumed cause.Interactions often based direct spontaneous gesturing, implying responses patterns using gestures. kind direct gestural responding goes fast, based alignment, mirroring, including counterpoint gesturing. Interpreting expression terms presumed cause, largely depends context type interaction. main point expressions, valid significant, always point deep underlying reason, reason can found inference. Instead, expressive interacting may occur without assuming causes expression.. Expression biological largely intuitive. Therefore, rather inferencing latent state (known theory mind theory), appropriate speak gestural responding (based mirroring). real power expression exchange dynamic ability build maintain self-augmented states. Like Sardinian throat singing, real power ability blend voices create implied harmony ghost tone. others may hear expression divine . Expression theory may thus understood terms exchange expressive gestures patterns (possible inferred underlying states always excluded) steer-interaction towards self-augmented states.question raises whether Bayesian inference applies patterns causes.\nSorry, Bayesian inference explained next chapter.\nAnyhow, answer applies . Responding expression implies processing patterns assumption particular shape observed pattern can seen prior Bayesian inference pattern. Inferring cause expression also apply Bayesian inference scheme. case, prior focus cause, example, emotion, character associated.\n’ll show Bayesian inference general machinery dealing assumptions observations, regardless whether applies expressive forms expressive causes forms.","code":""},{"path":"chapTheory.html","id":"conclusion","chapter":"1 Theory","heading":"1.7 Conclusion","text":"theory music interaction hands, perspective understanding music people people music, . theory evolved several decades research musicology. However, ’s far established theory needs refinement, even reformulation. biased certain trends cognitive science, future, likely neuroscience neuro-biology important contribution allowing refinement theory.book, use theory general framework case studies highlight particular phenomena related timing. believe proper description causal modelling timing may contribute understanding theory.\nyes, timing covers tiny small aspect entire theoretical framework believe timing essential cornerstone. linked neuro-something future research!","code":""},{"path":"chapModelling.html","id":"chapModelling","chapter":"2 Modelling","heading":"2 Modelling","text":"Statistical modelling aims establishing connection data theory, basically capturing data estimated parameters assumed distribution. Responses showing normal distribution thus modelled mapping predictors onto parameters normal distribution, , mean standard deviation (variation). better accurate conclusions can drawn using modelling, can also clarify key theoretical insights. parameters statistical model known, model can predict data. Statistical modelling thus drives domain forwards terms better understanding data’s underlying parameters.chapter depends following scripts data preparation, plotting, modelling model plotting:","code":"\nsource(\"Code/chapAll_00_Initialization.R\")\nsource(\"Code/chapAll_01_Functions.R\")\nsource(\"Code/chapModelling/chapModelling_02_DataPreparation.R\")\nsource(\"Code/chapModelling/chapModelling_03_DataPlotting.R\")\nsource(\"Code/chapModelling/chapModelling_04_Modelling.R\")\nsource(\"Code/chapModelling/chapModelling_05_ModelPlotting.R\")"},{"path":"chapModelling.html","id":"bayesian-epistemology","chapter":"2 Modelling","heading":"2.1 Bayesian epistemology","text":"book adopt overall Bayesian epistemology knowledge acquisition.\napplies subjects interacting environment.\nbest way introduce approach means graph – simple example.\nFigure 2.1: Bayesian model\nConsider figure 2.1 graphical description human subject (left circle), observing pattern (middle circle), making inference state caused pattern (right circle).","code":""},{"path":"chapModelling.html","id":"from-pattern-to-state","chapter":"2 Modelling","heading":"From pattern to state","text":"Say, see dog approaching ’re sure attitude. aggressive friendly, scale -1 +1, 0 neutral. prior belief dog rather angry, almost sure . belief expressed Gaussian distribution mean value -0.7 standard deviation 0.2. observe dog different instances. However, given belief, attitude, observed, seems friendly get new probability distribution based observations respect belief, called: likelihood. distribution positive, uncertain: mean 0.3 points higher attitude-scale, standard deviation 0.5. Accordingly, true mean -0.4 std 0.5.information hand, can update prior belief construct posterior belief dogs attitude, just combining two distributions. result, new belief dog neutral less angry thought , less sure attitude . Based simulations, obtain result mean -0.5511 (shifted neutral attitude, still angry) standard deviation 0.2698 (prior belief). posterior belief becomes prior belief new observations.simulation works samples generated Gaussian, normal, distribution.dog approaches observe friendly expected basis (new) prior belief.\nresult, next posterior belief shift direction friendly dog.Now, second variable added, say also consider posture dog scale -2 2 (stiff versus relaxed), normal distribution become two-dimensional rather one-dimensional. mean specified two values, standard deviation define ellipses around mean. Yet reasoning remain . prior likelihood. posterior just combine two-dimensional distributions, used new prior, , expectation attitude-size.dog example illustrates Bayesian reasoning (inferring posterior likelihood prior), dynamic behind reasoning (posterior becomes new prior), using parameters Gaussian model. observe data, can continue update beliefs (priors) refine understanding world.Bayesian reasoning applied music, variables addressing musical properties, harmony, articulation rhythm. ’s ’ll restrict timing. Tempo particular. prior belief tempo observations durations successive tics metronome, finger taps human subjects.\nFigure 2.1 also suggests Bayesian reasoning true tempo going possible probe subject’s experiences, example questionnaires measurements. Questionnaire address difficulty task, aborbation task many issues. measures physiological measures (sweath, temperature), brain activation measures, indicators experiences.\nquestionnaire assumes subject somehow capable translating experiences verbal descriptions.short, way subject infers dog, also way subjects infer tempo. Interestingly, even way – researchers – infer data gathered observations experiments. often prior belief rather uninformative, sometimes can informative, example knowledge human tapping. known tapping metronme anticipative: human tap metronome beat. Well, information can used prior belief interpret observations.general research strategy also Bayesian updating theory. theory self-augmented interaction states typically updated applied concrete case studies, find new evidence relevant refinement.","code":"\nprior_distribution = rnorm(10000,-0.7,0.2)\nlikelihood_distribution = rnorm(10000,-0.4,0.5)\nprior_combined_with_likelihood_distribution = (prior_distribution + likelihood_distribution)/2\nmean(prior_combined_with_likelihood_distribution)## [1] -0.551553\nstd(prior_combined_with_likelihood_distribution)## [1] 0.2703112"},{"path":"chapModelling.html","id":"interactions","chapter":"2 Modelling","heading":"Interactions","text":"focus book self-augmented interactions, special focus interaction . believe interaction factor stirrs-augmentation.\nSince assume Bayesian reasoning basis interacting environment, ’s interest consider happens environement responsive. example, environment AI-system, another human. Let’s take another human.Two subjects interacting can represented using Bayesian scheme shown 2.1.\nsubject state--expressed via pattern. subject observes pattern subject subject infers state subject.\nFigure 2.2 shows states--two subjects represented fully colored left right cycles (state 1 state 2).\nFigure 2.2: Bayesian model 2 subjects\nlikely subjects mutually influenced interacting. shown chapters 7 8, mutual influence can understood flow information among units states units change. change humans adapt . ability adapt may, cases, become factor facilitates formation self-augmented interaction states. example, musicians manage adapt others tempo, might able maintain stable tempo duet. result considered self-augmented interaction state.short, Bayesian epistemology applies subjects interacting, well researcher studying interaction. even applies modelling approaches.","code":""},{"path":"chapModelling.html","id":"regression","chapter":"2 Modelling","heading":"2.2 Regression","text":"let’s look modelling, given overall Bayesian epistemology.\nfollows, utilize regression tool analysis.\nRegression analysis based idea variable, known response dependent variable, can predicted variables, known predictors independent variables. predict estimate parameters mathematical model, mean standard deviation Gaussian model.Following Buerckner (2018), write\n\\[\\begin{equation}\n\\begin{aligned}\ny &\\sim D(\\theta_{p})\\\\\n\\text{}\\\\\ny_i &\\sim D(\\theta_{1,},\\theta_{2,}, ...)\n\\end{aligned}\n\\tag{2.1}\n\\end{equation}\\]\n\nexpress response \\(y\\) predicted parameters \\(\\theta_p\\) response distribution \\(D\\).\ndetail means \\(y\\) \\(\\)th observation predicted parameters\n\\(\\theta_{1},\\theta_{2}, ...\\)\n\\(\\)th observation. normal model, mean standard deviation parameters.Every parameter \\(\\theta_p\\) can regressed predictor term \\(\\eta_p\\),\ntransformed -called inverse link function \\(f_p\\). Per observation \\(\\), \n\\(\\theta_{pi} = f_p(\\eta_{pi})\\).\nnormal model, inverse link function identity function., every \\(\\eta_p\\) regressed :\n\\[\\begin{equation}\n\\eta = X\\beta + Zu + \\sum_{k=1}^{K} s_k(x_{k})\n\\tag{2.2}\n\\end{equation}\\]\n\n\\(\\beta\\) \\(u\\) respective coefficients population-level group-level (also known random variables),\n\\(X\\), \\(Z\\) corresponding design matrices.\nterms \\(s_k(x_k)\\) symbolize optional smooth functions unspecified form based covariates \\(x_k\\) fitted via functions (e.g. splines, gaussian processes).","code":""},{"path":"chapModelling.html","id":"data-as-indicator","chapter":"2 Modelling","heading":"2.3 Data as indicator","text":"Let’s work regression example using timing data.\nAlong way, ’ll introduce relevant concepts return later chapters.go.\nConsider simple question whether humans can synchronize finger tapping along regular metronome ticking.\nCan use regression say something finger tapping?\n","code":""},{"path":"chapModelling.html","id":"dataset","chapter":"2 Modelling","heading":"Dataset","text":"use data Rosso et al. (2023), subject instructed tap finger table, along regular metronome tics, heard every \\(0.6\\) seconds, \\(390\\) seconds.\nfinger touches measurement device table, clock time gets registered tap.\nalso registers tic.\ndata can arranged array time values tap tic appeared.\nfirst six rows dataset look like:\nTable 2.1: Tic tap times\ncolumn time marks numerical time values names factor two levels: tic tap.\nAnother view dataset given :just says object data.frame 6 observations 2 variables, time names, shows first values. 6 values, see .point may interest show data.\nfollowing code found `Code/chapModelling/chapModelling_02_DataPreparation.R```.read content file stored Data/chapModelling_TicTap_Data.rds store TicTap_data.\nDData created turn table using R-chunk already used .\nhidden text rendered.\nexplicitly show chunk used generate table, showing time tic tap occurred:\nTable 2.2: Tic tap times\n","code":"## 'data.frame':    6 obs. of  2 variables:\n##  $ time : num  0.12 0.6 0.64 1.2 1.21 1.8\n##  $ names: Factor w/ 2 levels \"tic\",\"tap\": 2 1 2 1 2 1\nTicTap_data <- readRDS(file = \"Data/chapModelling_TicTap_Data.rds\")\nd1 <- TicTap_data %>% filter(names == \"metronome\") %>% mutate(dtime = c(0.6,diff(time))) \nd2 <- TicTap_data %>% filter(names == \"subject\") %>% mutate(dtime = c(NA,diff(time))) \nDData <- rbind(d1,d2) %>% arrange(time)\nw <- which(DData$dtime>.9)\nDData <- DData[-w,]\nDData <- DData %>% mutate(names = factor(names, labels = c(\"tic\",\"tap\")), time = round(time,2))\nD1 <- DData %>% dplyr::select(time, names) %>% head()\nknitr::kable(D1, booktabs=T, label = NA, caption = paste(\"Tic and tap times\")) %>% \n  kable_styling(\"striped\", font_size = 10)"},{"path":"chapModelling.html","id":"period","chapter":"2 Modelling","heading":"Period","text":"\nTable 2.3: Periods: inter-tap inter-tic intervals\nvalues dtime based time difference successive tap, well time difference successive tic.\nhistogram periods shown figure 2.3, left panel.\ncode calculating histograms found Code/chapModelling/chapModelling_03_DataPlotting.R\nFigure 2.3: Left panel, histogram periods. Right panel, histogram relative phases. blue line shows mean -2.03[rad] according circular model. ocre line shows mean -1.09[rad] according non-circular model. red line shows mean -1.68[rad] according synchronization strength measure\norder able count periods,\nsmall containers covering small ranges (= bins) defined setting binwidth, periods slightly different value fit.\ncurrent purposes binwidth important small enough small, good amount periods fit bin.\nWhenever measured period falls bin, bin count increases.\nhistogram left reveals metronome’s periods, shown gray color, exactly \\(0.6 ~s\\), expected, close. due small differences (milliseconds) tics whose origin technical. Anyhow, differences perceived human ear.subject’s periods, shown green color, fluctuate broadly around value.\nappear normal distribution mean close \\(0.6 ~s\\) standard deviation \\(0.046~s\\).\nprecisely:","code":"\nms <- DData %>% filter(names == \"tap\") %>% drop_na() %>% \n  summarise(mu = mean(dtime),sd = std(dtime))\nknitr::kable(ms) %>%\n    kable_styling(\"striped\", font_size = 10)"},{"path":"chapModelling.html","id":"relative-phase","chapter":"2 Modelling","heading":"Relative phase","text":"revealing, perhaps, view relative phase, shown histogram right.\ndata look like :\nTable 2.4: Data relative phase\ncalculate relative phase, let’s go back previous table showing tic tap times metronome subject.\ntap event row \\(n\\) (\\(tap_n\\)) considered within two surrounding tic events closest time, found row \\(m\\) row \\(m+\\) (next row find tic).\nrelative phase \\(\\phi\\) \\(tap_n\\) (called: \\(\\phi_n\\)) defined time interval \\(tic_m\\) \\(tap_n\\), divided time interval \\(tic_{m}\\) \\(tic_{m+}\\), multiplied \\(2\\pi\\) represent ratio time intervals \\(radians\\), :\\[\\begin{equation}\n\\phi_n~= ~2\\pi \\left(\\frac{tic_m - tap_n}{tic_m - tic_{m+}}\\right)\n\\tag{2.3}\n\\end{equation}\\]\ntic \\(0.6 s\\), first tap occurs \\(0.64 s\\). tap tic interval \\([0.60,1.20]s\\),\nthus \\(2\\pi[(.6 - .64) / (.6 - 1.2)] = 0.42 [rad]\\).\n(2.3) always get value 0 \\(2\\pi\\).\nobtain value range \\([-\\pi,+\\pi]\\) necessary rotate :\\[\\begin{equation}\n\\hat\\phi_n = [(\\phi_n + \\pi)mod(2\\pi)] -\\pi\n\\tag{2.4}\n\\end{equation}\\]\n\\(\\hat\\phi_n\\) rotated value, \\(mod\\) modulo operation ()modulo(B).\nRotation effect values \\(\\pi\\) go \\(0\\).Accordingly, \\(tap_n\\) occurs half cycle \\(tic_m\\), \\(\\hat\\phi_n\\) positive, indicating delay.\n\\(tap_n\\) occurs half cycle \\(tic_{m+}\\), \\(\\hat\\phi_n\\) negative, indicating anticipation \\(tic_{m+}\\).\nRotating \\(0.42 [rad]\\), \\((.42 + \\pi)\\) modulo \\((2 \\pi)- \\pi\\) get \\(0.42 [rad]\\). case, rotation effect \n’s want. values \\(\\pi\\) get rotated re-appear zero.\nvalue 4[rad], rotation gives -2.28[rad].obtained scale circular scale \\(0\\pi\\) (equal \\(2\\pi\\)) appearing middle interval spanned \\([-\\pi,+\\pi]\\). expresses relative phase cycle marked successive taps. circularity implies values slightly \\(>\\pi\\) can also considered slightly \\(<-\\pi\\).\nrelative phase histogram figure 2.3, peak negative value, meaning , average, taps occur half cycle tic (tics zero). taps anticipating ticks.\nNote histogram distribution looks normal slightly skewed right.","code":"\ndf <- RelPhase %>% data.frame() %>% mutate(relphase = round(relphase,2) ) %>% \n  dplyr::select(time,relphase)  %>% arrange(time) \nkable(head(df), \n      booktabs=T, label = NA, \n      caption = paste(\"Data with relative phase\")) %>%\n  kable_styling(\"striped\", font_size = 10)\n# \\@ref(tab:chapModellingRelPhases)"},{"path":"chapModelling.html","id":"polar-representation","chapter":"2 Modelling","heading":"Polar representation","text":"Interestingly, relative phase can represented angle unit length vector polar representation.\nAccordingly, construct vector :\\[\\begin{equation}\nv = e^{(j\\phi)}\n\\tag{2.5}\n\\end{equation}\\]\n\n\\(v\\) unit length vector angle equal relative phase \\(\\phi\\).\n\\(j\\) indicates complex number.Given series relative phases, first turn unit vectors.\nsum unit vectors divide number unit vectors.\nresultant vector \\(V\\) can easily extract polar coordinates, vector length \\(R\\) angle \\(\\alpha\\). ’s .\\[\\begin{equation}\nV = \\frac{1}{N}\\sum_{n=1}^N v_n\\\\\nR = Mod(V)\\\\\n\\alpha = Arg(V)\n\\tag{2.6}\n\\end{equation}\\]\nexample, given relative phases shown table 2.4, first turn unit vectors.\nvectors point several directions along unit circle phases different zero. mean length smaller one.R \\(\\alpha\\) given ","code":"\nV <- (exp(1i *0.38) + exp(1i*0.03) + exp(1i*0.16) + \n        exp(-1i*0.03) + exp(1i*0.06) + exp(-1i*0.13)) /6\nMod(V) ## [1] 0.9871149\nArg(V)## [1] 0.077842"},{"path":"chapModelling.html","id":"synchronization-strength-and-delay","chapter":"2 Modelling","heading":"Synchronization strength and delay","text":"working relative phase, length \\(R\\) can interpreted synchronization strength.\ntap perfectly synchronized tic, \\(R = 1\\).\nangle \\(\\alpha\\) can interpreted synchronization delay.\ntap anticipated, delay, \\(\\alpha = 0 [rad]\\).can now return data table 2.3 shown figure 2.3, right panel.\nTaking data account, synchronization strength \\(R = 0.61\\) synchronization delay \\(\\alpha = -1.68[rad]\\).\nlatter shown right panel figure 2.3 dotted red line.point, analysis stop conclusions drawn subject’s tapping variability.\nnegative mean asynchrony, indicating anticipation tapping.finding confirms know literature. finding tapping proceeds ticking agreement theoretical assumption predictive brain. case, brain handles motor prediction asymmetric delay lines (longer) tactile feedback (shorter) auditory feedback compensated tapping earlier, tactile feedback auditory feedback arrive time brain.","code":""},{"path":"chapModelling.html","id":"data-and-model","chapter":"2 Modelling","heading":"2.4 Data and model","text":"course don’t stop .\nfact, fun just starts.\ntapping events can considered indicators continuous hidden process related brain’s prediction time.\nStatistical models can make hidden process visible.","code":""},{"path":"chapModelling.html","id":"circular-axis","chapter":"2 Modelling","heading":"Circular axis","text":"Consider dataset shown table 2.4.\nget interesting graphical representation showing relative phase event time, ilustrated figure 2.4, , time horizontal axis relphase vertical axis.\nfigure shows particular tapping segment 160 175 seconds.\ndashed vertical lines show tics.\ncircles show taps defined relative phase values, depend tap time relative tic time.tics may missing tic selected always first tic tap.\nexample, tap period wider tic period, first tic selected.\nGiven \\(tic_0, tap_1, tic_1, tic_2, tap_2\\), \\(tic_1\\) shown\n\\(tic_0\\) reference \\(tap_1\\) \\(tic_2\\) reference \\(tap_2\\).\nTaps positive relative phase (.e., delayed) fall first half-cycle tic.\nTaps negative relative phase (.e., anticipated) fall first half-cycle next tic.\nFollowing logic, values top figure 2.4,\n163 167 seconds, form actually part U-shaped sequence relative phase values, vertical axis circular. . code found Code/chapModelling/chapModelling_03_DataPlotting.R.\nFigure 2.4: Relative phase values time, using circular vertical axis\n\nFigure 2.5: Relative phase values time fitted, using circular model (blue), non-circular model (ochre)\ncomplete tapping sequence shown figure 2.5.\ncode found Code/chapModelling/chapModelling_05_ModelPlotting.R.\ncontinuous lines smooths generated two different smooth regression models, either taking account circularity response (= blue line), (= ochre line). Smooths fact curves go data optimal fluent way, whose resolution can define.\nGiven knowledge circularity relative phase, ochre line one just wrong.obtain figure?","code":""},{"path":"chapModelling.html","id":"smooth-regression","chapter":"2 Modelling","heading":"Smooth regression","text":"description smooth regression model based lme4-syntax, used R-packages statistics.\ndefined relation response predictor :\n\n\nformula says relative phase relphase distributed offset (indicated 1) plus smooth time using basis \\(k=30\\) spline-functions.\nrelative phase value \\(\\phi_i\\), occurring particular time \\(t\\), equal offset plus linear combination 30 spline-functions values evaluated \\(t\\), plus residual noise.\nsplines capture correlation among relative phase values time.\nObviously, model come fitted splines \\(\\phi_i\\) .values \\(\\phi_n\\) value circular axis defined interval \\([-\\pi,+\\pi]\\), regression model fitted proper circular link function (family=“von_mises”), predictor gets correctly mapped circular axis response.\nAccordingly, formula brms-package :\n\n\nfamily specified, model assumes relphase non-circular; ’s ochre model.\nnon-circular model (ochre) strongly affected values close \\(\\pi\\).\nconsiders high positive values time-independent mean goes .\ncontrast, circular model (blue) considers points near \\(\\pi\\) circular axis mean lower line estimates.\ntime-independent means shown vertical (blue ochre) lines histogram figure 2.3 (right panel).Readers interested code can look \nCode/chapModelling/chapModelling_04_Modelling.R.\nBasically, contains :run_model_cmdstanr() custom function defined Code/chapAll_00_Functions.R, shown :calls brm R-package brms. compiles program Stan runs 6000 sampling iterations finding solution equation. output stored fit.\nsimple way see fit load model, use conditional_effets() function R-package brms.shows blue model figure 2.5.\nsaid, figure 2.5 calculated Code/chapModelling/chapModelling_05_ModelPlotting.R.follows, try avoid much code text.\nInstead, deemed relevant, ’ll point reader relevant code script R.","code":"\nrelphase ~ 1 + s(time, k=30)\nformula = bf(relphase ~ 1 + s(time, k=30))\nfamily = \"von_mises\"\n# response and smooth over time\nform = bf(relphase ~ 1 + s(time, k=50))\n# circular distribution\nfam = \"von_mises\"\n# get priors\npriors = get_prior(formula = form,data = RelPhase, family = fam)\n# run the model with the dataset RelPhase and \n# the above defined form, priors, and fam\nB1 <- run_model_cmdstanr(RelPhase, form, priors, fam)\nrun_model_cmdstanr <- function(Data, form, fam, priors){   #  }, priors){\n  print(paste(form[1],fam,sep=\"\\n\"))\n  fit <- brms::brm(data = Data,\n             formula = form,\n             family = fam,\n             prior = priors,\n             iter = 6000, warmup = 3000,\n             #control = list(adapt_delta = 0.995,  max_treedepth = 12),\n             init = 0,\n             thin = 2,\n             chains = 4,\n             backend = \"cmdstanr\",\n             threads = threading(4),\n             silent = 0\n             #save_pars = save_pars(all = TRUE),\n             #sample_prior = TRUE #,\n             #file = filen\n  )\n  return(fit)\n}\nload(\"Fitted/chapModelling_modelB1_k50.rda\")\nconditional_effects(B1)"},{"path":"chapModelling.html","id":"uncertainty","chapter":"2 Modelling","heading":"Uncertainty","text":"Let us proceed explaining uncertainty \nfigure 2.5.\nfigure shows predicted mean uncertainty time.\nTaking average time, means -2.03[rad] according circular model -1.09[rad] according non-circular model.\nSince know time tics \\(0.6 s\\), anticipated time \n\\((-2.03 / 2\\pi) 0.6s = -0.194s\\) circular model\nnon-circular model \\(-0.105s\\).\ncircular model uncertainty given critical interval (CI-95%) \\([-2.39,-1.75]\\).\nCI-95% indicates mean appear interval 95% estimations.\nnon-circular model, uncertainty given critical interval (CI-95%) \\([-1.18,-1.00]\\).\nClearly, models uncertainty unresolved parameters regression model.type statistical modelling can called: circular-linear smooth regression.\nname stress fact response circular predictor linear, use smooths.\nSoon, ’ll work circular-linear hierarchical distributional smooth regression.\nDon’t panic, know already circular-linear smooth regression!","code":""},{"path":"chapModelling.html","id":"predictions-of-tapping","chapter":"2 Modelling","heading":"2.5 Predictions of tapping","text":"Given model fitted parameters, can used generate discrete tapping events.\nRecall fitted model gives us estimation continuous hidden process.\ncreate discrete taps make sure relative phase values match time values occur.\n\n\n\nproceed:\n- First, predict relative phase \\(\\phi^{tap}_n\\) fitted model using sampling rate 100 samples per second.\nthus get predictions relative phase \\(\\phi^{tap}_n\\) time instances\n\\(t_1=0[s], t_2= 0.01[s],...,t_N = 390[s]\\), \\(n\\) index (\\(n=1,2,...,N\\)) samples \\(t_n\\) sample time.\n- Next, calculate generated tap phase \\(\\psi^{tap}_n\\) sum () tic phase \\(\\psi^{tic}_n\\), (ii) relative phase \\(\\phi^{tap}_n\\), (ii) noise \\(\\epsilon_n\\). expressed :\n\\[\n\\psi^{tap}_n = \\psi_n^{tic} + \\phi^{tap}_n + 2\\pi\\epsilon_n ~,~\\\\\n\\psi_n^{tic}=\\frac{2\\pi t_n}{0.6},~\\\\\n\\epsilon_n \\sim  N(0,.05).\n\\]\nNote \\(\\psi_n^{tic}\\) phase corresponds time indication given metronome tic \\(tic_n\\).\ndivision \\(0.6\\) guarantees \\(2\\pi\\) (= maximum phase metronome tic) occurs multiples \\(t_n=0.6~[s]\\).\nnoise added predicted relative phase comes normal distribution zero mean 0.05 standard deviation.Finally, get discrete tap values \\(\\psi^{tap}_{\\hat n}\\) select samples \\(n\\) \n\\(\\psi^{tap}_n\\) modulo \\(2 \\pi\\) maximum.\nget time value \\(\\psi^{tap}_{\\hat n}\\) occurs:\\[\n\\psi^{tap}_{\\hat n} = max(mod(\\psi^{tap}_{n},2\\pi))\\\\\nt^{tap}_{\\hat n}  = \\frac{0.6 \\psi^{tap}_{\\hat n}  }{2\\pi}\n\\]\n\\(\\psi^{tap}_{\\hat n}\\) selected tap phase \\(2 \\pi\\) value, close value, depending sampling rate, \\(t^{tap}_{\\hat n}\\) time tap \\(\\hat n\\).\nR code calculating predictions found Code/chapModelling/chapModelling_05_ModelPlotting.R.Well, let us show well:\nFigure 2.6: Simulated discrete taps, using underlying process, shown first 100 seconds\nhidden process generated taps first 100 seconds shown figure 2.6.\nObviously, generated taps exactly similar original taps. However, similar statistical structure.sum , used fitted model give us -called counterfactual predictions equal time intervals.\ncounterfactual prediction often needed.\nstraightforward get .","code":"\n# 1. Prepare a data frame with equal samples\nNewdata = data.frame(time = seq(0,100, by=0.01))\n# 2. draw samples from the posterior in B1 with Newdata\npred1 <- B1 %>% epred_draws(newdata = Newdata) %>% median_qi(.epred) \n# 3. calculate discrete taps\npred2 <-  pred1 %>% mutate(phase.metro = 2*pi*time/.6, # we have 2pi when time = .6\n                           epsilon2pi =  2*pi*rnorm(length(time),0,.05), \n                           # add a bit of noise to the .epred\n                           relphase = .epred + epsilon2pi,\n                           phase.tap = phase.metro + relphase,\n                           newtime = phase.tap*.6/(2*pi))\n# plot.ts(pred2$phase.tap[1:1000]%% (2*pi))\np <- findpeaks(pred2$phase.tap %% (2*pi), minpeakdistance = 56)\np = p[,2]\ntaps <- pred2[p,] #%>% mutate(phase.tap = 2*pi) \n# 4. Only the first 100s\nrelPhase <- RelPhase %>% filter(time <= 100)\n# 5. Plotting\nchapModellingB1predicted <- ggplot(pred2) +\n  geom_lineribbon(aes(x = time, y = .epred, \n                      ymin = .lower, \n                      ymax = .upper), alpha=.4, color = \"#56B4E9\") + \n  #geom_line(aes(x=time,y=.epred), color = \"#56B4E9\", alpha=1, size=1) +\n  # geom_point(aes(x=time,y=relphase)) +\n  ylab(\"relative phase\") +\n  geom_point(data=relPhase,aes(x=time,y=relphase),shape=1,size=2, alpha=.6) +\n  geom_point(data=taps,aes(x=newtime,y= relphase), size=2, alpha=.6) +\n  theme_bw() +\n  xlim(0,100)"},{"path":"chapModelling.html","id":"note-about-bayesian-statistics","chapter":"2 Modelling","heading":"2.6 Note about Bayesian statistics","text":"Bayesian approach statistics many advantages, also disadvantages.\nAmong advantages flexibility working fitted model. fitted, kinds combinations parameters counterfactuals can investigated drawing samples model’s posterior.disadvantage time takes compute fitted model.\nmentioned illustrated drawing figure 2.1, estimation process Bayesian data modelling revolves around optimizing likelihood function, , function likelihood priors included. goal find values parameters maximize likelihood function, thereby providing best fit observed data. optimization can viewed Bayesian perspective, goal find posterior distribution parameters given data prior beliefs.powerful technique used Bayesian optimization Hamiltonian Monte Carlo (HMC) sampling. HMC combines principles Hamiltonian dynamics Monte Carlo sampling explore parameter space efficiently traditional optimization methods. However, computational cost considerable.","code":""},{"path":"chapModelling.html","id":"conclusion-1","chapter":"2 Modelling","heading":"2.7 Conclusion","text":"chapter introduced smooth regression applied simple dataset tic tap events, showing timing delicate matter.\naddition showed , based estimated parameters regression model, possible generate counterfactual tap events.\napproach offers many possibilities explored next chapters.","code":""},{"path":"chapListener.html","id":"chapListener","chapter":"3 Listener appreciation","heading":"3 Listener appreciation","text":"chapter17, delve question music listeners. Ultimately, goal develop theory people reflect music .chapter proposes theory music appreciation investigate listeners rationalize appreciation, using large empirical survey music appreciation. way, methodology Bayesian theory used develop questionnaire survey. statistical model used analyzing survey responses. model draws upon theory, based data, informs updated theory. cycles lead refined theory.chapter, studying listeners interact music; rather, study listeners reflect interactions music. Therefore, chapter offline online. focuses listener, performer. Nevertheless, performers also listeners. sense, chapter sketches global background chapters follow.chapter depends following scripts data preparation, plotting, modelling model plotting:","code":"\nsource(\"Code/chapAll_00_Initialization.R\")\nsource(\"Code/chapAll_01_Functions.R\")\nsource(\"Code/chapListener/chapListener_02_DataPreparation.R\")\nsource(\"Code/chapListener/chapListener_03_DataPlotting.R\")\nsource(\"Code/chapListener/chapListener_04_Modelling.R\")\nsource(\"Code/chapListener/chapListener_05_ModelPlotting.R\")"},{"path":"chapListener.html","id":"workflow","chapter":"3 Listener appreciation","heading":"3.1 Workflow","text":"chapter adopts theory-driven approach outlined previous chapter figure 2.1. subject listener interacts music. However, chapter, focus indicators.\nprobe listener questions appreciation motivation, forcing listener reflect happened listening. Using questions, aim building model listener’s appreciation.fully grasp structure chapter, instructive consider workflow figure 3.1, also applies Bayesian epistemology.\nFigure 3.1: Overview theory statistical modelling\nstarting point theory music appreciation.\nBased theory, questionnaire statistical model generated.\nquestionnaire launched survey, answers questionnaire, data, processed transmitted statistical model.\nstatistical modelling serves feedback theory.short, theory start prior, data given theory likelihood, updated theory posterior, turn becomes new theory.follows, hook wagon acceptable stage iteration, ’ll try refine results obtained.","code":""},{"path":"chapListener.html","id":"theory","chapter":"3 Listener appreciation","heading":"3.2 Theory","text":"approach, currently developed, draws fields neurobiology, marketing, musicology. fields enable us conceptualize music appreciation rating assigned listeners gratification experience engaging music.Neurobiology suggests gratification (reward) arises brain’s chemistry fabric, neurotransmitter dopamine. diffuses throughout brain, eliciting pleasurable sensation triggering desire —- behavioral pattern akin seeking stimuli induce reward, reminiscent addiction.Neurobiology suggests gratification (reward) arises brain’s chemistry fabric, neurotransmitter dopamine. diffuses throughout brain, eliciting pleasurable sensation triggering desire —- behavioral pattern akin seeking stimuli induce reward, reminiscent addiction.realm marketing, pattern called wanting. linked perceived value product, reflects overall appreciation indicative customer satisfaction regarding product’s functionalities qualities. qualities can also assessed series questionnaires designed probe various aspects.realm marketing, pattern called wanting. linked perceived value product, reflects overall appreciation indicative customer satisfaction regarding product’s functionalities qualities. qualities can also assessed series questionnaires designed probe various aspects.Finally, domain musicology, proposed music profoundly influences listener’s experience can analyzed terms sub-categories experience, immersion, embodiment, anticipation, emotion expression. concepts discussed chapter 1.Finally, domain musicology, proposed music profoundly influences listener’s experience can analyzed terms sub-categories experience, immersion, embodiment, anticipation, emotion expression. concepts discussed chapter 1.Combining insights neurobiology, marketing, musicology, theory music appreciation can outlined follows:\nlistener engages music, dynamic anticipation-reward-motivation loop initiated, leading experiences emotionally moved, deeply absorbed, urge move, profoundly touched. listener can subsequently reflect upon experiences. listener can also reflect upon effect experiences, may culminate pleasurable bodily reward, positively evaluated.\nUpon reflection, listener may also identify specific qualities music assumed contributed pleasurable experiences.\nFinally, appreciation can expressed means global score, say 1 10.Obviously, comprehensive theory music appreciation must also consider influence context. Factors setting music heard (e.g., live concert versus radio broadcast), listener’s mood (happy, sad), demographic background (young, old), environmental variables can significantly impact listeners perceive interpret musical experiences. Therefore, conducting surveys assessments, essential account contextual factors ensure clarity accuracy participants’ responses, thus avoiding potential confusion misinterpretation.However, believe appreciation independent specific type music listened . Consider example sad music. Despite melancholic nature, piece sad music can trigger intense embodied experiences highly valued listeners, leading high appreciation score. Conversely, happy music may always receive high appreciation, example fails engage listener compelling rhythm groove.\naddition, appreciation agnostic factors gender age.Overall, theory, truly matters activation reward, pleasure, wanting experiences music. Music appreciation reflects inward reflection, focusing nature evaluation experience , outward reflection, directed towards assumed qualities music. reflections influenced various contextual factors background, gender, setting.","code":""},{"path":"chapListener.html","id":"causal-model","chapter":"3 Listener appreciation","heading":"3.3 Causal model","text":"appreciation theory can clarified network variables relationships variables. However, shown already outcome considerable study involving fine-tuning concepts modelling. mentioned, hook wagon acceptable stage iteration theory currently conceived.","code":""},{"path":"chapListener.html","id":"directed-acyclic-graph-dag","chapter":"3 Listener appreciation","heading":"Directed acyclic graph (DAG)","text":"\nFigure 3.2: Causal model appreciation shown DAG\nnetwork can shown DAG, directed acyclic graph (DAG), shown figure 3.2. graph theory spelled set concepts causal relationships among concepts. Note use term causal specific meaning context. cause-effect relationship among two concepts means () information flow direction, sense cause precedes effect time, (ii) association (correlation) concepts, (iii) potential confounding variables account observed association. DAG causality tested considering logic causal relations (see ). Note really model causal flow sense done chapters 7 8.DAG, Kind_of_Experience stands kinds experiences generated musical qualities (Quality) selected listener. Also concepts exposed one, Global_Appreciation outcome.\nconcepts Quality, Immersion , called latent variables directly observable via questions. Instead, live\nunderneath surface observable can probe via questions.rationale musical qualities (Quality) affect listener, causing experiences listener (Kind_of_Experience), including instance, increase dopamine level generating pleasurable feelings wanting urge. Quality represents musical attributes identified participant contributing type experience . ’s objective quality music, subjective quality, identified individual listener. Quality can considered determinant Kind_of_Experience, also divide sub-concepts Immersion, Emotion, Embodiment.\nexperiences set scene assessment (Evaluation), causes scoring Global_Appreciation. latter product value, expression degree wanting product.DAG, ellipses marked X questions.\nincoming arrow answers conceived generated latent variables.\nPretty much like catching fish different environments underneath water surface. ’s fish bites.","code":""},{"path":"chapListener.html","id":"confounding-variables","chapter":"3 Listener appreciation","heading":"Confounding variables","text":"causal direction plausible associations show clear relationships among concepts, might require careful logical reasoning order prevent confounding variables network18.\nFortunately, DAG can tested using tool Daggity. involves evaluating whether assumed causal structure consistent, , whether certain sets variables conditionally independent given sets variables, predicted DAG. lucky, DAG safe. adjustment necessary estimate total effect Kind_of_experience Global_Appreciation, meaning confounding paths variable Kind_of_experience outcome variable Global_Appreciation.can test different interpretations model, example, drawing arrow Kind_of_experience Quality, assuming Kind_of_experience cause quality recognized music.\nHowever, one careful possible open biasing paths, confounding variable bias estimation causal effect Kind_of_experience Global_Appreciation.","code":""},{"path":"chapListener.html","id":"questionnaire","chapter":"3 Listener appreciation","heading":"3.4 Questionnaire","text":"Based theory music appreciation, possible define questions allow us measure latent variables. following table summary questions used survey (see ), except open questions don’t handle . follows, briefly discuss questions structured processed.\n(#tab:chapListener_datasetQ)Questionnaire label, question summary question. L5 means: Likert scale 1 5\nquestions linked DAG. Note DAG’s questions marked X ’s just dummy. follows, mark questions Q indicated table @ref(tab:chapListener_datasetQ). Accordingly, complete DAG real questions, necessary take following steps consideration:Global_appreciation DAG estimated single question (Q1), scored scale 1 10. reflects eager listener want music.Global_appreciation DAG estimated single question (Q1), scored scale 1 10. reflects eager listener want music.Quality DAG based six yes/questions (Q6, Q8, Q10, Q12, Q14, Q16 dataset) probing different aspects musical quality. Quality score based weighted combination binary questions19. gives colored assessment musical features believed influenced experiences.Quality DAG based six yes/questions (Q6, Q8, Q10, Q12, Q14, Q16 dataset) probing different aspects musical quality. Quality score based weighted combination binary questions19. gives colored assessment musical features believed influenced experiences.Evaluation based three questions (Q47, Q48, Q49) probing personal value experience specified Kind_of_experience.Evaluation based three questions (Q47, Q48, Q49) probing personal value experience specified Kind_of_experience.Kind_of_experience subdivided Immersion (Q31, Q33, Q35), Embodiment (Q37, Q41, Q43) Emotion (Q43, Q45). questions probe kind experience generated music.Kind_of_experience subdivided Immersion (Q31, Q33, Q35), Embodiment (Q37, Q41, Q43) Emotion (Q43, Q45). questions probe kind experience generated music.additional questions demography hours listening (Q50), hours playing (Q51), education (Q52), listener’s age (Q53), gender (Q54).\nalso two questions arousal (Q3) valence (Q4) attributes music. questions span space divided four parts (see ).utilizing questionnaire, researchers can effectively gather data understand analyze components music appreciation outlined theory.","code":""},{"path":"chapListener.html","id":"survey-and-data","chapter":"3 Listener appreciation","heading":"3.5 Survey and data","text":"Validation theory based large survey.\nsurvey conducted collaboration VRT-Klara, classic music radio Flemish radio television broadcasting company. edition Klara-Top100 2023, listeners participate survey, using redirect survey platform (Qualtrix) mounted Ghent University. Approximately 1200 listeners responded survey 807 listeners completed entire questionnaire.questionnaire set two parts first part, listener focus high appreciation, coded Liking Q57, second part, listener focus low appreciation, coded Disliking Q57.data looks like:1614 observations come 807 subjects rated two pieces music, one Liking one Disliking.\nBasically, datset reflects questionnaire, except labels constructed top, Q57, Quality (based Q6, Q8, Q10, Q12, Q14, Q16), ArousalValence_category (based Q3, Q4).","code":"## 'data.frame':    1614 obs. of  38 variables:\n##  $ Title                  : chr  \"Concerto in D voor viool en orkest op35 3Finale\" \"Miserere\" \"Comptine dun autre t\" \"BWV 0248: Weihnachtsoratorium (Jauchzet, frohlocket! Auf, preiset die Tage)\" ...\n##  $ Composer               : chr  \"Tsjaikovski, Pjotr Iljitsj\" \"Allegri, Gregorio\" \"Tiersen, Yann\" \"Bach, Johann Sebastian\" ...\n##  $ Q1                     : num  10 10 9 9 10 9 10 10 10 10 ...\n##  $ Q2                     : num  1 1 1 1 1 1 2 1 1 1 ...\n##  $ Q3                     : num  5 2 2 4 5 NA 5 2 1 2 ...\n##  $ Q4                     : num  5 4 5 5 2 4 5 2 4 NA ...\n##  $ Q6                     : num  1 1 1 1 0 0 1 1 1 1 ...\n##  $ Q8                     : num  1 1 1 1 1 1 1 0 1 1 ...\n##  $ Q10                    : num  0 0 0 0 0 0 0 0 0 0 ...\n##  $ Q12                    : num  0 1 0 0 0 0 0 1 0 0 ...\n##  $ Q14                    : num  0 0 0 0 0 0 0 0 0 0 ...\n##  $ Q16                    : num  0 0 0 0 0 0 0 0 0 0 ...\n##  $ Q18                    : num  4 5 4 4 3 3 4 4 5 4 ...\n##  $ Q20                    : num  4 4 3 4 3 3 4 2 5 4 ...\n##  $ Q22                    : num  5 4 4 4 3 4 4 4 5 4 ...\n##  $ Q24                    : num  5 5 3 4 3 4 4 2 5 4 ...\n##  $ Q26                    : num  3 5 4 4 3 4 4 4 5 4 ...\n##  $ Q28                    : num  1 3 1 2 1 1 1 2 1 1 ...\n##  $ Q29                    : num  NA 3 NA 2 NA NA NA 4 NA NA ...\n##  $ Q31                    : num  4 4 3 4 5 3 4 5 5 3 ...\n##  $ Q33                    : num  4 4 4 3 4 4 4 4 5 3 ...\n##  $ Q35                    : num  4 5 4 4 4 3 4 5 5 4 ...\n##  $ Q37                    : num  5 4 2 3 4 4 3 3 4 4 ...\n##  $ Q39                    : num  4 2 2 2 4 2 4 3 1 3 ...\n##  $ Q41                    : num  3 5 2 3 3 3 3 5 5 4 ...\n##  $ Q43                    : num  4 5 4 4 4 4 4 4 5 3 ...\n##  $ Q45                    : num  5 5 3 3 4 3 4 3 5 4 ...\n##  $ Q47                    : num  5 5 5 5 5 4 5 5 1 5 ...\n##  $ Q48                    : num  5 5 5 5 5 4 5 5 1 5 ...\n##  $ Q49                    : num  1 1 1 1 1 1 1 1 1 1 ...\n##  $ Q50                    : Factor w/ 7 levels \"0\",\"0m-15m\",\"15m-30m\",..: 7 4 6 7 7 6 7 7 7 5 ...\n##  $ Q51                    : Factor w/ 7 levels \"0\",\"0m-15m\",\"15m-30m\",..: 1 1 1 1 1 1 1 1 1 3 ...\n##  $ Q52                    : num  0 0 0 0 0 0 0 0 0 3 ...\n##  $ Q53                    : Factor w/ 10 levels \"11-20\",\"21-30\",..: 6 4 7 6 6 7 7 6 6 7 ...\n##  $ Q54                    : Factor w/ 3 levels \"male\",\"female\",..: 2 2 2 2 1 1 2 2 2 2 ...\n##  $ Q57                    : chr  \"Liking\" \"Liking\" \"Liking\" \"Liking\" ...\n##  $ Quality                : num  2.5 1.33 2.5 2.5 1 ...\n##  $ ArousalValence_category: chr  \"high_pos\" \"low_pos\" \"low_pos\" \"high_pos\" ..."},{"path":"chapListener.html","id":"inspect-the-data","chapter":"3 Listener appreciation","heading":"3.6 Inspect the data","text":"Exploration data via plotting always useful.","code":""},{"path":"chapListener.html","id":"appreciation","chapter":"3 Listener appreciation","heading":"Appreciation","text":"show global appreciation (labelled dataset : Q1) scale 1 10, per category Liking Disliking.\nhighest appreciated music gets mean 9.42, standard deviation 0.88.\nlowest appreciated music gets mean 2.89 standard deviation 1.66.\nApparently, highest appreciated music somewhat better defined lowest appreciated music , case still gets overall appreciation 5/10 rare cases even 6/10.\nFigure 3.3: Distribution scorings global appreciation (Q1) music qualified Liking Disliking (Q57), mean standard deviation indicated\n","code":""},{"path":"chapListener.html","id":"participants","chapter":"3 Listener appreciation","heading":"Participants","text":"quick view participants shows striking facts. 43% 61-70 years old 17% younger 50 years old. twice many females compared men. majority low level music education. main interaction music listening, playing.\nFigure 3.4: info listeners\n","code":""},{"path":"chapListener.html","id":"affect-attribution","chapter":"3 Listener appreciation","heading":"Affect attribution","text":"listeners’ attribution arousal (Q3) valence (Q4) probed Likert scale 1 5.\nscores can interpreted coordinates -called circumplex model affect20, shown figure 3.5.\nuse identify four different attributed affect categories music.High-arousal high-valence defined happyHigh-arousal high-valence defined happyhigh-arousal low-valence defined aggressivehigh-arousal low-valence defined aggressivelow-arousal high-valence defined relaxinglow-arousal high-valence defined relaxinglow-arousal low-valence defined sad.low-arousal low-valence defined sad.horizontal vertical band middle show neutral zone listeners gave score 3 either question.\nscores reveal interesting pattern.\nRelaxing music liked lot, aggressive music mostly disliked.\nLikewise, happy music mostly liked, sometimes disliked.\nsad music, seems, often disliked, often also liked.\nFigure 3.5: Liked disliked music categorized arousal valence 5-point scale. show distributions point, added jitter\nOverall, seems quite structure dataset.\nCronbach’s alpha gives value 0.84, considered good excellent, meaning internal consistency dataset high. mean value correlations among subjects 0.54.\ncan said data restrict minimum needed modelling.\nTable 3.1: Cronbach alpha mean\n","code":""},{"path":"chapListener.html","id":"preparing-analysis","chapter":"3 Listener appreciation","heading":"3.7 Preparing analysis","text":"steps follow can seen preparatory work statistical modelling.\nrationale view main question global appreciation (Q1), possible \nidentify questions low correlation Q1.\nquestions anyhow really affect Q1 therefore can deleted.start , consider figure 3.6.\nleft panel shows correlation among (numerical) questions.\nFigure 3.6: Correlation matrices. (left) original, (right) pruned\ncheck contributes Q1, may suffice look first vertical column (Q1 label).\nimportant questions high correlation values. decided \nquestions correlation value less \\(.5\\) can deleted – , , set zero.leftovers shown right panel.\n: Q2, Q31, Q33, Q35, Q37, Q39, Q41, Q43, Q47, Q48, Q49, Quality.\nBasically, questions probe structural features music correlate high, either difficult, /listeners subjective focus selected aspects, captured Quality. Also Q45 left , probably listeners interpreted question different ways.short, based somewhat arbitrary correlation threshold, pruned version questionnaire obtained.\nquestions pass threshold can now considered candidates model.\nLet us see far get modelling.","code":""},{"path":"chapListener.html","id":"structural-equation-modelling","chapter":"3 Listener appreciation","heading":"3.8 Structural equation modelling","text":"structural equation model (SEM) implements DAG shown figure 3.2 statistical model. Meanwhile, however, identified questions therefore, now , use question labels used table @ref(tab:chapListener_datasetQ).SEM estimates strength significance association variables.\n, can assess fit model observed data, evaluate overall model’s explanatory power. ’s validity.","code":""},{"path":"chapListener.html","id":"model","chapter":"3 Listener appreciation","heading":"Model","text":"SEM follows syntax R-package lavaan.\noperator =~ defines confirmatory factor analysis, used created latent variable.\nexample, Evaluation constructed Q47, Q48 Q49.\nSimilarly, Immerson, Embodiment Emotion latent variables, define Kind_of_experience.\noperator ~ defines regression, used relate response variable predictor variables.\nQuality (indicator) link Kind_of_experience Kind_of_experience Evaluation.\n, Evaluation Q2 predictors Q1, called Global_appreciation DAG figure 3.2.","code":"\n  model_1 <- '\nEvaluation =~ Q47 + Q48  + Q49\nImmersion =~ Q33 + Q35 + Q31 \nEmbodiment =~ Q37 + Q39 + Q41\nEmotion =~ Q43\nKind_of_experience =~ Immersion + Embodiment + Emotion\nKind_of_experience ~ Quality \nEvaluation ~ Kind_of_experience\nQ1 ~ Evaluation + Q2'"},{"path":"chapListener.html","id":"covariance-matrix","chapter":"3 Listener appreciation","heading":"Covariance matrix","text":"Mathematically speaking, SEM fits covariance matrix \\(\\Sigma(\\theta)\\) defined model covariance matrix \\(\\Sigma\\) data. optimal fitting:\n\\[\n\\Sigma = \\Sigma(\\theta),\n\\]\n\\(\\theta\\) parameters model.pruned questionnaire contains 12 questions 800 respondents answered questions. gives us 12x12 covariance matrix questions (\\(\\Sigma\\)), 12x12 covariance matrix questions embedded model parameters, \\(\\Sigma(\\theta)\\).\n, \\(\\Sigma(\\theta)\\) optimized approach \\(\\Sigma\\).\noptimization successful, obtained insight data viewpoint model, inspired theory music appreciation.Thus, rather just putting data unrelated box, theory suggests data structured.\ndata come measurements using questions relate theory.\nHence, can tested theory justified data.","code":""},{"path":"chapListener.html","id":"cfa-and-regression","chapter":"3 Listener appreciation","heading":"CFA and regression","text":"Let us just recall just said.\nStructure among variables, specified DAG, defined confirmatory factor analysis (CFA) regression.\nCFA generates new latent variable weighted sum variables.\nexample, latent variable Immersion generated indicators Q33, Q35, Q31.\nregression associates given variable weighted sum given variables.\nexample, Q1 (response) associated Evaluation Q2 (predictors).\nRecall Quality really latent variable anymore model obtained combining yes/questions pre-processing stage. contrast, Kind_of_experience Evaluation can considered genuine latent variables.","code":""},{"path":"chapListener.html","id":"dataset-and-sem","chapter":"3 Listener appreciation","heading":"3.9 Dataset and SEM","text":"Let’s now fit SEM data. Recall goal fitting see whether indeed structure data, defined model.Lavaan lot bells whistles. limit simple fitting use Q57 divide database two parts, based Liking Disliking.\ntwo parts database reflect fact listeners filled questionnaire twice. First preferred music, piece like.\nfitting models, obtain weights parameters associate variables.\nHowever, whether fitted model acceptable depends tests check discrepancy \\(\\Sigma\\) \\(\\Sigma(\\theta)\\).","code":"\nsemfit1 <- lavaan::sem(model_1, data = Data, \n                       group = \"Q57\",  meanstructure = TRUE)"},{"path":"chapListener.html","id":"measurement-invariance","chapter":"3 Listener appreciation","heading":"Measurement invariance","text":"use technique called called measurement invariance check consistency across different groups conditions simply comparing fit several nested models impose increasingly restrictive constraints parameters measurement model across groups. measurement invariance established, differences observed scores groups may due measurement bias rather true differences underlying construct. summary measurmement invariance.Comparing results different models (semfit1, semfit2, semfit3), can see following trends:Chi-square: models significant chi-square values (p < .05), indicating models perfectly fit data. However, often case large sample sizes, even minor deviations model can lead significant chi-square values.Chi-square: models significant chi-square values (p < .05), indicating models perfectly fit data. However, often case large sample sizes, even minor deviations model can lead significant chi-square values.RMSEA: models RMSEA values around .089-.095, within acceptable range (typically .08 good fit), indicating reasonable fit.RMSEA: models RMSEA values around .089-.095, within acceptable range (typically .08 good fit), indicating reasonable fit.CFI TLI: models CFI values around .81-.85 TLI values around .79-.81, suggesting reasonable fit.CFI TLI: models CFI values around .81-.85 TLI values around .79-.81, suggesting reasonable fit.SRMR: Model semfit1 lowest SRMR (.083), indicating better fit terms standardized root mean square residual.SRMR: Model semfit1 lowest SRMR (.083), indicating better fit terms standardized root mean square residual.AIC BIC: Model semfit1 lowest AIC value among three models, indicating better parsimony.AIC BIC: Model semfit1 lowest AIC value among three models, indicating better parsimony.Based results, conclusion might model semfit1 provides best overall fit data among three models tested. However, given minor differences among three models, measurement invariance can assumed.","code":"## ####################### Model Fit Indices ###########################\n##             chisq  df pvalue rmsea   cfi   tli  srmr        aic        bic\n## semfit1  902.093† 122   .000 .089  .849† .810  .083† 40633.042† 41042.366 \n## semfit2  956.857  130   .000 .089† .840  .811† .085  40671.807  41038.044†\n## semfit3 1125.185  136   .000 .095  .809  .783  .093  40828.134  41162.057"},{"path":"chapListener.html","id":"parameters","chapter":"3 Listener appreciation","heading":"Parameters","text":"inspect estimated parameters latent variables regression:\nlatent variables, except Q2, fit well.\ncan seen P(>|z|) Std.columns.\nlooking regression see Q2 doesn’t play role specification Q1.far second part dataset concerned, latent variables fit well.\n, Q2 doesn’t contribute much global result.Overall, model suggests Evaluation relevant predictor Q1.\nMoreover, Evaluation predicted Kind_of_experience \nImmersion strongest contributor Liking Disliking groups.Liking group, Emotion contributes Embodiment, Disliking, Embodiment contributes Emotion.\nQuality less impact Liking group, compared Disliking group.Overall, Liking group Immersion Emotion strong predictors, Disliking group, Immersion Embodiment Quality strong. like music, subjects emotionally touched. dislike music, subjects seem overall less emotionally touched. refer consistently quality music source disliking.","code":"\ns <- summary(semfit1, standardized = TRUE, rsquare = TRUE, ci = T)\nreg <- '\nGroup 1 [Liking]:\n\nLatent Variables:\n                        Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper   Std.lv  Std.all\n  Evaluation =~                                                                                \n    Q47                    1.000                               1.000    1.000    0.315    0.674\n    Q48                    0.848    0.114    7.422    0.000    0.624    1.072    0.267    0.383\n    Q49                   -0.368    0.054   -6.756    0.000   -0.474   -0.261   -0.116   -0.337\n  Immersion =~                                                                                 \n    Q33                    1.000                               1.000    1.000    0.671    0.783\n    Q35                    0.702    0.050   13.968    0.000    0.604    0.801    0.471    0.600\n    Q31                    0.856    0.058   14.747    0.000    0.742    0.969    0.574    0.649\n  Embodiment =~                                                                                \n    Q37                    1.000                               1.000    1.000    0.896    0.727\n    Q39                    0.957    0.104    9.205    0.000    0.753    1.161    0.857    0.672\n    Q41                    0.408    0.052    7.860    0.000    0.306    0.509    0.365    0.381\n  Emotion =~                                                                                   \n    Q43                    1.000                               1.000    1.000    0.681    1.000\n  Kind_of_experience =~                                                                        \n    Immersion              1.000                               1.000    1.000    0.870    0.870\n    Embodiment             0.602    0.094    6.412    0.000    0.418    0.786    0.393    0.393\n    Emotion                0.688    0.075    9.156    0.000    0.540    0.835    0.589    0.589\n\nRegressions:\n                       Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper   Std.lv  Std.all\n  Evaluation ~                                                                                \n    Kind_of_exprnc        0.322    0.040    8.028    0.000    0.244    0.401    0.597    0.597\n  Kind_of_experience ~                                                                        \n    Quality               0.089    0.027    3.300    0.001    0.036    0.142    0.152    0.141\n  Q1 ~                                                                                        \n    Evaluation            1.382    0.160    8.630    0.000    1.068    1.696    0.435    0.497\n    Q2                   -0.015    0.046   -0.318    0.750   -0.105    0.075   -0.015   -0.010\n'\n # summary(semfit1, standardized = TRUE, rsquare = TRUE, ci = T)\nreg <- '\nGroup 2 [Disliking]:\n\nLatent Variables:\n                        Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper   Std.lv  Std.all\n  Evaluation =~                                                                                \n    Q47                    1.000                               1.000    1.000    0.568    0.787\n    Q48                    0.988    0.049   20.044    0.000    0.892    1.085    0.561    0.761\n    Q49                   -0.742    0.067  -11.033    0.000   -0.874   -0.610   -0.421   -0.420\n  Immersion =~                                                                                 \n    Q33                    1.000                               1.000    1.000    0.617    0.837\n    Q35                    1.027    0.040   25.803    0.000    0.949    1.105    0.633    0.854\n    Q31                    0.775    0.059   13.041    0.000    0.659    0.892    0.478    0.467\n  Embodiment =~                                                                                \n    Q37                    1.000                               1.000    1.000    0.766    0.901\n    Q39                    0.904    0.044   20.712    0.000    0.818    0.989    0.692    0.800\n    Q41                    0.413    0.059    6.989    0.000    0.298    0.529    0.317    0.261\n  Emotion =~                                                                                   \n    Q43                    1.000                               1.000    1.000    1.287    1.000\n  Kind_of_experience =~                                                                        \n    Immersion              1.000                               1.000    1.000    0.940    0.940\n    Embodiment             0.917    0.058   15.852    0.000    0.804    1.031    0.694    0.694\n    Emotion                0.664    0.086    7.766    0.000    0.497    0.832    0.299    0.299\n\nRegressions:\n                       Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper   Std.lv  Std.all\n  Evaluation ~                                                                                \n    Kind_of_exprnc        0.840    0.051   16.573    0.000    0.740    0.939    0.857    0.857\n  Kind_of_experience ~                                                                        \n    Quality               0.205    0.017   12.108    0.000    0.172    0.238    0.354    0.453\n  Q1 ~                                                                                        \n    Evaluation            1.517    0.109   13.914    0.000    1.303    1.731    0.861    0.523\n    Q2                   -0.142    0.044   -3.190    0.001   -0.229   -0.055   -0.142   -0.098\n'"},{"path":"chapListener.html","id":"predictions","chapter":"3 Listener appreciation","heading":"3.10 Predictions","text":"following sections, show model can used predicting.","code":""},{"path":"chapListener.html","id":"j.s.-bach","chapter":"3 Listener appreciation","heading":"J.S. Bach","text":"first example, ’ll predict listeners’ overall appreciation (Q1) Bach pieces.\nCan predict Q1 Bach pieces, given SEM trained dataset Bach pieces included?\ncan happen SEM captures necessary information pieces, can predict Q1 new pieces using indicators Q47, Q48, Q33, Q35, Q31 Quality. words, SEM generalize input Q1 applies Bach.figure , distinction made training-data test-data.\ntraining-data contain data except answers 157 listeners said something Bach.\ntest-data contain Bach pieces.\n, SEM trained training-data, predictions regenerated.\nTable 3.2: Prediction Bach pieces, versus original data\nFigure 3.7 shows prediction Bach appreciation Q1_prediction original Bach appreciation data Q1_data (cor =.95). horizontal axis shows true Q1, answers given participants. vertical axis shows predicted Q1, answers generated model doesn’t know Bach. regression lines show linear regression (straight line) loess Locally Estimated Scatterplot Smoothing (sigmoid line).\ngenerate figure, see code Code/chapListener/chapListener_05_ModelPlotting.R.\nFigure 3.7: Prediction global appreciation Bach pieces\nmodel gives rather accurate prediction global appreciation Bach’s pieces.\nInterestingly, Bach’s pieces always liked.\ndepth analysis needed figure whether depends particular music pieces.","code":""},{"path":"chapListener.html","id":"attributed-affects","chapter":"3 Listener appreciation","heading":"Attributed affects","text":"second example, look latent variables viewpoint sad, relaxing, aggressive happy music.\ncategories introduced figure 3.5.\nprediction, figure 3.8 created.\nshows distribution 50 dots per latent variable latent variables scaled -2 2.\ndistributions reflect latent variable contributes Q1 sad, relaxing, aggressive happy music.\nEvaluation Experience display similar distributions, meaning appraisal experiences depends whether experiences high degree immersion.figure reveals distribution relaxing, aggressive, happy tends towards unipolar scoring, 96%, 82% 78% counted dots one side Evaluation. scoring agreement valence.\nHigh valence (relaxing happy) get high scores, low valence (aggressive) gets low scores.\nHowever, distribution sad tends bi-polar balance 62% negative evaluation.\nmeans 38% listeners, decisive opinion arousal-valence questions, attributed high Evaluation sad music thus high overall appreciation (Q1) strongly correlated.\nFigure 3.8: Latent variables SEM modelling distributions category happy, aggressive, relaxing, sad, attributed listeners\n","code":""},{"path":"chapListener.html","id":"discussion","chapter":"3 Listener appreciation","heading":"3.11 Discussion","text":"Overall, statistics supports proposed theory music appreciation.\nMusic appreciation rest mainly evaluation pleasurable experiences \nattribution quality plays role depending whether music liked disliked.main findings :listener likes music, quality scores low, compared situation listener dislikes music. can explained fact listener anticipated certain qualities music. liked music, qualities agree anticipation therefore, role less prominent qualities agree anticipation. State otherwise, people dislike music, attributed musical qualities, anticipation.listener likes music, quality scores low, compared situation listener dislikes music. can explained fact listener anticipated certain qualities music. liked music, qualities agree anticipation therefore, role less prominent qualities agree anticipation. State otherwise, people dislike music, attributed musical qualities, anticipation.causes appreciation experiences. Immersion appears important consistent predictor, embodiment emotion different roles depending whether music liked . somewhat surprising literature puts quite lot emphasis emotion. show experience unity absorption consistent strong predictors, compared felt emotions.causes appreciation experiences. Immersion appears important consistent predictor, embodiment emotion different roles depending whether music liked . somewhat surprising literature puts quite lot emphasis emotion. show experience unity absorption consistent strong predictors, compared felt emotions.connection quality experience/evaluation may intricate.\nlistener may find music high quality, example due composition, performance, , music doesn’t appeal pleasant feeling played radio. Probably, get low rating appreciation.\nHhowever, dataset don’t examples dis-accordance attributed quality experience/evaluation.\nmay due fact listeners asked give example music dislike hearing radio, finding rationale disliking.listeners asked select piece high quality, rationalize whether piece pleased hearing radio, situation might different context added.\nreason somebody doesn’t like hear music radio may due intrinsic musical qualities, context. aspect probably needs clarification follow-studies.Finally, happens listeners hear music repeatedly? Can still experience reward anticipation-reward-motivation mechanism becomes saturated? theory suggests affirmative answer.\nListeners may become entrained music. Similar locomotive pulling wagons, music propels listener point reward can consistently experienced. crux lies dynamic binding structure, known sonic moving forms ability dynamically shape anticipation melodic line, harmonic progression, rhythmic flow, tension, resolution. entrained music, embodied experiences anticipative. feeling potent, fostering sense control rewarding , thus, pleasurable (see illusion reversed causality explained chapter 1).","code":""},{"path":"chapListener.html","id":"conclusion-2","chapter":"3 Listener appreciation","heading":"3.12 Conclusion","text":"chapter, probed listeners reflect music . Using questionnaire, refined theory music appreciation. Based neurobiology, marketing musicology, causal model tested structural equation modelling approach using data questionnaire.model suggests music can cause experiences listeners immersion important experience contributing appreciation.\nCan linked dynamic concept self-augmented interactions?\nlatter indeed suggests experiences occur interaction music, rather interaction music.Related theory self-augmented interaction, expressed chapter 1, theory appreciation focuses reflective aspect, involving evaluation state reached. likely self-augmented interactions lead highly appreciated music. rationalizations appreciation may well relevant understanding self-augmentation. , appreciation theory dealing -line situation, whereas self-augmentation theory attempts grasping -line situation.chapters follow, focus less appreciation, less experiences even. Instead, look music interactions viewpoint performance.\nsense, put emphasis encoders (dancers, musicians) decoders (listeners).","code":""},{"path":"chapDancer.html","id":"chapDancer","chapter":"4 Dancer synchronization","heading":"4 Dancer synchronization","text":"chapter21 look music dancers classical ballet, assuming roles prescribed narrative.\ninvestigate music, constant given audio track, influences timing dancers.\nparticular, show repeats musical structure, repeats musical fragments phrases within fragments, somehow influence micro-timing dancing without dancers aware influence.code can found following scripts data preparation plotting, modelling plotting, contrast analysis plotting:","code":"\nsource(\"Code/chapAll_00_Initialization.R\")\nsource(\"Code/chapAll_01_Functions.R\")\nsource(\"Code/chapDancer/chapDancer_02_DataPreparation.R\")\nsource(\"Code/chapDancer/chapDancer_03_DataPlotting.R\")\nsource(\"Code/chapDancer/chapDancer_04_Modelling.R\")\nsource(\"Code/chapDancer/chapDancer_05_ModelPlotting.R\")\nsource(\"Code/chapDancer/chapDancer_06_Contrasts.R\")"},{"path":"chapDancer.html","id":"theory-1","chapter":"4 Dancer synchronization","heading":"4.1 Theory","text":"dance solo Swan Lake (1875–76) Pyotr Ilyich Tchaikovsky’s ballet composition taken example study micro-timing. dance forms part narrative Princess Odette’s metamorphosis swan, orchestrated malevolent sorcerer. Accordingly, dancers articulate swan personas movements unfold precise swan-like alignment musical cadence. dance solo known Odile variation famous solo dance taken ballet. recorded laboratory dancers heard audio track.\nrecordings form starting point studying effect phrase repeats micro-timing dance-music synchronizations.22The synchronization body movement musical beat sensory-motor process, guided brain predictions timing. classic example human finger tapping metronome. micro-timing level, measured milliseconds centiseconds, seems synchronization largely automated process based error-correction mechanisms, although skilled performers can exert top-influence. instance, experienced jazz musicians can intentionally play laid-back -beat, affecting micro-timing introducing varying levels anticipation synchronization fellow musicians. Given observations, research focus whether micro-timing can independently influenced mere repetition musical structure, devoid intentional even vaguely intentional acts. repetition musical structure influences micro-timing, another interesting example top-influence synchronization activity.Classical ballet offer good example, given musical structure expressed narrative.\nmechanisms underlying potential influence perceived musical structure micro-timing likely associated memory, anticipation, expression. Repetition choreographic sequences intricately linked memory anticipation/prediction frameworks.generally assumed training, movement sequences become stored motor memoryso cognitive effort required activation performance reduced. However, precise dynamics interaction retrieval high-level (cognitive) sequences execution low-level (sensory-motor) synchronized micro-timing may hinge effectiveness established prediction model.work hypothesis adopted chapter dance-music sequence establishes timing model dancer. sequence repeated shortly , established timing model facilitates micro-timing sequence. hypothesis facilitation translates subtle increase anticipation. assume likely dancer intuitively uses effect expressive element drive create tension. line theory self-augmented music interaction (chapter 1), dancing along music create illusion reverse causality, dancing causes music. illusion may generate arousal turns affects dancing, thus providing ingredients expressivity context self-augmentation.timing dancer can understood Bayesian perspective. establishment timing model can understood prior affecting likelihood synchronized events occur time. prior can adapted view past experiences future anticipations, repeated phrases, expression arcs propulse future. outcome likely reflected relative phase, , time difference musical event movement event, probably due intuitions artistic expression rooted.statistical modelling point view, challenge check whether repeated music-dance fragments, repeated phrases within fragments, show differences micro-timing.\nTherefore, suitable music-dance representation needed, using events extracted music dance. , suitable statistical model music-dance events developed, phrases can contrasted terms synchronization differences.","code":""},{"path":"chapDancer.html","id":"experiment","chapter":"4 Dancer synchronization","heading":"4.2 Experiment","text":"dataset contains recordings 3 ballerinas performing Odile variation, masterpiece female classical ballet occurs Act III Swan Lake ballet. analysis applied dance figure within variation, known Promenade Arabesque. dance figure, dancer performs promenade (turn walk) holding arabesque position. uses turnout motion standing foot leg rotate position solid posture, see figure 4.1 performance23.\nFigure 4.1: Arabesque figure ASIL, art science lab UGent\nObviously, data three ballerinas extremely meager. However, draw upon repeated measure confine main conclusions limited population.\nOdile variation, Promenade Arabesque occurs twice, dance fragments called F1 F2. shown figures 4.2 4.3, fragment repeated phrase. F1 phrase structure form ,B,,B F2 ,B,,C’, C phrase leading different part piece.\nDancers requested perform 12 times Promenade Arabesque isolated figure (.F1), followed entire Odile variation isolation F1 F2 embedded succession.Note repeats occur, level fragments, level phrases within fragments. Moreover, dancers requested perform task 12 times.repeated measures design thus implies 12 trials entire task might interest check whether trials generate additional effect measurement, example, due fatigue.\n12 trials, exclude trial 5 trial 8 trials entailed experimental manipulation relevant present study.\nFigure 4.2: Fragment F1\n\nFigure 4.3: Fragment F2\n","code":""},{"path":"chapDancer.html","id":"hypotheses","chapter":"4 Dancer synchronization","heading":"4.3 Hypotheses","text":"statistical modelling aim figuring whether () fragments different, (ii) phrases within fragments different,\nwhether (iii) bias trials due repeated measures.\nquestions may formulated hypotheses expectations based theoretical considerations:hypothesis 1: fragments different, assume prediction model influence micro-timing, allowing anticipation.hypothesis 1: fragments different, assume prediction model influence micro-timing, allowing anticipation.hypothesis 2: phrases within fragments different, assume prediction model influence micro-timing allowing anticipation.hypothesis 2: phrases within fragments different, assume prediction model influence micro-timing allowing anticipation.hypothesis 3: trails show bias towards less anticipation due fatigue.hypothesis 3: trails show bias towards less anticipation due fatigue.","code":""},{"path":"chapDancer.html","id":"data","chapter":"4 Dancer synchronization","heading":"4.4 Data","text":"Given focus timing, performance can reduced time events occur.\nmusical event beat-onset study, measured manually experts.dance event either heel_up heel_down event. heel_up event occurs vertical displacement heel maximal, heel_down event occurs vertical displacement heel minimal, touching ground. Heel movement measured motion caption system using infra-red reflexive markers allow accurate measurement position millimeters time milliseconds. Given 3-dimensional motion caption signal heel, vertical dimension suffices extract time maximum minimum values occur. time indications heel_up heel_down events.\nTable 4.1: Dataset dancer\ncolumn indicated phase holds relative phase, , time heel event relative time previous musical beat event context defined next musical beat event, multiplied \\(2\\pi\\), expressed range \\([0,2\\pi]rad\\), see formula\n(2.3).column indicated time0 holds time events start fragment.\nfactors Fragment, Participant, Heel, Trialf.\nFragment 3 levels (“.F1”, “F1”, “F2”) indicating 3 fragments,\nParticpant 3 levels (“P2”, “P3”, “P4”), indicating 3 participants,\nHeel 2 levels (“HeelsUp”, “HeelsDown”), \nTrialf 12 levels (“01”, “02”, “03”, “04”, “05”, “06”, “07”, “08”, “09”, “10”, “11”, “12”). mentioned, trial “05” “08” dataset.visual representation heel_down events per fragment, including participants trials, shown figure 4.4. right panel axis data rotated \\(0 [rad]\\) appears middle vertical axis, using formula rotating axis data, see equation (2.4).\nfollows, always use rotated representation represent relative phase.\nFigure 4.4: Plot relative phase heel-events fragments IF1, F1 F2, (top) scale 0 2pi, (bottom) scale -pi +pi.\nview data immediately suggests fragments might indeed different . first sight, difference can observed F1 F2, lower relative phase values F2 F1. Lower values imply shorter delay, eventually larger anticipation, heel-event, given beat event.addition overall trend, different trials per fragment, represented colored vertical circles next , suggest trend towards higher values. implies delay less anticipation respect musical beat. Although trend somewhat prominent .F1 compared F1 F2, doesn’t overrule major difference fragments.\nRecall difference fragments might due anticipation/prediction mechanisms. However, trend trials, clearly visible .F1, may due fatigue.let’s proceed inspection data. Consider heel events evolve time. figure 4.5, view heel-events trial 1 F1 shown next view trials F1. horizontal axis time starting beginning fragment F1.\nvertical axis phase heel-event relative musical beat event, expressed radians. Note vertical lines slightly tilted right. ’s time relative phase related.\nFigure 4.5: Plot heel-events three different dancers fragment F1, (top) one single trial, (bottom) trials\nfigure reveals relative phase decreases time proceeds, suggesting micro-timing changes performance proceeds. left picture, suggestive see change relative phase values around 8-9 seconds. dots appearing 0 8 seconds seem higher dots appearing 9 16 seconds. correspond phrase 1-2 phrase 3-4 figure 4.3.Overall, visualization data suggests hypotheses probably confirmed solid quantitative tests using statistical modelling.","code":""},{"path":"chapDancer.html","id":"regression-1","chapter":"4 Dancer synchronization","heading":"4.5 Regression","text":"goal find statistical support trends observed data.\nfirst focus fragments.\nidea extract mean variance fragment data, disregarding variance possibly due repeated measures.\ncomparison reveal whether fragments different among conditions.\nanalysis similar ANOVA, except data circular, use hierarchical distributional approach. group-level variable Trialf model two parameters von Mises response distribution model mean Phase, kappa, scale parameters model. next section, add time.","code":""},{"path":"chapDancer.html","id":"model-1","chapter":"4 Dancer synchronization","heading":"Model","text":"model specification brms shown :first line says Phase response, Fragment, Participant, Heel Trialf predictors. intercept, indicated 1 syntax, captures overall mean data.\npredictors Fragment, Participant, Heel corresponding parameters reveal population-level effects.\npredictor Trialf corresponding parameter reveals group-level effect, , effect among levels Trialf, assuming normal distribution variability.second line says also kappa response, using specification predictors top part.\nGiven circular response distribution, link function von_mises, parameter corresponding gaussian sigma called kappa.\ndefined :\n\\[\nf(x | \\mu, \\kappa) = \\frac{1}{2\\pi I_0(\\kappa)} \\exp(\\kappa \\cos(x - \\mu))\n\\]\n:\n\\(x\\) observed value unit circle (angle),\n\\(\\mu\\) mean direction parameter,\n\\(\\kappa\\) concentration parameter (measures dispersion distribution), \n\\(I_0(\\kappa)\\) modified Bessel function order 0:\n\\[\nI_0(\\kappa) = \\frac{1}{\\pi} \\int_{0}^{2\\pi} e^{\\kappa \\cos(\\theta)} d\\theta\n\\]non-circular regression model, used gaussian link function sigma specification variance parameter.\ncode found Code/chapDancer/chapDancer_04_Modelling.R.alert reader may object data, shown figure 4.4 doesn’t need circular link function data look much gaussian. ’s true therefore, non-circular model gaussian link function may work data. However, considering entire dataset, including heels-events, circularity pops clearly, many data points top figure. reason, circular model better choice apply entire dataset.","code":"\nformula = bf(Phase ~ 1 + Fragment * Participant * Heel + (1| Trialf),\nkappa ~ 1 + Fragment * Participant * Heel + (1 | Trialf))\nfamily = von_mises()"},{"path":"chapDancer.html","id":"model-check","chapter":"4 Dancer synchronization","heading":"Model check","text":"useful check good response distribution fitted, using visual tool called pp_check() brms.\nposterior predictive check shows model’s prediction response.\nfollowing figure see fit response (yrep y), acceptable.\nFigure 4.6: Posterior predictive check\n","code":""},{"path":"chapDancer.html","id":"model-plotting","chapter":"4 Dancer synchronization","heading":"Model plotting","text":"Figure 4.7 shows results applying model dataset two figures. cloud points just data. modelling result specified terms big dots error bars. extract correct data correct predicted mean critical interval (CI-95%) means, per group, posterior, can use circular statistics. two figures show difference using circular statistics using circular statistics, using regular plotting routines instead. slight differences due circularity data. Recall CI-95% means estimates mean fall interval 95% cases. way calculate can found Code/chapDancer/chapDancer_05_ModelPlotting.R.\nFigure 4.7: Mean variance heel conditions fragments. Circular (left) versus non-circular (right) statistics posterior\nnext figure 4.8 go detail looking participant fragments. also use circular statistics plotting, although difference non-circular plotting can neglected.plot two error bars per mean.\none large horizontal lines shows CI-95% variance Trialf included.\nerror bar short horizontal lines shows CI-95% variance Trialf excluded.\ndifference two error bars suggests group-level effect, , effect repeated measures.now ready calculate contrasts show differences among fragments.\nFigure 4.8: Showing mean variance dancer among fragments\nproceed, briefly summarize far.\nFirst, retrieve posterior predictive distributions use brms function epred_draws(). uses fitted model dataset generate draws expected value posterior distribution. piece code can found Code/chapDancer/chapDancer_05_ModelPlotting.R:First read posterior fitted model call model1.\nNext sample posterior 500 samples (ndraws = 500, per Heel, Fragment, Participant), including group-level effects (re_formula = NULL), using critical interval prob = .95.\ndata frame generate predictions data frame used fitting model: newdata = LL_data_1_2. fitted Bayesian model model1.\nungroup data frame, select relevant parameters, store results pred_NULL.\ndata frame contains total 2221000 observations .epred factors Heel, Fragment Participant.calculate circular mean CI-95% .epred values.\ncareful take factors account:Note calculations draw upon R-package circular calculate mean standard deviation circular scale, CI-95% standard deviation.\nBasically, similar calculations discussed chapter 2. calculate mean,\nobservation treated unit vector, point unit circle. resultant vector observations found, direction resultant vector returned. called synchronization delay \\(\\alpha\\).\nstandard deviation defined square root minus 2 times log mean resultant length \\(R\\) divided number observations.\nGiven predsum_NULL use simple formula go fron standard deviation CI-95%.","code":"\nmodel1 <- readRDS(\"Fitted/chapDancer_Model1.rds\")\npred_NULL <-\n  epred_draws(model1, newdata = LL_data_1_2, re_formula = NULL, ndraws = 500, prob = .95) %>%\n  ungroup() %>%\n  dplyr::select(Heel, Fragment, Participant, .epred)\n  predsum_NULL <- pred_NULL  %>% group_by(Fragment, Heel, Participant) %>% \n    summarize(mean_angle = mean.circular(.epred),\n              sd_angle = sd.circular(.epred), \n              len = n()) %>% ungroup()\n  \n  pred_NULL <- predsum_NULL %>% group_by(Fragment, Heel, Participant) %>% \n    mutate(ci.lower = mean_angle - 1.96 * sd_angle ,\n           ci.upper = mean_angle + 1.96 * sd_angle )"},{"path":"chapDancer.html","id":"contrasts","chapter":"4 Dancer synchronization","heading":"Contrasts","text":"Using R-package brms, contrasts can estimated considering difference two posterior predictive distributions, drawn fitted model’s predictions. prefer method rather looking posterior distributions model parameters distributions can hard interpret model complex. way retrieve posterior predictive distributions via posterior_epred(). computes summaries draws expected value (.e., mean) posterior predictive distribution. Alternatively one can use epred_draws() %>% median_qi(). latter takes raw draws summarizes .Figure 4.9 illustrates works contrast two ballet fragments, .F1 F1, using heels-condition.\ntop, posterior predictive distributions mean two segments called seg1 seg2, standing .F1 F1, respectively.order get distributions equal number samples – need subtract distributions (see ) – define two counterfactual datasets equal number time points segment, regardless segment duration original data.\nAssuming data_seg1 datseg2 contain data segment 1 segment 2, calculate new data frame using data_grid, follows:Accordingly, fitted model can now used generalize specified time points new data, thus generate wanted predictions, stored pp_seg1 pp_seg2.Details provided Code/chapDancer/chapDancer_06_Contrasts.R also plotting.Consider figure 4.9 .F1 F1 Heelsdown shown.\nseg1 (.F1), mean \\(0.44 [rad]\\), seg2 (F1), \\(0.21 [rad]\\). Subtracting distributions implies equal amount draws distributions (meanwhile) subtract (randomly drawn) samples .gives new distribution diff_seg12 represents seg1 - seg2.\nunits also radians, indicating contrast seg1 seg2.\nprobability mass distribution zero, mean difference close \\(0.23 [rad]\\).\nmeans strong support contrast segments, meaning seg1 higher values seg2, higher relative phase, implying seg2 anticipative.Assume posterior distributions overlapped , likely many samples one distribution close many samples distribution, generating values zero close zero. Accordingly, zero come picture probability mass positive, negative.\n95% probability mass either positive negative (called: probability direction, pd) strong support high contrast. percentage matter choice24.data panel shows thumbnail events time, just additional check talking : posterior distributions obviously apply means data, regardless time.\nFigure 4.9: Contrasts (see text explanation)\nTable 4.2 shows contrasts among fragments heels-condition. labels est1 est2 show mean posterior predictive distributions fragments indicated, estdiff mean difference distribution, pd>0 indicating probability mass estdiff zero, expressed percentage.\nTable 4.2: Contrasts among fragments heel-condition\ntable easy see fragments contrast, size contrast radians.","code":"\nnewdata_seg1 <- data_seg1 %>% \n  data_grid(Timeregion, Trialf, Participant, Fragment, Heel, \n            time0 = seq_range(time0, 25))\nnewdata_seg2 <- data_seg2 %>% \n  data_grid(Timeregion, Trialf, Participant, Fragment, Heel, \n            time0 = seq_range(time0, 25))\npp_seg1 <- posterior_epred(fit, newdata = newdata_seg1, re_formula = NA) \npp_seg2 <- posterior_epred(fit, newdata = newdata_seg2, re_formula = NA)diff_seg12 <- pp_seg1 - pp_seg2 %>% data.frame()"},{"path":"chapDancer.html","id":"smooth-regression-1","chapter":"4 Dancer synchronization","heading":"4.6 Smooth regression","text":"slightly advanced type modelling obtained mean variance calculated time, fragment, trials, participants, using circular representation relative phase heel-beat events.\ncan done smooth regression modelling: () calculate mean time music-dance phrase, (ii) give us mean variance due repeated measures eliminated, allow (iii) contrast checks music-dance phrases.","code":""},{"path":"chapDancer.html","id":"model-2","chapter":"4 Dancer synchronization","heading":"4.6.1 Model","text":"model smooth term specified time0, time seconds fragment, starting zero. smooth term accounts factor called HeelFragment, specifies interactions Heel Fragment levels. simple way handle interaction create new column HeelFragment data set interaction defined factor.model specification thus contains general intercept overall mean, intercept per level HeelFragment, smooth term time level HeelFragment. addition, variance modeled per participant, repeated measures related participant. notation 1|Participant/Trialf equal 1|Participant + 1|Participant:Trialf means variance among participants accounted assuming drawn normal distribution. words, trials nested within participant assumed also trials can drawn normal distribution.model computational intensive therefore, ran server rather laptop.\ncalculated model comes code Code/chapDancer/chapDancer_02_ModelPlotting.R.","code":"\nformula = bf(Phase1 ~ 1 + HeelFragment + s(time0, by = HeelFragment) + \n               (1  |  Participant/Trialf ),\n             kappa ~ 1 + HeelFragment + s(time0, by = HeelFragment) + \n               (1  |  Participant/Trialf ) )\nfamily = von_mises()"},{"path":"chapDancer.html","id":"model-plotting-1","chapter":"4 Dancer synchronization","heading":"4.6.2 Model plotting","text":"\nFigure 4.10: Showing floating mean variance dancer among fragments\nFigure 4.10 now shows heel events colored dots, lines indicating mean time, grey bands indicating uncertainty mean (95%-CI).inspection figure suggests plateau 3 8 seconds, another one 9 15 seconds (except F2 data stop 11 seconds). Now question whether plateau’s can substantiated terms statistical contrast.","code":""},{"path":"chapDancer.html","id":"contrasts-1","chapter":"4 Dancer synchronization","heading":"4.6.3 Contrasts","text":"Figure 4.11\nshows contrasts two segments, time intervals identified seg1 = \\([2.51, 4.25]sec\\) seg2 = \\([4.26, 6.00]sec\\) fragment F2 heels-.\nfigure shows posterior distribution mean seg1 seg2, well difference distribution seg1 - seg2. panel data shows thumbnails fragments seg1 seg2 indicated red.\ndistribution corresponding seg1 - seg2 include zero, probability mass one side zero equal higher 95% strong support claim means different.\nexample, segments different .\nFigure 4.11: Contrast two segments\nsummary table provides information need moment.\nlabel fragment\nindicates fragment segments contrasted,\nlabel contrast shows times segments contrasted, example segment \\([0.00, 4.25]s\\) versus segment \\([9.00, 13.25]s\\).\nlabels est, est2 estdiff show estimated mean first second segment, difference, pd>0 probability direction greater zero.\nTable 4.3: Contrasts among time segments heel-condition\nTable 4.3 best understood reference \nfigure 4.2.\nfigure, indicated sections phrases within fragments.\nPhrase 1 repeated phrase 3, phrase 2 repeated phrase 4.time segments defined table 4.3 correspond less phrase indications.\ntable shows \nsegments corresponding repeats phrases show contrast, segments corresponding repeats phrases show contrast.\nfindings support hypothesis 2, phrases within fragments different. assumed prediction model influences micro-timing allowing anticipation.repeat key aspect computation based drawing posterior predictive distributions segments can compared basis equal number samples spread segment.\ndata_grid() possible generate evenly spaced grid new data points using model. ? model. Even segments different intervals time, missing data points, grid can used draw posterior predictive distributions, can compared .","code":""},{"path":"chapDancer.html","id":"conclusion-3","chapter":"4 Dancer synchronization","heading":"4.7 Conclusion","text":"Given current knowledge sensory-motor synchronization, memory anticipation/prediction, contrast analysis seems support idea sequence establishes micro-timing model dancer. sequence repeated shortly , established micro-timing model facilitates timing events sequence, translates subtle shift relative phase, direction suggesting increase anticipation. Statistical modelling allows dealing circularity response (relative phase radians) hierarchical representation repeated measures nested within subjects different variances conditions. resulting model called circular-linear hierarchical distributional smooth regression ’s long name, isn’t ?Overall, question whether repeats musical sequence somehow influence micro-timing synchronization step understanding artistic expression terms interaction cognitive sensory-motor level. useful future technological mirrors, dancers monitor performances order become aware intuitions perhaps fine-tune artistic espression basis.Finally, introduce theory self-augmented interactions. present results indicate sequences influence micro-timing direction increased anticipation. Given anticipation often linked arousal satisfaction, appears structure may enhance interaction, providing boost augmentation.","code":""},{"path":"chapViolinist.html","id":"chapViolinist","chapter":"5 Violin player visual feedback","heading":"5 Violin player visual feedback","text":"previous chapter looked effect musical structure micro-timing dancers solo-dance, look effect visual feedback instrumental learning.25Imagine orchestra string section. Typically, members string section, violinists, bowing movements going synchronized manner, appear one single organism moving together. Less experienced violinists learn play sync principal violinist section. need learn bowing gestures well particular expression associated .Now, imagine audiovisual play-along system visual representation principal violinist orchestra teacher-avatar. Wouldn’t cool system train , violinist? happens teacher-avatar visible 3D, Hololens? benefit learning?ultimate goal present chapter check effectiveness 3D play-back system learning play orchestra, compared 2D play-back system.\nfigure easy matter, due entire setup resources available. Typically, deal small number participants different levels musical experience.Owing reasons, least novelty highly technical character study, chapter highly exploratory.\nshows flexibility Bayesian statistical modelling studies time important, even focusing individual musicians.Learning perform violinist orchestra multifaceted process involves structured practice, anticipatory behavior, collaborative engagement, continuous feedback. elements work together create self-augmented interaction, violinist’s skills abilities continually enhanced engagement orchestra.modelling techniques introduced previous chapter partly repeated present chapter. Data chapter can found Campo et al. (2023a, 2023b), software available Campo et al. (2024). See also Michalko et al. (submitted).\ncode can found following scripts data preparation plotting, modelling plotting, contrast analysis plotting:","code":"\nsource(\"Code/chapAll_00_Initialization.R\")\nsource(\"Code/chapAll_01_Functions.R\")\nsource(\"Code/chapViolinist/chapViolinist_02_DataPreparation.R\")\nsource(\"Code/chapViolinist/chapViolinist_03_DataPlotting.R\")\nsource(\"Code/chapViolinist/chapViolinist_04_Modelling.R\")\nsource(\"Code/chapViolinist/chapViolinist_05_ModelPlotting.R\")\nsource(\"Code/chapViolinist/chapViolinist_06_Contrasts.R\")"},{"path":"chapViolinist.html","id":"theory-2","chapter":"5 Violin player visual feedback","heading":"5.1 Theory","text":"believe music playback system 3D teacher-avatar efficient learning 2D version?\nreason probably 3D offers richer feedback motor-control.hypothesis can tested augmented reality setting violinists wearing Hololens.\nunique capabilities allow parallax, visual changes visual scene small head movements, similar everyday life see object different angles estimate size considering close versus nearby features changing due head movements. bowing gestures violin teacher observed circumstances enables nuanced interpretation parallax possible, thus providing better feedback control bowing gestures. Parallax possible avatar seen 2D condition, teacher-avatar just projected screen.\nUsing Hololens bowing gestures can seen without parallax, depending whether scene presented 2D 3D augmented reality.Accordingly, augmented reality setting offers perfect environment testing whether parallax necessary component visual modality feedback motor control.\nFigure 5.1 shows typical measurement setup student (, b), teacher-avatar seen viewpoint student Hololens 2D (c), 3D (d).\nFigure 5.1: View teacher-avatar 2D 3D: () student violinist equipped Hololens motion tracking suit, (b) stick figure extracted, teacher-avatar 2D, (c, d) teacher-avatar 2D 3D, seen Hololens\n","code":""},{"path":"chapViolinist.html","id":"experiment-1","chapter":"5 Violin player visual feedback","heading":"5.2 Experiment","text":"experiment, eleven participants recruited, members Ghent Universitary Student Orchestra GUSO.\nengaged four practice trials spaced evenly course month, student experiencing conditions (2D, 3D). Like real orchestral playing, members string section follow principal violinist, students instructed closely imitate teacher-avatar’s bowing gestures, encompassing bowings, articulations, dynamics.Due limited amount students, design somewhat peculiar sense \nparticipant takes part two conditions (2D 3D), four trials per condition (T1, T2, T3, T4).\nHowever, conditions apply different pieces (F1, F2, F3, F4), F1 F2 first violin players, F3 F4 second violin players. two teacher-avatars, one principal violinist first violin players,\none principal violinist second violin players.\nstructure shown table .\nTable 5.1: Experimental design\nUnfortunately, design allow us check conditions per student per piece. students played one piece 2D another piece 3D.\nHowever, piece, can compare students playing 2D students playing 3D.\nexample, piece F1, student P004, P006 P009 playing 2D condition student P001, P002, P0010 playing 3D condition.\nMoreover, subject played four trials, spread four weeks.\ntwo groups, formed condition, can compared per piece.Eleven subjects much. reason experiments time-consuming subjects, play orchestra, sometimes hard find, especially participation longitudinal studies. Nevertheless, thanks four trials, consider repeated measures, just border enough statistical power.","code":""},{"path":"chapViolinist.html","id":"data-1","chapter":"5 Violin player visual feedback","heading":"5.3 Data","text":"study already published Campo et al. (2023a) bowing gesture events can downloaded Campo et al. (2023b) software available Campo et al. (2024).\nfocus aspects statistical modelling explicitly contained publications.data comes publicly available dataset (Campo et al., 2023a). describes similarity student teacher terms events, , identification bowing gesture subsequent calculation bowing similarity feature student teacher. similarity feature based Procustus distance (PD), quantifies extent deformation needed transform one gesture gesture. based scaling, rotating, translating student’s bowing gesture. Smaller PD values indicate greater similarity bowing gestures.facilitate statistical fitting, use scaled log PD call log_PD. Note cases hard define bowing events. Accordingly, several passages taken account analysis.\nuse dataset specified following table.\noriginal dataset also contains motion capture, audio, questionnaire data violinists.\nTable 5.2: Data procustus distance (PD)\nfirst three columns contain metrics Procustus Distance, PD, (scaled) logarithm logPD.\ncolumns startIndex endIndex contain start end times bowing gesture seconds.\nsample times indicated time bowing gestures sampled every .3 seconds.\ncolumns subject, trial, condition, piece factors levels (11 subjects, 4 trials, 2 conditions, 4 pieces).","code":""},{"path":"chapViolinist.html","id":"data-plotting","chapter":"5 Violin player visual feedback","heading":"5.4 Data plotting","text":"Basically, good performance defined performance student’s bowing gestures sync teacher’s bowing gestures. lower PD, similar bowing gesture resembles teacher’s bowing gesture.histogram data PD metric reveals Poisson-like distribution PD values, shown left panel figure 5.2.\nright panel shows logarithmic transformation PD values. Low values get bit stretched, high values get squeezed distribution still slightly skewed due data high PD values, especially 2D condition.\nInterestingly, difference 2D 3D mainly seen higher values, 3D fewer values, indicating better alignment.\ndotted lines show medians condition. looks 3D lower 2D.\nFigure 5.2: Density PD 2D 3D\nHowever, may differences pieces sections.\nFigure 5.3 shows data time, four different pieces (F1,F2,F3,F4) two conditions (2D, 3D).\nvertical axis shows logPD.\nhorizontal axis shows time.\ndot represents sample logPD value.\nFigure 5.3: Data four pieces two conditions\nDifferences 2D 3D subtle things can already observed visual inspection. example, first column (piece F1), first row (condition 2D), quite dots 2 2D condition, whereas dots 2 3D condition. suggests better alignment 3D. However, second column (piece F2), 75 seconds, looks higher logPD values occur 3D, compared 2D.\nFigure 5.4: Score excerpt first piece (F1), time indication seconds.\n","code":""},{"path":"chapViolinist.html","id":"smooth-regression-2","chapter":"5 Violin player visual feedback","heading":"5.5 Smooth regression","text":"focus performance time, develop analysis based smooth regression. approach, estimate similarity/synchronization metric terms smooths time. smooths represent floating mean variance time.\nsmooth regression can specified follows:expression says logPD modeled general intercept (represented “1”) two levels condition (2D, 3D), smooth time levels condition, using basis 30 splines. value logPD certain point time weighted sum spline basis functions. Furthermore, trial subject defined group-level variables, whose variance extracted estimates variables don’t contain variance. Given fact PD 1-R show Poisson-like distribution, take log apply scaling mean data zero. allows us apply gaussian link function calculated mean variance data.smooth regression implemented R-package brms comes high computational cost, due algorithms optimization. Alternatively, R-package mgcv can used. However, brms flexible mgcv offers better grip fitted model.Based fitted model using brms, extract samples posterior. particular, generate posterior predictive distribution posterior difference distribution, similar way chapter 4. posterior predictive distribution can generated using newly defined data grid time sampled, say .5 seconds, variables model accordingly sampled. entire posterior prediction contains one posterior predictive distribution per specified time point, can easily extract distributions 2D 3D condition subtract get posterior difference distribution.probability mass zero can calculated used support difference posterior predictive distribution (2D - 3D). probability mass 90% zero give strong support 2D distinct 3D. Note posterior time instance, performance 2D versus 3D can contrasted time. Obviously, can also summarize time intervals.summarize steps: () run smooth regression model, (ii) generate model-based prediction using dataset counterfactual time (e.g. sampling every .5 seconds), (iii) contrast 2D 3D predictions sampled time.","code":"\nform = bf(logPD ~ 1 + condition + s(time,k=30) + \n            s(time,by=condition,k=30) +  (1 | subject + trial))\nfam = gaussian()"},{"path":"chapViolinist.html","id":"contrasts-2","chapter":"5 Violin player visual feedback","heading":"5.6 Contrasts","text":"compare performances visual scene 2D 3D, develop contrast analysis shows us contrasts time.","code":""},{"path":"chapViolinist.html","id":"posterior-over-time","chapter":"5 Violin player visual feedback","heading":"Posterior over time","text":"\nFigure 5.5: Piece F1 audio (top panel), logPD posterior predictions 2D 3D conditions (middle panel), posterior difference 2D 3D (bottom panel). Vertical lines show regions interest.\nFigure 5.5 shows audio posterior distributions first piece used experiment.\ntop panel shows audio waveform teacher’s performance. use mainly reference, check rests fragments analysed bow gestures identified. blocks, marked vertical lines, show relevant sections bow gesture events identified. gray zones show zones bowing gesture events easily defined. Therefore, events deleted analysis.middle panel shows logPD bowing gestures 2D 3D performances subjects trials piece, see table.\nsmooths (2D gray, 3D ocre) show posterior predictive distribution calculated .5 seconds, indicating mean uncertainty condition subjects.\nNote smooths show 25% distribution’s probability mass (critical interval 25%, CI-25%). Taking CI-90% resulted much overlap less clear picture.bottom panel shows posterior difference distribution.\npoint time, 1000 samples randomly drawn (2D, 3D) posterior predictive distributions. , draw, number \\(2D\\) corresponding number \\(3D\\) subtracted (: \\(2D-3D\\)), giving 1000 new values used build new distribution, called posterior difference distribution.\nNote calculation entire distribution used, rather CI-25% shown middle panel.calculation applied points time, leading posterior difference distribution CI-90%.\nred dots horizontal line (2D-3D = 0), just indicate whether data samples available point time.Note posterior difference distribution possible based smooths posterior predictive distribution. distribution based data points (rather smooths) face problem bow strokes common onset offset. therefore, compared. smooth allows contrast!previous chapter, key trick define new data grid counterfactual time, use model generalizes time extract samples. R-code based following expressions (see: `Code/chapViolinist/chapViolinist_05_ModelPlotting.R```):Given approach, can check probability direction sampled time defined interval time.\n, certain point time, gray band completely zero, , strong support 3D lower logPD 2D, means: 3D offers better alignment teacher.gray band completely zero, strong support 2D lower logPD value 3D, means: 2D offers better alignment teacher.\ncrosses zero, depends much probability mass different zero. still 70%, one argue weak trend, 50% certainly indicate difference.short, gray band zero possible conclude student’s bowing gestures better lined 3D teacher’s bowing gestures, confirming theory parallax might offer distinctive feedback sensorimotor control needed bowing.bottom panel shows contrast analysis per time point.\ngraph seems suggest alignment favor 3D, meaning 3D works better 2D.\ntime instances, many.","code":"\nnewdat <- data %>% data_grid(time = seq(time_begin, time_end,by=.5))\npost_pred_distr <- epred_draws(fit, newdat, scale = \"response\", re_formula = NA) "},{"path":"chapViolinist.html","id":"considering-blocks","chapter":"5 Violin player visual feedback","heading":"Considering blocks","text":"useful look data blocks.\nfigure 5.5 blocks marked time intervals \n\\([3.6, 38.7]\\),\n\\([53, 88]\\),\n\\([97.3, 99]\\),\n\\([127,145]\\),\n\\([165, 180.5]\\) seconds, indicated vertical red lines.First consider block one two.\nreference still bottom panel figure 5.5.\nSee also score figure 5.4, rudimentary indication time.\nblocks, sudden short peak appears 26 77 seconds, corresponding ending phrase longer notes played.\nfirst block almost everywhere significantly different, second block, gray parts can observed, instance 63 seconds.distribution two blocks can plotted density plots, shown figures 5.6 5.7.\nmentioned, can concluded contrast condition block 1 block 2.\nFigure 5.6: Contrast block1 [3.6,26]s\n\nFigure 5.7: Contrast block 2 [53,77]s\nBased posterior smooths, possible summarize blocks time.\nTable 5.3 shows result.\nlabel left indicates piece selected interval seconds, followed mean posterior difference distribution PD, CI-95% indicated min max, followed probability direction (pd).can observed almost contrasts positive, suggesting 2D higher logPD values 3D thus 2D overall less well aligned compared 3D. However, pd shows sections strong evidence contrast. logPD difference 0.5 least needed strong evidence contrast. calculation found Code/chapViolinist/chapViolinist_06_Contrasts.R.\nTable 5.3: Contrasts defined segments different Pieces (F1,..,F4)\nConsidering block defined \\([3.6,38.7]s\\), evidence favor contrast. value pd, direction probability, says 96% distribution zero. zero (logPD value 1.00) means 3D condition, student’s performance much better aligned teacher.Considering block defined \\([53,88]s\\). evidence contrast value pd 83%. One argue trend certainly distinctive enough. fact, careful visual inspection blocks 5.5 already suggested result.\nNow numbers!overall conclusion student’s alignment teacher, terms bowing gestures, works better 3D 2D sections showing strong support contrast rare: 4 17 sections. Moreover, seems evidence found piece F1.point, qualitative analysis score bow strokes needed.\nexample, time instances, especially long notes played ending block, difference suddenly prominent. Score associated performance analysis needed investigate origin sudden (dis)alignments student teacher.major point made chapter methodological. analysis illustrates flexibility statistical modelling approach flexibility great value future work domain.","code":""},{"path":"chapViolinist.html","id":"individual-violinists","chapter":"5 Violin player visual feedback","heading":"Individual violinists","text":"illustrate flexibility type modelling analysis individual violinists, can look performance violinist.\nFigure 5.8 shows individual violinist can visualized.\nline represents smooth data per trial, subject P009 .\nFigure 5.8: Piece F1 audio (top panel), logPD posterior predictions\n","code":""},{"path":"chapViolinist.html","id":"continuous-metric","chapter":"5 Violin player visual feedback","heading":"5.7 Continuous metric","text":"follows, show results different metric.\nmetric discussed detail next chapter (chapter 6).suffices say based continuous comparison bowing movements, using using time differences student teacher captured relative phase. metric ignorant bowing gesture events continuous metric. ’s advantage. disadvantage passages bowing teacher student rest shows highest synchronization don’t differ timing. Obviously, passages rest can easily extracted audio taken account mark performance.\nFigure 5.9: Piece F1 audio (top panel), logPD posterior predictions (middle panel), posterior difference 2D 3D. Vertical lines show regions interest\nfigure 5.9 clearly see contrast (lowest panel) favour 3D, except passages indicate rest. indicate points, difference can made 2D 3D. Ideally, student teacher don’t move bow therefore, sync points, contrast zero. See second panel log(1-R) measure lowest regions audio occurs.Figures 5.10 5.11 show two metrics (Procustus relative phase) next , now applied second piece (F2).beginning piece, 3D offers better synchronization 2D. However, towards end piece, roles reversed 2D offers better synchronization 3D. see trend reflected figures. reason may due fact score different towards end. Accordingly, type analysis calls deeper musicological analysis based additional score analysis. book place provide analysis. merely show statistical representation music performance may interest future work done domain.\nFigure 5.10: Comparison Procustus metric piece F2\n\nFigure 5.11: Comparison relative phase metric\n","code":""},{"path":"chapViolinist.html","id":"discussion-1","chapter":"5 Violin player visual feedback","heading":"5.8 Discussion","text":"Several noteworthy aspects merit attention discussing teachers bow gestures. gestures vary expressiveness, ranging effectively convey clear intention less expressive fail effectively communicate intended message. times, gesture may readily anticipated comprehended student, facilitating synchronization teacher student. However, instances gesture unprepared, plausibly resulting diminished anticipation understanding part student.Treating gestures equally, irrespective level anticipation, – modelling – potentially impact analysis interpretation specific effects. Difference teachers’ expressiveness can consequently result disparate communicative values, influencing students perceive respond gestures.Moreover, student’s attention resources likely fluctuate time due multitasking, encompassing activities playing instrument, consulting musical score, observing teacher. Given dynamic, remains uncertain student directs attention attention distributed among tasks. Although technologies eye-trackers EEG measurements provide insights, integrating significantly augment volume data introduce numerous challenges subsequent data analysis statistical modeling.Furthermore, additional sources variability arise variations educational backgrounds complexity levels musical compositions. Students exhibit diverse playing skills varying levels experience within orchestra. Moreover, musical pieces present differing degrees difficulty, contributing complexity situation.multitude factors contributing uncertainty data inevitably impacts outcomes statistical modeling. Given limitations, unrealistic anticipate statistical modeling panacea resolving issues. Instead, objective chapter apply statistical modeling available data assess extent findings within context limitations.Primarily, chapter demonstrates efficacy smooth regression adaptability Bayesian statistical modeling. results may yield unequivocal conclusions due inherent uncertainties, methodology presented herein profoundly intriguing holds substantial potential future research music performance analysis.","code":""},{"path":"chapViolinist.html","id":"conclusion-4","chapter":"5 Violin player visual feedback","heading":"5.9 Conclusion","text":"Overall, found trend favor 3D, least piece F1.\nability use parallax seems help particular circumstances related difficulty playing. However, 2D may offer already decent good visual perception opportunity sufficient control bowing gestures.result, one may wonder whether cost Hololens addition equipment needed play along teacher-avatar really worth effort. merely see least trend favour 3D, line suggestion parallax important feature visual modality order work feedback control bowing gestures.Nevertheless, analysis illustrates flexibility smooth regression Bayesian statistics.\npossible zoom sections, get specific answers whether condition works better sections.\nmain idea statistical modelling allows predictions equally sampled times. useful events one condition necessarily happing time events another condition, want compare conditions assuming correlation time short time intervals.","code":""},{"path":"chapExoskeletons.html","id":"chapExoskeletons","chapter":"6 Two violin players’ haptic feedback","heading":"6 Two violin players’ haptic feedback","text":"chapter yet published due time-limited embargo content.","code":""},{"path":"chapTappers1.html","id":"chapTappers1","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"7 Two finger tappers’ entrainment (Part 1)","text":"chapter mutual influences music interaction.\nrestricted context finger tapping influence can formulated follows:\ntapping affected seeing another person tapping different speed?\nperson influence ?analyse data two persons interacting way, previous studies used methods cross-correlation, cross-recurrence analysis, quantification analysis, delay-coupled oscillators, among others26.chapter, however, explore state-space model, mathematical representation dynamic system allowing description evolution internal states time. discription based state equation defines transition states, example means differential, difference, equations. internal states linked observations means observation equation , example, add fluctuation noise states.\ninternal states system containing two persons tapping, represent tapping frequency, tapping period, tapping phase moment. Adding fluctuation noise discrete tapping events due human sensorimotor variability, giving rise observations. Basically state-space model offers toolbox studing mutual influences finger tapping interactions.’ll study state-space model two perspectives. Firstly, model observations, using defined parameters solve state equation generate observations adding noise.\nSecondly, observations model, estimating parameters solving likelihood function based state-space model (state observation equations).solve likelihood equation, use Stan27, probabilistic programming language based Markov chain Monte Carlo (MCMC) sampling algorithms. Note Stan also engine beneath brms, package used previous chapters. address engine directly.code contained :","code":"\nsource(\"Code/chapAll_00_Initialization.R\")\nsource(\"Code/chapAll_01_Functions.R\")\nsource(\"Code/chapTappers/chapTappers_02_DataPreparation.R\")\nsource(\"Code/chapTappers/chapTappers_02_Simulation.R\")\nsource(\"Code/chapTappers/chapTappers_03_DataPlotting.R\")\nsource(\"Code/chapTappers/chapTappers_04_Modelling.R\")\nsource(\"Code/chapTappers/chapTappers_05_ModelPlotting.R\")\nsource(\"Code/chapTappers/chapTappers_06_Evaluation.R\")\nsource(\"Code/chapTappers/chapTappers_07_EvaluationPlotting.R\")"},{"path":"chapTappers1.html","id":"theory-3","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"7.1 Theory","text":"theoretical background chapter based two concepts: entrainment dynamic systems.","code":""},{"path":"chapTappers1.html","id":"entrainment-1","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Entrainment","text":"First consider entrainment, , specifically, rhythmic entrainment.\ncan defined adaptation timing, due influences persons interacting . influence can occur via modalities perception hearing, example seeing, feeling (see chapter 6).believe entrainment factor facilitates self-augmented interactions (see chapter 1).\ncontext, entrainment works automatic adapter actions towards joint goal. Hence facilitaties interaction. automatic sense relies sensorimotor control mechanisms, subjects typically aware .\npower entrainment assumed considerable, probably even resulting strong emotional effects. dealing .demonstrating near inevitability entrainment controlled circumstances, Rosso et al. (2024) created ingenious paradigm based conditions hearing seeing inform timing differently, , incongruently. Entrainment understood principle tends solve incongruent feedback actions changing actions originally caused incongruent feedback. Consequently, perceptions longer incongruent, least less incongruent. Entrainment thus drives incongruent perception congruent perception, via changes actions. ’s going deal . Actions understood fingertapping actions whose control largely unconscious control. , changes timing small, perhaps speak micro-timing actions (synchrony metronome), occur umbrella macro-timing actions (finger taps).","code":""},{"path":"chapTappers1.html","id":"dynamic-system","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Dynamic system","text":"Can understand action change terms dynamic system?\nsounds complicated details action-perception mechanisms, sensorimotor mechanisms, leading entrainment probably specific individual, far known. , deal ?dynamic systems approach assumes interaction ruled higher-level parameters matter observed interaction.\nAccordingly, unit involved interaction can handled black box whose inputs outputs can measured, without knowing black box functions. reduction underlying action-perception mechanisms necessary observed behavior can globally described. order words, reductionism replaced wholistic perspective. Ultimately, reductionism wholism may integrated know mechanisms. , , assume mechanism black box well.\nlet us see far get wholistic perspective assumed black box mechanisms error corrrection.capture dynamic system state-space model, state equation observation equation. global terms, equations can stated :\\[\\begin{equation}\n\\begin{array}{rl}\nx_t = f(x_{t-1}, w) & \\text{[state equation]} \\\\\ny_t = h(x_t, v) & \\text{[observation equation]}\n\\end{array}\n\\label{eq:chapTappersEquationStateSpaceModel}\n\\end{equation}\\]formulation, observation \\(y_t\\) based particular function \\(h\\), state \\(x_t\\) observation noise \\(v\\). example, function \\(x_t + v\\) observation generated state plus random number \\(v\\) drawn normal distribution, representing fluctuation noise.\nstate \\(x_t\\) depends function \\(f\\), previous state \\(x_{t-1}\\) system noise \\(w\\).\nsimplest case \\(f\\) \\(x_{t-1} + w\\), \\(w\\) system related stochastic parameter, noise, \\(f\\) also non-linear function, approach.state represent time interval taps tics.\nnew time interval based previous time interval system noise, making new time interval shorter, larger.\nuse phase (= time * \\(2\\pi\\)) allows us stipulate every tick tap occurs multiples \\(2\\pi\\), starting \\(0 [rad]\\). , using modulo \\(2\\pi\\) operator can easily extract timing situation two successive tics taps.\ngiven fact phase evolves time can always translate phase value back time (simply dividing \\(2\\pi\\)).state can also considered vector, vector components representing different units.\n’s exactly need order model entrainment.\ngo deeper mathematics state-space model.\nneed know exactly want model.","code":""},{"path":"chapTappers1.html","id":"drifting-metronomes","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Drifting metronomes","text":"drifting metronomes paradigm, developed (Rosso et al., 2021, 2023), peculiar experimental design uncover entrainment, controlling incongruency. works.Two subjects engage synchronized tapping listening metronome headphones. metronomes slightly detuned tempo, phase drifts. particular, one metronome tics every 600 ms, tics every 610 ms. Initially, metronomes start ticking together (-phase), time evolves, tics become wider apart (-phasing), eventually reaching anti-phase state ticking comes closer time (-phasing). cycle completed, metronomes one tic exactly together. One complete outphasing inphasing cycle takes \\(36.6\\) seconds (\\(= 600 * 610/ 10\\)). subjects asked perform 10 cycles row one performance. instructed follow metronome hear headphones.conditions interest : () seeing (ii) seeing .28Rosso et al. (2023) found subjects’ tapping behavior influenced seeing tapping, despite instruction follow metronome. words, visual coupling individuals led entrainment effect tapping behavior, even task implied anti-entrainment (resistence entrainment). suggests incongruent visual cues partner’s tapping can particularly strong, overriding intended synchronization metronome heard.interest offer causal explanation phenomenon. goal build state-space model entrainment, using control parameters govern causal flow among interacting units.","code":""},{"path":"chapTappers1.html","id":"causality","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Causality","text":"meant causal explanation? type modelling suggests causal level tapping/ticking basically understood terms limited number parameters control phase flow among units. knowledge dynamics phase flow don’t need go deeper subcomponents interacting units. Conceptually speaking, approach different smooth regression, modelling based basis expansion using many parameters splines (see previous chapters). associated parameters don’t model flow, just expand space data.want model dynamics pops action-perception mechanisms control timing interacting units (subjects metronomes). dynamics described higher level parameters control phase flow among units. parameters form part state equation, describes internal states propagated. equation captures belief system works. addition another parameter links state observation.measure parameters directly infer observations.","code":""},{"path":"chapTappers1.html","id":"approach-in-this-chapter","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Approach in this chapter","text":"development state-space model implies several steps summarize figure 7.1:\nFigure 7.1: Methodological approach (see text explanation)\nstep 1, define state-space model parameters. state equations obtain states, observation equation obtain observations.step 1, define state-space model parameters. state equations obtain states, observation equation obtain observations.step 2, use simulated observations (step 1) feed state-space model likelihood equation. solution (via MCMC sampling) posterior distribution retrieve parameters. also calculate generated observations, called posterior predictions, estimated parameters.step 2, use simulated observations (step 1) feed state-space model likelihood equation. solution (via MCMC sampling) posterior distribution retrieve parameters. also calculate generated observations, called posterior predictions, estimated parameters.step 3, check whether defined parameters correspond estimated parameters. Moreover, check whether states observations defined model correspond states observations generated fitted model.step 3, check whether defined parameters correspond estimated parameters. Moreover, check whether states observations defined model correspond states observations generated fitted model.","code":""},{"path":"chapTappers1.html","id":"step1.-from-model-to-observations","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"7.2 Step1. From model to observations","text":"","code":""},{"path":"chapTappers1.html","id":"define-the-units","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Define the units","text":"First define dynamic system.\ncontains four units, whose interaction described arrows, shown figure 7.2.Metronome 1, subject 1, metronome 2 subject 2 represented units \\(m1,s1,m2\\) \\(s2\\) \ncoupling represented arrows pointing one unit another unit. arrow \\(s1\\) pointing \\(m1\\) means subject 1 coupled metronome 1, described combination coupling strength phase delay.\narrows show subjects coupled metronome, subject.follow convention arrows point direction influence comes .\nAccordingly, subject points metronome subject.\nFigure 7.2: Dynamic system\n","code":""},{"path":"chapTappers1.html","id":"coupling-parameters","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Coupling parameters","text":"arrow defined two parameters, called coupling strength phase delay.coupling strength prefix \\(k\\) value ranges 0 1. value 0 indicates coupling, phase flow, value 1 indicates full coupling, full phase flow. coupling strength \\(ks1m1\\) captures strongly \\(s1\\) adheres phase \\(m1\\) thus, strongly \\(m1\\) affecting tapping \\(s1\\).important feature model coupling parameters always sum \\(1\\). words: \\(1 = ks1m1 + ks1s2\\) \\(1 = ks2m2 + ks2s1\\). constraint ensures competition among phase flows metronome partner. words, subject constant volume phase flow metronome partner. However, gate controls phase flow metronome competes gate controls phase flow gate partner. gate metronome fully open, gate partner fully closed. sum always 1.coupling strength can represented length arrows, suggested figure 7.3.\nleft block subjects devote attention metronome (\\(ks1m1 = ks2m2 = 1\\)). typical situation subjects hear metronome don’t see .\nright block, subjects divide attention partly metronome, partly partner.\ntypical situation subjects hear metronome see .\nfigure suggests \\(s1\\) attention metronome partner (say, \\(ks1m1 = .7\\) \\(ks1s2 = 1-.7 =.3\\)), \\(s2\\) attention partner metronome (say, \\(ks2m2 = .3\\) \\(ks2s1 = 1-.3 = .7\\)).\nFigure 7.3: Assumed coupling strength parameters uncoupled coupled condition\nphase delay prefix \\(d\\) (figure 7.2) value ranges \\(-\\pi\\) \\(\\pi\\).\n\nspecifies average synchronization offset entire outphasing-inphasing cycle.\nphase delay deleted model introducing gives flexibility model.","code":""},{"path":"chapTappers1.html","id":"state-equations","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"State equations","text":"state equations fully describe phase flow, , phase values interconnected units \\({m1,s1,m2,s2}\\) change time. observation equation describes observations relate states. Typically, relationship caputures distinction discrete observations continuous states. addition, captures fluctuation property, inpredictable uncertainty leading small deviations predictions.Let us look detail state changes.\nFirst consider metronomes, subjects.state metronomes \\(m1\\) \\(m2\\) particular time can notated \\({\\theta}_{m1,t}\\) \\({\\theta}_{m2,t}\\). simply phase \\(m1\\), \\(m2\\), time \\(t\\).\nchange state (phase change) time notated \\(\\dot\\theta\\), different notation, \\(\\frac{d\\theta}{dt}\\).get phase?\nWell, metronomes tic frequency, called eigen-frequency, given units radians per second \\([\\frac{rad}{sec}]\\).\ndiscrete tic events \\(m1\\), every \\(.6\\) second, turned continuously increasing phase cycle running \\(2\\pi\\) radians every \\(.6\\) second. Similarly, \\(m2\\) phase cycle \\(.61\\) seconds.short, metronome tics occur \\(2\\pi\\) happens different speed, due different eigen-frequency.\nMetronomes fixed phase cycle influences acting upon . system equations show continuous change metronomes constant.\\[\n\\begin{aligned}\n\\dot{\\theta}_{m1} &= \\omega_{m1} = \\frac{2\\pi}{0.6} \\\\\n\\dot{\\theta}_{m2} &= \\omega_{m2} = \\frac{2\\pi}{0.61}\n\\end{aligned}\n\\]expressed difference equation :\\[\n\\begin{aligned}\n\\theta_{m1,t} &= \\theta_{m1,t-1} + \\frac{2\\pi}{0.6} \\Delta t \\\\\n\\theta_{m2,t} &= \\theta_{m2,t-1} + \\frac{2\\pi}{0.61} \\Delta t\n\\end{aligned}\n\\]representation clearly says state \\(t\\) depends state \\(t-1\\) plus constant depending time difference (\\(\\Delta{t}\\)) \\(t\\) \\(t-1\\). equation suggests phase \\(\\theta\\) constantly increasing time.state transition subjects bit demanding, due influences.\nstate equations \\(s1\\) \\(s2\\), formulated differential equations, :\\[\\begin{equation}\n\\begin{array}{rl}\n\\dot{\\theta}_{s1} = & \\omega_{m1} + \\\\\n& ks1m1 \\cdot sin(\\theta_{m1} - \\theta_{s1} + ds1m1) + \\\\\n& (1-ks1m1) \\cdot sin(\\theta_{s2} - \\theta_{s1} + ds1s2)\\\\\n\\end{array}\\\\\n\\begin{array}{rl}\n\\dot{\\theta}_{s2} = & \\omega_{m2} + \\\\\n& ks2m2 \\cdot sin(\\theta_{m2} - \\theta_{s2} + ds2m2) +\\\\\n& (1-ks2m2) \\cdot sin(\\theta_{s1} - \\theta_{s2} + ds2s1)\\\\\n\\end{array}\n\\tag{7.1}\n\\end{equation}\\]Let us focus \\(s1\\).\nsubject requested follow \\(m1\\) therefore eigen-frequency set equal eigen-frequency metronome \\(m1\\) (\\(\\omega_{m1}\\)).subject devoting attention \\(m1\\), \\(ks1m1 = 1\\) zero contribution third term right hand side equation. following metronome, might deviations corrected error term \\(sin(\\theta_{m1} - \\theta_{s1} + ds1m1)\\).\nHowever, note subject can tap perfect synchrony metronome (\\(\\theta_{m1} - \\theta_{s1} = 0\\)), apart possible phase delay \\(ds1m1\\).subject devoting attention \\(m1\\), \\(ks1m1 = 1\\) zero contribution third term right hand side equation. following metronome, might deviations corrected error term \\(sin(\\theta_{m1} - \\theta_{s1} + ds1m1)\\).\nHowever, note subject can tap perfect synchrony metronome (\\(\\theta_{m1} - \\theta_{s1} = 0\\)), apart possible phase delay \\(ds1m1\\).subject devoting attention \\(s2\\),\n\\(ks1m1 < 1\\) external influence exerted addition.subject devoting attention \\(s2\\),\n\\(ks1m1 < 1\\) external influence exerted addition.Let’s expand influence. First, note terms two three state equation genuine error terms.\nbetter understand contribution terms dynamics system, simplify second term :\n\\[sin(\\theta_{m1} - \\theta_{s1})\\] , even simplified notation, write: \\[sin(\\theta_{m1-s1}).\\]\nrepresents phase error, phase difference, metronome 1 subject 1.also keep mind first part outphasing-inphasing cycle, metronomes start ticking together start defasing immediately \\(m2\\) ticking slower \\(m1\\).Given context, \\(sin(\\theta_{m1-s1})\\) positive phase difference metronome 1 subject 1 (modulo \\(2\\pi\\)) \\(<\\pi\\), reaching maximum \\(\\theta_{m1-s1} = \\frac{\\pi}{2}\\), \\(sin(\\frac{\\pi}{2}) = 1\\).\nmight typically happen \\(s1\\) retarded, example, due influence seeing \\(s2\\) tapping slower.\nvalue negative phase difference (modulo \\(2\\pi\\)) \\(>\\pi\\), reaching minimum \\(\\theta_{m1-s1} = \\frac{3\\pi}{2}\\), \\(sin(\\frac{3\\pi}{2}) = -1\\).\nmight happen influence seeing \\(s2\\) experienced tapping ahead, due anti-phase effect.\nOverall, suggest error term evolves time sinusoidal curve, first going going , cross zero, going going .Next, consider third term, simplified \\[sin(\\theta_{s2-s1})\\].\nrepresents phase error subject 2 subject 1.first part outphasing-inphasing cycle, \\(s2\\) tapping gradually slower \\(s1\\). phase \\(s1\\) higher phase \\(s2\\) phase difference \\(s2-s1\\) negative.\nlong phase difference (modulo \\(2\\pi\\)) \\(> \\pi\\), \\(sin(\\theta_{s2-s1})\\) negative minimum \\(\\theta_{s2-s1} = \\frac{\\pi}{2}\\). situation typically occurs beginning sequence.\nHowever, phase difference (modulo \\(2\\pi\\)) turns positive \\(< \\pi\\), \\(sin(\\theta_{s2-s1})\\) positive maximum \\(\\theta_{s2-s1} = \\frac{3\\pi}{2}\\). happens due anti-phase effect.\nOverall, error term evolves time sinusoidal curve, first going going , cross zero, going going .Note \\(m1\\) \\(s2\\) pull opposite directions global resulting error term sum error terms, weighted \\(km1s1\\) reverse \\(1 - km1s1\\), respectively.Due response \\(s2\\), one may expect , typically, anti-phase zero-crossing point subjects tapping delayed second error term. delay pronounced \\(s2\\) \\(m1\\). tapping slows , later zero-crossing point occur global error curve.Since sinusoids add, curve become asymmetrical time amplitude. don’t forget \\(sin(.)\\) first multiplied coupling strength.\nextreme parameter settings (e.g., \\(ks1m1\\) < .4) zero-crossing effect disappears (see examples ).Finally, also consider effect phase delay parameters.\nSince parameters held constant entire outphasing-inphasing cycle, affect entire curve shift values.\neffect also best illustrated means examples shown .state equations subjects can written either differential difference equation.\nconsider concise notation \\(s1\\):\\[\n\\begin{aligned}\n\\dot{\\theta}_{s1} &= \\omega_{m1} + (\\epsilon_{m1-s1} + \\epsilon_{s2-s1}) \\\\\n\\theta_{s1,t} &= \\theta_{s1,t-1} + (\\omega_{m1} + \\epsilon_{m1-s1} + \\epsilon_{s2-s1}) \\Delta t\n\\end{aligned}\n\\]first equation (differential) clearly shows error term \\(\\epsilon_{m1-s1}+\\epsilon_{s2-s1}\\). second equation (difference) clearly shows \\(\\theta\\) \\(s1\\) \\(t\\) equal \\(\\theta\\) \\(s1\\) \\(t-1\\) plus term contains fraction (\\(\\Delta{t}\\)) eigen-frequency \\(\\omega\\) \\(m1\\) plus error terms. eigen-frequency always positive large compared error terms. Hence, phase continue increase. Note error terms also include system noise coupling strength (\\(k\\)) phase delay (\\(d\\)) parameters.state equation governs state transitions dynamic system.\nState equations thus propagate states.\nfour units dynamic system, four states need propagated time instance.\nAccordingly, state vector \\(t\\) \\[\n\\boldsymbol{\\theta}_t = <\\theta_{m1,t}, \\theta_{s1,t}, \\theta_{m2,t}, \\theta_{s2,t}>\n\\].state equation :\\[\n\\boldsymbol{\\theta}_t = \\boldsymbol{\\theta}_{t-1} +  (\\boldsymbol\\omega + \\boldsymbol\\epsilon)\\Delta{t}\n\\]\n\\(\\boldsymbol\\omega\\) vector eigen-frequencies \\(\\boldsymbol\\epsilon\\) vector error terms. Clearly, metronomes error always zero., finally, observation \\(O\\) conceived based state \\(\\boldsymbol{\\theta_{t}}\\), plus observation noise \\(\\textbf{v}\\), component \\(v\\) can considered normal distribution \\(N(0,\\textbf{V})\\) thus :\\[\nO_{t} = \\boldsymbol{\\theta_{t}} + \\textbf{v}\n\\]\n\\(\\textbf{v}\\) distributed normal distribution mean 0 standard deviation \\(V\\): \\(N(0,\\textbf{V})\\).\n\\(\\textbf{V}\\) vector standard deviations associated vector components \\(\\boldsymbol{\\theta_{t}}\\).\nzero metronomes.\nobserved tap \\(s1\\) \\(t\\) equal state \\(\\theta_{s1,t}\\) plus fluctuation noise.Note equations metronomes deleted state-space representation completely deterministic.\nHowever, prefer include specifications state-space model, mainly future generalization purposes.","code":""},{"path":"chapTappers1.html","id":"understanding-the-dynamic","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Understanding the dynamic","text":"point instructive calculate states using state equation.\nFirst define R function called dydt, contains state equation.didactic reasons, also retrieve error terms contribute ds1 separately.\nfact, re-calculate error term ks1m1* sin(m1 - s1 + ds1m1) dem1s1 error term\n(1-ks1m1)* sin(s2 - s1 + ds1s2) des2s1.call upon R-function solve equations numerically using ode-function R-package deSolve, shown code .\nfirst specify parameters.\nparticular, set coupling strength ks1m1 = .9, ks2m2 = .7, phase delays zero.\ninitial values states, time \\(0\\), zero.\nstates (solution) differentiated order obtain instantaneous frequency phase.data frame solution looks like:solution comes time indicator called time, m1, s1, m2, s2 representing states’ phase, well phase error terms em1s1 es2s1 related s1.\ndifferentiating, get instantaneous frequencies: dm1, ds1, dm2, ds2, dm1s1 ds2s1, prefix \\(d\\) refers differential.instructive vary coupling strengths systematic way, see happens.\nLet’s , first focus em1s1 es2s1, error terms contribute phase change s1. code follows, define ks1m1 1, .8, .6, .4, .2, ks2m2 1 .75.\nrun combinations ks1m1 ks2m2.\nFigure 7.4: Error terms s1 due competing influences m1 s2. error terms shown thin lines. columns show five different values ks1m1 (1, .8, .6, .4, .2), rows show two different values ks2m2 (1, .75). thick line average thin lines. Overall, figures show instantaneous frequency (without eigen-frequency) error terms contribution s1\npanels top row Figure 7.4 show error terms contribute state s1, ks1m1 = 1, .8, .6, .4, .2, given ks2m2 = 1. bottom row shows error terms ks2m2 = .75.\nglobal error term shown thick line, sum two error terms ($\\epsilon_{m1-s1}$ $\\epsilon_{s2-s1}$) divided 2.\nfact, vertical scale important .dotted vertical line marks anti-phase time metronomes.\nOne can see crossing point error term curves delayed.\nks1m1 = .4 curve flipped.\nmarks fact tapping line \\(s2\\) \\(s1\\).similar way, possible calculate error terms \\(s2\\) based pulling forces metronome partner subject.Next show phase, just illustrate much see phase increasing continuously phase fluctuation minimal respect increase.\nshow code show details phase treated.\nFigure 7.5: Phase units\nalternative representation instantaneous period, period vertical axis.\n’s inverse instantaneous frequency, obtain differentiating phase. Accordingly, \\(ks1m1 = ks2m2 = 1\\), subjects follow metronomes therefore instantaneous period tapping 600 ms 610 ms. Note blue curves (\\(s1\\)) reversed curves figure 7.4.\nFigure 7.6: Instantaneous periods. columns show five different values ks1m1, rows show two different values ks2m2\nfigure reveals blue curves (representing instantaneous period \\(s1\\)) become slightly pronounced shifted mutual influence due \\(ks2m2 = .75\\).Next, show relative phase, rather instantaneous period.\nphase continuously increasing practical look phase relative metronome, rotate axis interval covers \\([-\\pi,+\\pi]\\).\nFigure 7.7: Relative phase s1 s2. columns show five different values ks1m1, rows show two different values ks2m2\nviewpoint interest phase delays enter picture.\nnext figure shows relative phase phase delays, \\(ds1m1 = ds2m2 = 1\\).\nFigure 7.8: Relative phase s1 s2, phase delay ds1m1 = ds2m2 = 1. columns show five different values ks1m1, rows show two different values ks2m2\nNote phase delay tends shift curve downward, implying anticipation, similar figures appear, except beginning curves point, start state zero position.examples reveal complex character dynamical system.\nDespite fact composed simple sinusoids, final behavior can rather surprising.","code":"\n# Define dydt\ndydt <- function(t, y, parms) {\n  with(as.list(c(y, parms)), {\n    ############################## dynamic system\n    dm1 = 2*pi*1000/600\n    ds1 = 2*pi*1000/600  + \n      .5*(ks1m1* sin(m1 - s1 + ds1m1) + \n            (1-ks1m1)* sin(s2 - s1 + ds1s2) )\n    \n    dm2 = 2*pi*1000/610\n    ds2 = 2*pi*1000/610  + \n      .5*(ks2m2* sin(m2 - s2 + ds2m2) + \n            (1-ks2m2)* sin(s1 - s2 + ds2s1) )\n    ############################## retrieve components for ds1\n    dem1s1 = ks1m1 * sin(m1 - s1 + ds1m1)\n    des2s1 = (1-ks1m1) * sin(s2 - s1 + ds1s2)\n    \n    return(list(c(dm1,ds1,dm2,ds2,dem1s1,des2s1)))\n  })\n}\n# define time points\ndt = 1/100\ntime_points <- seq(0, 36.6, by = dt)\n# define initial state\nstate <- c(m1 = 0, s1 = 0, m2 = 0, s2 = 0, em1s1 = 0, es2s1 = 0)\n# define the parameters\nparm = c(ks1m1 = .9, ks2m2 = .7, ds1m1 = 0, ds2m2 = 0, ds1s2 = 0, ds2s1 = 0)\n# solve the ODE\nsolution <- ode(y = state, times = time_points, func = dydt, parms = parm) %>% \n  data.frame()\n# calculate the phase change over time = instantaneous frequency\nsolution <- solution %>% mutate(\n  dm1 = c(NA,diff(m1)),\n  ds1 = c(NA,diff(s1)),\n  dm2 = c(NA,diff(m2)),\n  ds2 = c(NA,diff(s2)),\n  dm1s1 = c(NA,diff(em1s1)),\n  ds2s1 = c(NA,diff(es2s1))\n)## 'data.frame':    3661 obs. of  13 variables:\n##  $ time : num  0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 ...\n##  $ m1   : num  0 0.105 0.209 0.314 0.419 ...\n##  $ s1   : num  0 0.105 0.209 0.314 0.419 ...\n##  $ m2   : num  0 0.103 0.206 0.309 0.412 ...\n##  $ s2   : num  0 0.103 0.206 0.309 0.412 ...\n##  $ em1s1: num  0.00 1.93e-09 1.15e-08 3.65e-08 8.34e-08 ...\n##  $ es2s1: num  0.00 -8.58e-07 -3.43e-06 -7.71e-06 -1.37e-05 ...\n##  $ dm1  : num  NA 0.105 0.105 0.105 0.105 ...\n##  $ ds1  : num  NA 0.105 0.105 0.105 0.105 ...\n##  $ dm2  : num  NA 0.103 0.103 0.103 0.103 ...\n##  $ ds2  : num  NA 0.103 0.103 0.103 0.103 ...\n##  $ dm1s1: num  NA 1.93e-09 9.61e-09 2.50e-08 4.69e-08 ...\n##  $ ds2s1: num  NA -8.58e-07 -2.57e-06 -4.28e-06 -5.99e-06 ...\ncbPalette <- c(\"#56B4E9\",\"#E69F00\", \"#56B4E9\",\"#E69F00\",\"#D55E00\")\nSolution %>% pivot_longer(cols = c(m1,s1,m2,s2)) %>% group_by(time) %>% ggplot() +\n  geom_line(aes(x= time,y = value, color = name),size=1) +\n  geom_vline(xintercept = 36.6/2, color = \"#D55E00\", linetype = \"dotted\") +\n  theme_bw() +\n  scale_fill_manual(values=cbPalette) +\n  scale_colour_manual(labels = c(\"m1\",\"s1\",\"m2\",\"s2\"),values=cbPalette) +\n  facet_grid(ks2m2~ks1m1)\n# \\@ref(fig:chapTappersSol2)\ndo_period <- function(value,dt){\n  return = 2000*pi*dt/value\n}\n\ncbPalette <- c(\"lightblue\",\"#f1c9a5\", \"#56B4E9\",\"#E69F00\",\"#D55E00\")\n\nSolution %>% pivot_longer(cols = c(dm1,ds1,dm2,ds2)) %>% mutate(value = do_period(value,dt)) %>% group_by(time) %>% ggplot() +\n  geom_line(aes(x= time,y = value, color=name), size=1) +\n  geom_vline(xintercept = 36.6/2, color = \"#D55E00\", linetype = \"dotted\") +\n  ylim(585,635) +\n  theme_bw() +\n  scale_fill_manual(values=cbPalette) +\n  scale_colour_manual(labels = c(\"dm1\",\"dm2\",\"ds1\",\"ds2\"),values=cbPalette) +\n  facet_grid(ks2m2~ks1m1)\n\n# \\@ref(fig:chapTappersSol2)\ndo_rotate <- function(value){\n  return =  ((value + pi)%%(2*pi))-pi\n}\n\ncbPalette <- c(\"#56B4E9\",\"#E69F00\",\"#D55E00\")\n\nSolution %>% mutate(m1s1 = do_rotate(m1 - s1), m2s2 = do_rotate(m2 - s2)) %>% \n  pivot_longer(cols = c(m1s1,m2s2)) %>% group_by(time) %>% ggplot() +\n  geom_line(aes(x= time,y = value, color=name), size = 1) + \n  # ylim(5.75,6.35) +\n  theme_bw() +\n  scale_fill_manual(values=cbPalette) +\n  scale_colour_manual(labels = c(\"m1 - s1\",\"m2 - s2\"),values=cbPalette) +\n  facet_grid(ks2m2~ks1m1) +\n  labs(y=\"relative phase\")\n\n# \\@ref(fig:chapTappersSol3)\n# Set the time points\nSolution <- data.frame()\ndt = 1/100\ntime_points <- seq(0, 36.6, by = dt)\nstate <- c(m1 = 0, s1 = 0, m2 = 0, s2 = 0, em1s1 = 0, es2s1 = 0)\n\nfor (ks1m1 in seq(1,.2,-.2)){\n  for(ks2m2 in c(1,.75)){\n    parm <- c(ks1m1 = ks1m1,ks2m2 = ks2m2, ds1m1 = 1, ds2m2 = 1, ds1s2 = 0, ds2s1 = 0)\n    solution <- ode( state, time_points, dydt, parms = parm) %>% \n      data.frame() %>% \n      dplyr::select(time,m1,s1,m2,s2,em1s1,es2s1) %>% \n      mutate(ks1m1 = factor(ks1m1), ks2m2=factor(ks2m2))\n    Solution <- rbind(Solution, solution)\n  }\n}\n\nSolution <- Solution %>% mutate(\n  dm1 = c(NA,diff(m1)),\n  ds1 = c(NA,diff(s1)),\n  dm2 = c(NA,diff(m2)),\n  ds2 = c(NA,diff(s2)),\n  dem1s1 = c(NA,diff(em1s1)),\n  des2s1 = c(NA,diff(es2s1))\n)\n\ndo_rotate <- function(value){\n  return =  (value + pi)%%(2*pi)-pi\n}\n\ncbPalette <- c(\"#56B4E9\",\"#E69F00\",\"#D55E00\")\n\nSolution %>% mutate(m1s1 = do_rotate(m1 - s1), m2s2 = do_rotate(m2 - s2)) %>% \n  pivot_longer(cols = c(m1s1,m2s2)) %>% group_by(time) %>% ggplot() +\n  geom_line(aes(x= time,y = value, color=name), size = 1) + \n  # ylim(5.75,6.35) +\n  theme_bw() +\n  scale_fill_manual(values=cbPalette) +\n  scale_colour_manual(labels = c(\"m1 - s1\",\"m2 - s2\"),values=cbPalette) +\n  facet_grid(ks2m2~ks1m1) +\n  labs(y=\"relative phase\")\n\n# \\@ref(fig:chapTappersSol4)"},{"path":"chapTappers1.html","id":"general-specification","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"General specification","text":"possible generalize dynamic system units arranged different configurations, explore topic . focus current particular setup used experiment, data experiment analyzed using dynamic model validated chapter.Therefore, rather expanding dynamic system, aim validate whether dynamic system worth effort. However, proceeding, may interest generalize approach using equation (7.2):\\[\\begin{equation}\n\\frac{d\\theta_{}}{dt} = \\omega_{} + \\sum_j K_{,j} sin(\\theta_{t,j} - \\theta_{t,} + D_{,j}),~\n~ \\theta_i(0) = 0 \\tag{7.2}\n\\end{equation}\\]\\(\\theta\\) phase,\n\\(,j\\) index elements \\(\\left\\{ m1,s1,s2,m2 \\right\\}\\), \n\\(\\omega\\) instantaneous frequency, set \\(\\omega_i = \\frac{2\\pi*}{.6}~[\\frac{rad}{sec}]\\), \\(=1,2\\) \\(\\omega_i = \\frac{2\\pi}{.61}~[\\frac{rad}{sec}]\\) \\(=3,4\\).matrix \\(K\\) contains coupling parameters rows (index \\(\\)) columns (index \\(j\\)), parameters range \\([0,1]\\).\nAccordingly, \\(K(2,1) = K_{s1,m1} = ks1m1\\).\nmatrix \\(D\\) contains delay parameters range \\([-\\pi,\\pi]\\).Matrices K D design matrices define dynamic system. Dots mean parameter created. parameter created (e.g. \\(ks1m1\\)), two possibilities: either parameter gets defined value data can generated , value parameter estimated given data. chapter, ’ll first define , estimate . can check whether estimation correctly done.\\[\nK = \\begin{matrix}   \n&m1~~~~~~~~~~s1~~~~~~~~~~m2~~~~~~~~~~s2\\\\\n\\begin{matrix}   \n&m1 \\\\\n&s1 \\\\\n&m2 \\\\\n&s2 \\\\\n\\end{matrix} &\n\\begin{bmatrix}\n. &. &. &. \\\\\nks1m1 &. &. &1-ks1m1 \\\\\n. &. &. &. \\\\\n. &1-ks2m2  &ks2m2 &.\\\\\n\\end{bmatrix}\n\\end{matrix}\n\\]\\[\nD = \\begin{matrix}   \n&m1~~~~~s1~~~~~m2~~~~~s2\\\\\n\\begin{matrix}   \n&m1 \\\\\n&s1 \\\\\n&m2 \\\\\n&s2 \\\\\n\\end{matrix} &\n\\begin{bmatrix}\n. &. &. &. \\\\\nds1m1 &. &. &. \\\\\n. &. &. &. \\\\\n. &.  &ds2m2 &.\\\\\n\\end{bmatrix}\n\\end{matrix}\n\\]","code":""},{"path":"chapTappers1.html","id":"running-a-simulation-app","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Running a simulation app","text":"Equation (7.2) non-linear therefore useful explore simulations. refer shiny application here29, readers may explore.\nGiven explanation, believe tool self-explanatory.","code":""},{"path":"chapTappers1.html","id":"generating-fake-observations","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Generating fake observations","text":"Now system equations can generate states dynamic system, next goal generate observations. Currently, fake observations tics taps metronomes subjects. proceed two steps:First, use generated states extract time phase becomes multiple \\(2\\pi\\). time instances correspond tics taps metronomes subjects.First, use generated states extract time phase becomes multiple \\(2\\pi\\). time instances correspond tics taps metronomes subjects., add noise tap times, using normal distribution simulates human variability finger tapping tasks., add noise tap times, using normal distribution simulates human variability finger tapping tasks.dataset thus generated used retrieve parameters state-space model.\nlet’s first try generate observations.","code":""},{"path":"chapTappers1.html","id":"constraints-in-parameters","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Constraints in parameters","text":"Based drifting metronomes paradigm, subjects asked tap along metronome heard headphones, assume subjects indeed able adhere metronome. implies coupling strength \\(ks1m1\\) \\(ks2m2\\) rarely < .4 case actually follow partner (illustrated figures). Furthermore, assume testing purposes subjects distribution coupling strength. Accordingly, first generate coupling strength values subject 1. reshuffle values assign coupling strength values subject 2.\nFigure 7.9: Distributions coupling strength phase delay parameters simulations\n\nTable 7.1: K D parameters 40 simulations\nConstraints phase delays can justified studies showing humans tend anticipate beat30.Table 7.1 shows parameters 40 state equations, , 40 dynamical systems.\ncolumns represent number parameters \\(ks1m1, ks2m2, ds1m1, ds2m2\\). don’t specify \\(ds2s1\\) \\(ds1s2\\).\nNote first second 20 dynamic systems coupling strengths. first 20 systems zero phase delay, second 20 systems non-zero phase delay:Given parameters, generate states system.","code":"\n# distribution of coupling strengths\nK1 <- data.frame(ks1m1 = rbeta(20,4,2)) \nK1 <- K1 %>% mutate(ks2m2 = sample(ks1m1) )\n\n# distribution of delay times\nD2 <- data.frame(ds1m1 = rsn(n=20, xi=0, omega=.6, alpha=3, tau=0, dp=NULL)) \nD2 <- D2 %>% mutate(ds2m2 = sample(ds1m1), ds1s2 = 0, ds2s1 = 0)\n\n# delays set to zero because we want to test the system without delays and with delays\nD1 <- D2 %>%  mutate( ds1m1 = 0, ds2m2 = 0) \n\n# row bind the same coupling parameters\nK <- rbind(K1,K1)\n# row bind different delay parameters\nD <- rbind(D1,D2)\n\n# check distributions visually\ncbPalette <- c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\nK_long <- K %>% pivot_longer(cols = everything())\npk <- ggplot(K_long) + \n  geom_point(aes(x=name,y=value, color = name), size = 1, shape = 1) +\n  theme_bw() +\n  scale_fill_manual(values=cbPalette) +\n  scale_colour_manual(values=cbPalette) + \n  ylim(0,1)\n\nD_long <- D %>% pivot_longer(cols = everything())\npd <- ggplot(D_long) + \n  geom_point(aes(x=name,y=value, color = name), size = 1, shape = 1) +\n  theme_bw() +\n  scale_fill_manual(values=cbPalette) +\n  scale_colour_manual(values=cbPalette) + \n  ylim(0,1)\npk + pd"},{"path":"chapTappers1.html","id":"generate-states","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Generate states","text":"states generated (see Code script Code/chapTappers/chapTappers_02_DataPreparation.R) using parameters shown table 7.1.\nTable 7.2: States model 1\ngenerated states contained data frame States. Table 7.2 shows six rows (row 599 row 604) data frame. columns show time sample (time), phase unit (m1, s1, m2, s2), number simulated system (sim), associated parameters K (first 2 numbers) D (last 4 numbers) (param).","code":""},{"path":"chapTappers1.html","id":"generate-observations","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Generate observations","text":"Using states calculated previous step, time values (tics taps) taken phase closest multiples \\(2\\pi\\).\nexample, time 0.6, metronome 1 (see column names) produced tick, phase \\(6.283185\\), \\(2pi\\), shown column m1.\ntime 0.6006, subject 1 produced tap, shown s1. phase close \\(2\\pi\\), small acceptable peak extraction error.\n.time values can found using peak finding modulo 2*pi phase values, per unit.Finally, extracted taps tics, noise added time values.\nnoise characteristic \\(N(0, \\sigma)\\), \\(\\sigma\\) defined \\(0.005\\) [s].\nNote apply taps (subjects), ticks (metronomes).\nFinally, since phase values still defined interval \\([Ø,2\\pi]\\),\nrotate phase interval \\([-pi,+pi]\\), 0 right middle scale.\nresult (see Code script Code/chapTappers/chapTappers_02_DataPreparation.R) :\nTable 7.3: Observations\n6.28318","code":""},{"path":"chapTappers1.html","id":"examples","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Examples","text":"Figure 7.10 shows generated states discrete observations first model.parameters indicated top.\ntop panel shows states relative phase, , metronome states minus subject states mapped interval \\([-\\pi, +\\pi]\\).\ndotted vertical line indicates one completed outphasing-inphasing cycle. Three cycles shown.\ncircules show observations relative phase.bottom panel shows states units instantaneous periods.\nNote metronomes form straight lines 600 610 ms.\nFigure 7.10: Dynamic model 1. Generated phase-functions tapping data\ninclusion delay lines dynamic model 21, can observed two relative phase curves longer overlap relative phase zero, reflecting anticipation.\nFigure 7.11: Dynamic system 21. Generated phase-functions tapping data\nAdditionally, important note dynamic model constrained start \\(0 [rad]\\). indicated dashed red line, beginning second de-phasing/-phasing cycle, phase deviates \\(0 [rad]\\) dynamics cycles becomes stable (cf. cycle 2 cycle 3). Note dashed red line marks end first cycle.observations highlight intricate dynamics deviations perfect synchrony tapping process, influenced coupling parameters, delay lines, initial conditions dynamic system.\nUsing interactive tool odetappers2, figures can replicated setting parameters accordingly.","code":""},{"path":"chapTappers1.html","id":"step-2.-from-observations-to-parameters-and-predictions","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"7.3 Step 2. From observations to parameters and predictions","text":"specified state-space model, now turn attention estimation. used parameters specified Table 7.1 generate (fake) observations.\nNow start observations check whether can retrieve original parameters.\nworks, super cool regression model dynamical system predictor.","code":""},{"path":"chapTappers1.html","id":"observations","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Observations","text":"Let us first look observations, given input state-space model.\n’s just list times unit generates tic tap.\nRecall tic tap times, phase just 0 [rad].\nobservations shown table 7.4, time, names, phase selected Observations.\nTable 7.4: Simulated tappers data\n","code":""},{"path":"chapTappers1.html","id":"likelihood-function","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Likelihood function","text":"estimate parameters state-space model, specify observations relate states. done describing likelihood function want optimize.\nHowever, already work.likelihood function states :\n\\[\n\\boldsymbol{\\theta}_t = \\boldsymbol{\\theta}_{t-1} +  (\\boldsymbol\\omega + \\boldsymbol\\epsilon)\\Delta{t}\n\\]\n\\(\\boldsymbol{\\theta}_t\\) state continuous time point \\(t\\), \\(\\boldsymbol\\omega\\) eigen-frequencies, \\(\\boldsymbol\\epsilon\\) state error terms.likelihood function observations :\n\\[\nO_{u,t'} \\sim F\\boldsymbol{\\theta_{t'}} + \\textbf{v}\n\\]\n\\(O_u\\) observation unit \\(u\\) (\\(\\{m1,s1,m2,s2})\\) discrete time point \\(t'\\), \\(F\\) function, \\(\\textbf{v}\\) observation noise.\nfunction \\(F\\) specifies modulo operator phase. needed \\(\\boldsymbol{\\theta}\\) continuously increasing time. \\(F\\) translate phase interval \\([-\\pi,+\\pi]\\) order able match zero, phase value tick tap event occurs time indicated \\(t'\\).","code":""},{"path":"chapTappers1.html","id":"priors-for-likelihood-function","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Priors for likelihood function","text":"likelihood function complete unless boundaries distributions parameters specified. define guided search space optimal fit observations model parameters.priors coupling (k) phase delay (d) parameters defined using rough previous available knowledge.\nsubjects requested follow metronome, prior coupling strength parameter obeys beta distribution peak towards 1. Accordingly, \\(k\\)-parameters can specified \\(beta(19,2)\\).\nPhase delay parameters unknown assume normal distributed standard deviation 0.5: \\(normal(.0,.5)\\).\nprior observation noise parameter (observation_std), depends unit.\nmetronome units, set \\(normal(0,.1)\\).\nsubject units, set \\(normal(0,1)\\).\nFinally, work priors initial phases \\(s1\\) \\(s2\\) allow offset (order avoid starting zero), \\(normal(.0,.15)\\).\nalso set boundaries parameters. overview:\\[\n\\tiny\n\\begin{aligned}\n& \\textbf{priors state equation}&\\\\\n& ks1m1 &\\sim &beta(19,2) &\\text{Prior coupling strength s1 m1, range: [0,1] }\\\\\n& ks2m2 &\\sim &beta(19,2) &\\text{Prior coupling strength s2 m2, [0,1]  }\\\\\\\\\n& ds1m1 &\\sim &normal(0,.5) &\\text{Prior phase delay s1 m1},[-\\pi,\\pi]\\\\\n& ds2m2 &\\sim &normal(0,.5) &\\text{Prior phase delay s2 m2}, [-\\pi,\\pi]\\\\\n& ds1s2 &\\sim &normal(0,.5) &\\text{Prior phase delay s1 s2}, [-\\pi,\\pi]\\\\\n& ds2s1 &\\sim &normal(0,.5) &\\text{Prior phase delay s2 s1}, [-\\pi,\\pi]\\\\\\\\\n& \\textbf{priors observation equation}&\\\\\n& observation\\_std[1] &\\sim &lognormal(0,.1) &\\text{Prior observation noise m1} \\\\\n& observation\\_std[2] &\\sim &lognormal(0,1) &\\text{Prior observation noise s1} \\\\\n& observation\\_std[3] &\\sim &lognormal(0,.1) &\\text{Prior observation noise m2} \\\\\n& observation\\_std[4] &\\sim &lognormal(0,1) &\\text{Prior observation noise s2} \\\\\\\\\n& \\textbf{priors initial offset}&\\\\\n& \\theta_{s1}(0) &\\sim &normal(.0,.15) &\\text{Prior initial phase offset s1} \\\\\n& \\theta_{s2}(0) &\\sim &normal(.0,.15) &\\text{Prior initial phase offset s2} \\\\\n\\end{aligned}\n\\]","code":""},{"path":"chapTappers1.html","id":"running-stan","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"7.3.1 Running Stan","text":"solution likelihood function calculated MCMC-algorithms Stan. parameter values posterior distributions, can calculate new observations posterior predictions.show detail works, see also Code/chapTappers/chapTappers_04_Modelling.R.input Stan list containing specification number observations (n_times), number generated time instances (n_gen_times), initial time (time0), value observed events (observed) (recall always 0), time phase appears (time), generated time instances (time_gen), unit indicator (name_indicator) (1=\\(m1\\), 2=\\(s1\\), 3= \\(m2\\), 4= \\(s2\\)). list looks like:input can sent Stan inside R using function stan R-package rstan. sends program, contained filenameStanCode sampler-algorithms, creates posterior likelihood function priors.","code":"## List of 7\n##  $ n_times        : int 244\n##  $ n_gen_times    : num 100\n##  $ time0          : num 0\n##  $ observed       : num [1:244] -0.00906 -0.00906 -0.00875 -0.01047 -0.00461 ...\n##  $ time           : num [1:244] 0.00156 0.00911 0.59189 0.599 0.6059 ...\n##  $ time_gen       : num [1:100] 0.0001 0.3698 0.7395 1.1092 1.4789 ...\n##  $ names_indicator: num [1:244] 4 4 2 1 4 3 1 2 4 3 ...\nfilenameStanCode = \"Code/chapTappers/chapTappers_StateSpaceModel.stan\"\n\nfit <- stan(\n  data = StanData, # the data as input to stan\n  file = filenameStanCode, # the filename containing the stan code\n  thin = 2,\n  iter = 6000,\n  warmup = 2000,\n  cores = 4,\n  chain = 2\n)"},{"path":"chapTappers1.html","id":"state-equations-1","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"State equations","text":"code filenameStancode contains several blocks.\nstates equations syntax Stan :call function defined :Omega array vectors containing state values \\(m1\\), \\(s1\\), \\(m2\\), \\(s2\\) n_times tick tap events. omega thus get phases units, well distributions estimated parameters \\(ks1m1, ks2m2, ds1m1, ds2m2, ds1s2\\), \\(ds2s1\\).works put likelihood function observations linked states.function can understood follows. tick tap \\(n\\), observed value [n] (zero, close zero) state value mean, plus value drawn normal distribution --estimated standard deviation corresponding unit.Note state value single value names_indicator[n] taken event \\(n\\), array omega, applying modulo \\(2\\pi\\) rotation phase occurs interval \\([-\\pi,+\\pi]\\). words, observed value considered, fitted updating states call omega. returned state mixed noise fit observation.","code":"functions {\n  vector do_dt(real t, vector y,  real ks1m1, real ks2m2,  real ds1m1, real ds2m2,\n               real ds1s2, real ds2s1){\n    real pi600 = 2*pi()/.6; // Eigenfrequency s1, m1\n    real pi610 = 2*pi()/.61;  // Eigenfrequency s2, m2\n\n    real dm1dt = pi600;\n    real ds1dt = pi600 + .5*(ks1m1*sin(y[1]-y[2]+ds1m1)+(1-ks1m1)*sin(y[4]-y[2]+ds1s2));\n    real dm2dt = pi610;\n    real ds2dt = pi610 + .5*(ks2m2*sin(y[3]-y[4]+ds2m2)+(1-ks2m2)*sin(y[2]-y[4]+ds2s1));\n    return to_vector([dm1dt,ds1dt,dm2dt,ds2dt]);\n  }\n}vector[4] omega[n_times] = ode_rk45(do_dt, y0, time0, time,\n        ks1m1, ks2m2, ds1m1, ds2m2, ds1s2, ds2s1) ;for (n in 1:n_times){\n  state = fmod(omega[n,names_indicator[n]] + pi(), pi2 ) - pi();\n  // single value returned here because we have only one observation per time\n  observed[n] ~ normal(state, observation_std[names_indicator[n]]);\n  // names_indicator defines which unit is active at n\n}\n}"},{"path":"chapTappers1.html","id":"posterior-predictions-or-generated-states-and-observations","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Posterior predictions, or generated states and observations","text":"Given solution likelihood function, kown posterior, can generate new observations.directly calculated Stan, using block called generated quantities.\nFirst, calculate states call state equation.\ngenerates vector states_generated array vectors.\nlength array now n_gen_times, vector holds state values units point array. Obviously, used exactly times observation events gave input system.\n, however, specified time points events. fact, want time points given sampling interval get 100 time points per outphasing-inphasing cycle 36.6 seconds.Secondly, states generated, calculate observations unit separately time point n. observations drawn normal distribution given mean standard deviation.Basically, ’s modelling Stan.","code":"generated quantities {\n  vector[4] observations_generated[n_gen_times];\n  vector[4] states_generated[n_gen_times] = ode_rk45(do_dt, y0, time0, time_gen, ks1m1, ks2m2, ds1m1, ds2m2,ds1s2,ds2s1) ;\n  for (n in 1:n_gen_times){\n    observations_generated[n,1] = normal_rng(states_generated[n,1],observation_std[1]);\n    observations_generated[n,2] = normal_rng(states_generated[n,2],observation_std[2]);\n    observations_generated[n,3] = normal_rng(states_generated[n,3],observation_std[3]);\n    observations_generated[n,4] = normal_rng(states_generated[n,4],observation_std[4]);\n  }"},{"path":"chapTappers1.html","id":"summary-stan-code","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Summary Stan code","text":"code rather compact apart variable definitions constraints, lines.\nreproduce entirely.\ncode also found Code/chapTappers/chapTappers_StateSpaceModel.stan.31.Note Stan file, called within R, following example code. See Code/chapTappers/chapTappers_04_Modelling.R.","code":"functions {\n  vector do_dt(real t, vector y,  real ks1m1, real ks2m2,  real ds1m1, real ds2m2,\n  real ds1s2, real ds2s1){\n    real pi600 = 2*pi()/.6; // Eigenfrequency s1, m1\n    real pi610 = 2*pi()/.61;\n    real dm1dt = pi600; \n    real ds1dt = dm1dt + (ks1m1 * sin(y[1] - y[2] + ds1m1) + \n      (1-ks1m1) * sin(y[4] - y[2] + ds1s2)  ); \n    real dm2dt = pi610;\n    real ds2dt = dm2dt + (ks2m2 * sin(y[3] - y[4] + ds2m2) + \n        (1-ks2m2) * sin(y[2] - y[4] + ds2s1)  ); \n        return to_vector([dm1dt,ds1dt,dm2dt,ds2dt]);\n  }\n}\n\ndata {\n  int<lower=1> n_times; // Number of time steps minus one\n  int<lower=1> n_gen_times;\n  real time0;\n  array[n_times] real observed; // Observed taps, minus initial state\n  array[n_times] real time ;\n  array[n_times] int<lower=1> names_indicator; // names of oscillators\n  array[n_gen_times] real time_gen; // times to generate simulated data for\n}\n\nparameters {\n  real<lower = 0,upper=1> ks1m1;\n  real<lower = 0,upper=1> ks2m2;\n  real <lower = -pi(),upper=pi()> ds1m1; // 5_aug\n  real <lower = -pi(),upper=pi()> ds2m2; // 5_aug\n  real <lower = -pi(),upper=pi()> ds1s2; // 5_aug\n  real <lower = -pi(),upper=pi()> ds2s1; // 5_aug\n  // real <lower = 0, upper = 20> kappa[4];\n  array[4] real<lower=0> observation_std; // Variance of observation\n  real y0_s1;\n  real y0_s2;\n}\n\ntransformed parameters {\n  vector[4] y0 = [.0,y0_s1,.0,y0_s2]' ;\n  array[n_times] vector[4] omega = ode_rk45(do_dt, y0, time0, time, ks1m1, ks2m2, ds1m1, ds2m2, ds1s2, ds2s1) ;\n}\n\nmodel {\n  ks1m1 ~ beta(19,2) ;\n  ks2m2 ~ beta(19,2) ;\n  ds1m1 ~ normal(.0,.5) ;\n  ds2m2 ~ normal(.0,.5) ;\n  ds1s2 ~ normal(.0,.5) ;\n  ds2s1 ~ normal(.0,.5) ;\n  observation_std[1] ~ normal(.0,.1) ;\n  observation_std[2] ~ normal(.0,1) ;\n  observation_std[3] ~ normal(.0,.1) ;\n  observation_std[4] ~ normal(.0,1) ;\n  y0_s1 ~ normal(.0,.15) ;\n  y0_s2 ~ normal(.0,.15) ;\n  real pi2 = 2*pi() ;\n  real state;\n  for (n in 1:n_times){\n    state = fmod(omega[n,names_indicator[n]] + pi(), pi2 ) - pi(); \n    // single value returned here because we have only one observation per time\n    observed[n] ~ normal(state, (observation_std[names_indicator[n]]));\n    // names_indicator defines which unit is active at n\n  }\n}\n\ngenerated quantities {\n  array[n_gen_times] vector[4] observations_generated;\n  array[n_gen_times] vector[4] states_generated = ode_rk45(do_dt, y0, time0, time_gen, ks1m1, ks2m2, ds1m1, ds2m2,ds1s2,ds2s1) ;\n  for (n in 1:n_gen_times){\n    observations_generated[n,1] = normal_rng(states_generated[n,1],observation_std[1]);\n    observations_generated[n,2] = normal_rng(states_generated[n,2],observation_std[2]);\n    observations_generated[n,3] = normal_rng(states_generated[n,3],observation_std[3]);\n    observations_generated[n,4] = normal_rng(states_generated[n,4],observation_std[4]);\n  }\n}\n    fit <- stan(\n      data = StanData,\n      file = filenameStancode,\n      #verbose = FALSE,\n      init = 0,\n      thin = 2,\n      iter = 6000,\n      warmup = 2000,\n      cores = 2,\n      chain = 2\n    )"},{"path":"chapTappers1.html","id":"step-3.-evaluation","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"7.4 Step 3. Evaluation","text":"code calculating posterior 40 dynamic models can found Code/chapTappers/chapTappers_04_Modelling. involves steps seen far.\nposterior, extract posterior parameter distribution compare designed parameters.","code":""},{"path":"chapTappers1.html","id":"evaluating-the-posterior-distributions","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Evaluating the posterior distributions","text":"Figure 7.12 shows posterior distributions (estimated mean 95% CI) designed parameters (circles).\ntop panel shows coupling strengths 40 dynamic models tested.\nWhite circles implied match designed estimated parameter values.\nInstead see circles filled, suggests coupling strengths correctly retrieved. Recall designed coupling strengths exactly models 1 20, models 21 40.\nmiddle panel shows phase delay metronome.\nRecall zero models 1 20 randomly assigned models 21 40.\nbottom panel shows phase delay partner.\nFigure 7.12: Posterior sommary fitted parameters state equation, compared designed parameters (cicles). Top: coupling strength. Middle: phase delay metronome. Bottom: phase delay partner\n\n\n\ntable 7.5 show designed fitted parameters models, well difference.\nTable 7.5: Defined fitted parameters 40 dynamic systems.\nColumn names following coding convention:\nDefined parameters : \\(k1 = ks1m1\\), \\(k2 = ks2m2\\),\n\\(d1 = ds1m1\\), \\(d2 = ds2m2\\), \\(d3 = ds1s2\\), \\(d4 = ds2s1\\).\nFitted parameters : \\(K1 = ks1m1\\),\n\\(K2 = ks2m2\\),\n\\(D1 = ds1m1\\),\n\\(D2 = ds2m2\\),\n\\(D3 = ds1s2\\),\n\\(D4 = ds2s1\\).\nDifferences :\n\\(Kk1 = K1 - k1\\),\n\\(Kk2 = K2 - k2\\),\n\\(Dd1 = D1 - d1\\) \n\\(Dd2 = D2 - d1\\)\nTable 7.6 contains overview \nerrors designed estimated parameters.\nK parameters mean absolute value errors 0.01 standard deviation 0.01, suggesting error 1% coupling strength (given interval \\([0,1]\\)).\nD parameters error \\(100* .045 / (2\\pi) = 0.7 \\%\\) phase delay (interval \\([-\\pi,+\\pi]\\)).\nTable 7.6: Mean absolute value errors, standard deviation absolute errors, Q95 range designed estimated compling strength K phase deley D, without designed phase delay\nOverall, can concluded state-space modelling successful retrieving parameters simulated observations.","code":""},{"path":"chapTappers1.html","id":"evaluating-the-posterior-predictions","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"Evaluating the posterior predictions","text":"look posterior predictions, , observations generated state-space model. show relative phase instantaneous period defined fitted states observations.\ncomparison qualitative.\nexamples model 1 21.\nFigure 7.13: Dynamic system 1. Top: Defined discrete observations (circles) versus fitted observatins (gray band). Bottom: Instantaneous period defined states fitted states\n’s important understand fitted observations continuous. generated without considering discrete time. Starting states, just add random noise observation equation. Therefore, result band (CI-95%) around curve showing states, rather discrete events. bottom figure, curve shown instantaneous period, together designed instantaneous period. gives view states.\nFigure 7.14: Dynamic system 21. Top: Defined discrete observations (circles) versus fitted observatins (gray band). Bottom: Instantaneous period defined states fitted states\n","code":""},{"path":"chapTappers1.html","id":"discussion-2","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"7.5 Discussion","text":"error defined estimated coupling strength parameters 1% coupling strength scale, great difference accuracy coupling strengths without defined phase delay.However, several limitations shortcomings evaluation mentioned well.First, dynamic system assumes attention either devoted metronome heard subject seen. One may question whether realistic. Perhaps human subjects get distracted events outside timing task. Exogeneous distraction something model doesn’t capture.Second, current model, coupling strength fixed time subjects change coupling strength time. time series may non-stationary subject’s variability changes time.Finally, modelling needs accurately reflect physical setup. slightly different paradigm studying rhythmic entrainment (e.g. spontaneous tapping without metronomes) require careful adaptation dynamic system defined chapter. next chapter, ’ll see eigen-frequency second metronome exactly 610 609.375, due experimental design get 39 seconds outphasing-inphasing cycle (\\((600 * 609.375/9.375) /1000 = 39\\)).Overall, dynamic model might useful real observations (.e., tapping data real subjects) keep mind assumptions simulation different real world. example, subjects might distracted loose synchrony together.","code":""},{"path":"chapTappers1.html","id":"conclusion-5","chapter":"7 Two finger tappers’ entrainment (Part 1)","heading":"7.6 Conclusion","text":"chapter studied entrainment dynamic system’s perspective defined network timing units (metronomes subjects). units, phase flow can described state-space model, state equations observation equation.\nstate-space model can generate states possible generate discrete observations, standing tics taps.\nobservations, state-space model can used estimating parameters, generating new observations (continuous, rather discrete).compared designed parameters estimated parameters, got quantitative error estimate 1%. Visual inspection observations states state-space models confirm close match.Overall, non-linear state-space model seems offer valuable tool acquiring insight rhythmic entrainment terms causal dyadic interactions level phase flow.\n\n\n\n\n\n","code":""},{"path":"chapTappers2.html","id":"chapTappers2","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"8 Two finger tappers’ entrainment (Part 2)","text":"chapter builds upon previous chapter’s discussion entrainment development state-space model. now apply state-space model analyze entrainment human finger tapping data. primary objective investigate whether synchronized tapping two individuals becomes influenced, entrained, can see tapping, compared . goal gain global perspective entrainment capabilities subjects.bonus, show state-space model can explain earlier findings based smooth regression recurrence analysis.code can found following scripts data preparation plotting, modelling plotting, contrast analysis:","code":"\nsource(\"Code/chapAll_00_Initialization.R\")\nsource(\"Code/chapAll_01_Functions.R\")\nsource(\"Code/chapTappers2/chapTappers2_02_DataPreparation.R\")\nsource(\"Code/chapTappers2/chapTappers2_03_DataPlotting.R\")\nsource(\"Code/chapTappers2/chapTappers2_04_Modelling.R\")\nsource(\"Code/chapTappers2/chapTappers2_05_ModelPlotting.R\")\nsource(\"Code/chapTappers2/chapTappers2_06_Contrasts.R\")\nsource(\"Code/chapTappers2/chapTappers2_05_SSM_DataPreparation_Posterior.R\")\nsource(\"Code/chapTappers2/chapTappers2_06_SSM_Plotting.R\")"},{"path":"chapTappers2.html","id":"theory-4","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"8.1 Theory","text":"Given state-space model defined previous chapter, can define interaction concepts terms state observation parameters.example, entrainment can now defined depending coupling strength partner:\n\\[\n\\begin{aligned}\nE_{s1} &:= k_{s1s2} = 1 - k_{s1m1} \\\\\nE_{s2} &:= k_{s2s1} = 1 - k_{s2m2}\n\\end{aligned}\n\\]\nEntrainment \\(s1\\) \\((E_{s1})\\) depends coupling strength \\(s2\\).\nEntrainment \\(s2\\) \\((E_{s2})\\) depends coupling strength \\(s1\\).definition involves two competing forces defined entrainment-coupling strength adherence-coupling strength. One argue adherence-coupling strength (coupling metronome) characterizes volitional anti-entrainment force competing non-volitional entrainment force pulling synchronization. distinction relevant ensemble playing. search joint tempo, tempo played individual musician may influenced tempi perceived musicians. case, volitional action non-volitional perception compete adherence-coupling entrainment-coupling strengths.leader–follower relation can defined difference entrainment-coupling strength two subjects. makes sense coupled condition (C), don’t leader–follower relation uncoupled condition (U):\n\\[\nLF_{s1s2} := ks1s2 - ks2s1 =  ks2m2 - ks1m1\n\\]\n\\(LF_{s1s2}\\) positive negative depending whether \\(s1\\) \\(s2\\) leading.Note concept leader–follower, defined terms strength coupling, really tell us locally leading tapping. fact, start early phase outphasing-inphasing cycle, \\(s1\\) typically leading, sense \\(s2\\) taps slower speed. roles reversed subjects pass anti-phase relative tapping. moment , appears \\(s2\\) leading shortest phase interval now initiated \\(s2\\). anti-phase effect mentioned previous chapter. However, interpret concept leader–follower terms adherence strength (anti-entrainment). leader one better synchronizes metronome, resisting entrainment. otherwise stated, leader one less entrainment.Another useful term anticipation, anticipation bias subject. defined terms phase delay metronome:\\[\n\\begin{aligned}\nA_{s1} &:= d_{s1m1} \\\\\nA_{s2} &:= d_{s2m2}\n\\end{aligned}\n\\]\nvalue phase delay parameter positive means anticipation, otherwise delay. Anticipation expected line previous studies finger tapping (see chapter 2). Note also use phase delay partner, defined \\(ds1s2\\) \\(ds2s1\\). Due non-linearity equations, phase delays necessarily identical mainly used allow flexibility state-space model.final parameter interest fluctuation, can define standard deviation parameter links observations states. observations close states, fluctuation low. Fluctuation can understood uncertainty observations given states.","code":""},{"path":"chapTappers2.html","id":"setup","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"8.2 Setup","text":"now ready look tapping data experiment described Rosso et al. (2023). thereby limit uncoupled (U) coupled (C) conditions experiment.32The experimental setup implements drifting metronomes paradigm. uncoupled condition (U), subjects requested tap sync metronome heard headphones 600 ms 610 ms. fact, second metronome exactly 610 ms. 609.375 ms outphasing-inphasing cycle 39 seconds. Note period (609.375 ms) used state-space model followins. Henceforth ’ll say: 610 ms. coupled condition (C) subject 1 hears 600 ms sees hand subject 2, presumably tapping 610 ms, subject 2 hears 610 ms sees hand subject 1, presumably tapping 600 ms. creates incongruency subjects’ syncing may influenced seeing partner tapping.","code":""},{"path":"chapTappers2.html","id":"raw-tapping-data","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"Raw tapping data","text":"Figure 8.1 shows raw tapping data dyads two conditions.\nfinger tap times subtracted metronome tick times, represented proportion metronome tick intervals multiplied \\(2\\pi\\). resulting relative phase shown interval \\([-\\pi,+\\pi]\\).\ncalculation relative phase found Code/chapTappers2/chapTappers2-02_DataPreparation.R.\nsubjects zero relative phase tap exactly time tick metronome.\nFigure 8.1: Overview raw tapping data\nfigure gives rough idea subjects’ capabilities uncoupled condition (U) coupled condition (C). U (first two panels), dots expected fluctuate smoothly around zero, bit lower zero due anticipation.\nHowever, subjects severe fluctuation rather smooth fluctuation.\nexample, dyad_1 (subjects), dyad_6 (subject 1), dyad_14 (subject 2) seem fluctuate severely entire performance (10 outphasing-inphasing cycles).\ndyad_4 seems subject 2 distracted cycle 6 hardly match metronome later cycles. Overall, subjects can synchronize metronome subjects reveal fluctuation others.C (panels three four), subjects exposed entrainment.\nentrainment happens, expect see change relative phase due dynamic adaption. Overall, change seen cycles 39 seconds.\nHowever, panels show extreme pattern, dyad_8 cycles dyad_15 dyad_13.better see structure cycles, can squeeze sequence ten outphasing-inphasing cycles one single outphasing-inphasing cycle 39 seconds, figure 8.2. now easier see dyads tend entrain, despite request follow metronome. , show kind bubble, although still hard see happens exactly. also see strange behavior subject 2 dyad_8 dyad_15 rather consistent cycles. shows constant decrease subject 2. Dyad_13 seems less similar, see increasing subject 1. ’ll see, drifts point total entrainment meaning subject following subject, rather metronome.However, deeper analysis needed get clearer view phenomena.\nFigure 8.2: Overview raw tapping data, squeezed one cycle, coupled condition (C).\nOverall, inspection raw data suggests interaction outcomes vary among dyads subjects within dyads behave differently. subjects capable sync metronome uncoupled condition, subjects apparently overwhelmed interaction coupled condition. ’s can say far.modelling can go step .\ncan model performance dyad cycle state-space model order get coupling delay parameters, well observation noice.\ngive us clearer picture entrainment behaviour population.","code":""},{"path":"chapTappers2.html","id":"data-from-state-space-model","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"8.3 Data from state-space model","text":"now proceed analysis based state-space model.\nconfiguration specified figure 7.2.apply configuration interaction conditions U C.\nrequires word explanation using state-space model conditions implies test modelling allow state-space model capture interaction none.\nObviously, U, fitted models shouldn’t capture interaction. coupling strength parameter metronome expected stay close 1 (adherence metronome).","code":""},{"path":"chapTappers2.html","id":"running-a-single-model-with-stan","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"Running a single model with Stan","text":"modelling Stan similar previous chapter, , one model per cycle (n= 10) dyad (n=19) given condition (n=2). total, 380 models.show run one single model, say C_dyad_8_cycle_2. stands cycle 2 dyad 8 condition C.First filter data model, tappings recorded experiment:also need relative phase originally tapped data:relative phase shown :\nFigure 8.3: Top: relative phase. Bottom: rotated phase\nNext define function first prepares data state-space model runs Stan engine code state-space model.show routine calls stan function run set TRUE. However, pre-calculated model stored result .rds file, read.figure 8.4 show summary posterior fit.\nFigure 8.4: Posterior distribution major parameters state-space model\ninterpretation parameters straightforward. coupling parameter (\\(k\\)), whose value goes 0 1 reveals \\(s1\\) adheres \\(m1\\), \\(s2\\) clearly entrained even .4. \\(s1\\) clearly leader.\nphase delay parameters (\\(d\\)), whose value goes \\(-\\pi\\) \\(\\pi\\) reveal delay \\(s1\\) metronome \\(m1\\) constant, altough slightly behind metronome, \\(s2\\) uncertainty seenms ahead metronome. Obviously, distribution taken states. uncertainty \\(ds1s2\\) huge compared uncertainty delay \\(s2\\) \\(s1\\) (\\(ds2s1\\)).\nobservation_std, fluctuation, reveals metronomes fluctuation, \\(s2\\) slightly fluctuation \\(s1\\).can retrieve parameters explicitly :Using fit, can also retrieve generated quantities explicitly (also called: posterior predictions) :Let us briefly reflect .\ncolumns observations_generated states_generated represent phase values, unit, generated 100 instances uniformly distributed 39 seconds. Accordingly, retrieve real time, multiply column time \\(39/100\\).follows, show calculate relative phase observations_generated, showing grey band captures .75% uncertainty.\nrelative phase calculated similar chapter 7.\nscript also similar chapTappers_05_ModelPlotting calculated relative phase.generate plot showing relative phase:calculate instantaneous period states_generated.figure reveals tapping period \\(s2\\) heavily entrained \\(s1\\).","code":"\ndatt <- DTapping %>% filter(codycy == \"C.dyad_8.cycle_5\") %>% arrange(time0c)\n# Note that we use the function do_calc_phase2 to calculate the relative phase based on time values\n  Dummy <- datt \n  if( length(w<-which(Dummy$time0c==0)) > 0) {Dummy <- Dummy[-w,]\n  print(paste(\"---->\",w,\"is deleted\"))}\n  Om1 <- Dummy %>% filter(names_indicator == 1) %>% mutate(time = time0c) %>% dplyr::select(time,names_indicator)\n  Os1 <- Dummy %>% filter(names_indicator == 2) %>% mutate(time = time0c) %>% dplyr::select(time,names_indicator)\n  Om2 <- Dummy %>% filter(names_indicator == 3) %>% mutate(time = time0c) %>% dplyr::select(time,names_indicator)\n  Os2 <- Dummy %>% filter(names_indicator == 4) %>% mutate(time = time0c) %>% dplyr::select(time,names_indicator)\n  dummy_C1 <- do_calc_phase2(Os1,Om1)\n  dummy_C2 <- do_calc_phase2(Os2,Om2)\n  Observations_relphase <- rbind(dummy_C1,dummy_C2) \n  rm(Dummy,Om1,Os1,Om2,Os2)\n  rm(dummy_C1,dummy_C2)\np0 <- ggplot() + \n  geom_point(data = Observations_relphase,\n             aes(x=time,#%%aligned_beat_sec,\n                 y=relphase,\n                 color = factor(names_indicator)), \n             shape = 1, size = 2, alpha = 1) +\n  theme_bw() +\n  scale_fill_manual(values=cbPalette) +\n  scale_colour_manual(labels = c(\"m1-s1\", \"m2-s2\"), values=cbPalette) +\n  labs(color = \"\")  # Change the legend label\n\np1 <- ggplot() + \n  geom_point(data = Observations_relphase,\n             aes(x=time,#%%aligned_beat_sec,\n                 y= do_rotate(relphase),\n                 color = factor(names_indicator)), \n             shape = 1, size = 2, alpha = 1) +\n  theme_bw() +\n  scale_fill_manual(values=cbPalette) +\n  scale_colour_manual(labels = c(\"m1-s1\", \"m2-s2\"), values=cbPalette) +\n  labs(color = \"\")  # Change the legend label\n\n\np <- p0 / p1\np\n\n# \\@ref(fig:chapTappers2run3)\ndo_TapFitting_Stan <- function(Dat, fn){\n  # Dat = datt\n  # fn = filenameFitted\n  # Define general variables needed in the StanData\n  n_gen_times = 100\n  time_gen = seq(0.0001,max(Dat$time0c), length.out = n_gen_times) # time generated\n  filename <- paste(fn,unique(Dat$codycy),\".rds\",sep=\"\")\n  # Organize our data for Stan\n  StanData <- list(\n    n_times = length(Dat$time0c),\n    n_gen_times = n_gen_times, # number of model-generated times requested\n    time0 = 0.0,\n    observed = Dat$phase,\n    time = Dat$time0c,\n    time_gen = time_gen,\n    names_indicator = Dat$names_indicator\n  )\n  fit <- rstan::stan(\n    data = StanData,\n    #  file = \"../chapTappers/StateSpaceModel_2_oct2024.stan\",\n    file = \"Code/chapTappers2/chapTappers2_StateSpaceModel.stan\",\n    init = 0, thin = 2, iter = 4000,\n    warmup = 1000, cores = 2, chain = 2\n  )\n  return(fit)\n}\nrun = FALSE\n#run = TRUE\nif(run){\nfit <- do_TapFitting_Stan(datt, filenameFitted)\n} else {\n  print(\"readRDS a model\")\n  fit <- readRDS(\"Fitted/chapTappers2_C.dyad_8.cycle_8.rds\")\n}## [1] \"readRDS a model\"\nrun = FALSE## # A tibble: 12 × 8\n##    .variable            .value   .lower   .upper .width .point .interval names  \n##    <chr>                 <dbl>    <dbl>    <dbl>  <dbl> <chr>  <chr>     <fct>  \n##  1 ds1m1               0.277    0.198    0.428     0.95 median qi        ds1m1  \n##  2 ds1s2              -0.188   -1.52     1.01      0.95 median qi        ds1s2  \n##  3 ds2m2              -0.635   -1.08    -0.193     0.95 median qi        ds2m2  \n##  4 ds2s1              -0.107   -0.216    0.00484   0.95 median qi        ds2s1  \n##  5 ks1m1               0.958    0.834    0.994     0.95 median qi        ks1m1  \n##  6 ks2m2               0.253    0.195    0.311     0.95 median qi        ks2m2  \n##  7 observation_std[1]  0.00815  0.00688  0.00979   0.95 median qi        observ…\n##  8 observation_std[2]  0.218    0.182    0.264     0.95 median qi        observ…\n##  9 observation_std[3]  0.00731  0.00615  0.00879   0.95 median qi        observ…\n## 10 observation_std[4]  0.352    0.295    0.431     0.95 median qi        observ…\n## 11 y0_s1               0.0290  -0.227    0.291     0.95 median qi        y0_s1  \n## 12 y0_s2              -0.0599  -0.322    0.207     0.95 median qi        y0_s2## # A tibble: 6 × 8\n##    time  unit states_generated   .lower  .upper .width .point .interval\n##   <int> <int>            <dbl>    <dbl>   <dbl>  <dbl> <chr>  <chr>    \n## 1     1     1          0.00105  0.00105 0.00105   0.75 median qi       \n## 2     1     2          0.0301  -0.115   0.180     0.75 median qi       \n## 3     1     3          0.00103  0.00103 0.00103   0.75 median qi       \n## 4     1     4         -0.0588  -0.215   0.0969    0.75 median qi       \n## 5     2     1          4.07     4.07    4.07      0.75 median qi       \n## 6     2     2          4.17     4.07    4.27      0.75 median qi## # A tibble: 6 × 8\n##    time  unit observations_generated   .lower  .upper .width .point .interval\n##   <int> <int>                  <dbl>    <dbl>   <dbl>  <dbl> <chr>  <chr>    \n## 1     1     1               0.000894 -0.00863 0.0103    0.75 median qi       \n## 2     1     2               0.0343   -0.262   0.325     0.75 median qi       \n## 3     1     3               0.00125  -0.00759 0.00963   0.75 median qi       \n## 4     1     4              -0.0601   -0.495   0.382     0.75 median qi       \n## 5     2     1               4.07      4.06    4.08      0.75 median qi       \n## 6     2     2               4.17      3.89    4.44      0.75 median qi\n  # From fit_ps (summary of posterior selecting parameters)\n  S <- fit_ps %>% \n    dplyr::select(.variable,.value) %>% \n    mutate(.value= round(.value,2)) %>% \n    rename(parameter = .variable, fitted = .value) %>% \n    arrange(match(parameter,c(\"ds1m1\",\"ds2m2\",\"ds1s2\",\"ds2s1\",\"ks1m1\",\"ks2m2\"))) %>% \n    data.frame() \n  # Prepare string for plot\nstring_plot = paste(\"k= \", toString(S$fitted[5:6]), \n                    \"; d= \", toString(S$fitted[1:4]),\"\\n\",\n                    \"fluct= \", toString(S$fitted[c(8,10)]), sep=\"\")                           \n  # aligned_beat_sec \n  aligned_beat_sec = 39\n  \n  # From post_observations (summary of posterior selecting generated quantities)\n  # we rotate the phase from [0, 2pi] to [-pi, pi] when plotting\n  m1 <- post_observations %>% filter(unit == 1) \n  s1 <- post_observations %>% filter(unit == 2)\n  m2 <- post_observations %>% filter(unit == 3)\n  s2 <- post_observations %>% filter(unit == 4)\n  \n  # 1. Relative phase calculation.\n  # Given the fact that we have the phase, we can just take the difference between the \n  # phase of the metronome unit and the phase of the subject unit\n  dummy_data1 = data.frame(time = s1$time, \n                           relphase.y = m1$observations_generated - s1$observations_generated) %>% \n    mutate(names = \"m1-s1\")\n  dummy_data1.l = data.frame(relphase.lower = m1$.lower - s1$.lower)\n  dummy_data1.u = data.frame(relphase.upper = m1$.upper - s1$.upper) \n  \n  dummy_data2 = data.frame(time = s2$time, \n                           relphase.y = m2$observations_generated - s2$observations_generated) %>% \n    mutate(names = \"m2-s2\")\n  dummy_data2.l = data.frame(relphase.lower = m2$.lower - s2$.lower) \n  dummy_data2.u = data.frame(relphase.upper = m2$.upper - s2$.upper) \n  \n  y = rbind(dummy_data1,dummy_data2)\n  ymin = rbind(dummy_data1.l,dummy_data2.l)\n  ymax = rbind(dummy_data1.u,dummy_data2.u)\n  Observations_generated_relphase = cbind(y,ymin,ymax)\n  # remove dummy variables\n  rm(dummy_data1,dummy_data1.l,dummy_data1.u)\n  rm(dummy_data2,dummy_data2.l,dummy_data2.u)\ncbPalette <- c(\"#E69F00\",\"#56B4E9\",\"#E69F00\",\"#56B4E9\")\np0 <- ggplot() +\n  geom_lineribbon(data = Observations_generated_relphase, \n                  aes(x = (time*aligned_beat_sec/100.5),\n                      y = (relphase.y),\n                      ymin = (relphase.lower),\n                      ymax = (relphase.upper),\n                      color = names),alpha=.5) +\n  geom_point(data = Observations_relphase,\n             aes(x=time,#%%aligned_beat_sec,\n                 y=(relphase - (2*pi)),\n                 color = factor(names_indicator)), shape = 1, size = 2, alpha = 1) +\nscale_fill_manual(values=cbPalette) +\n  scale_colour_manual(labels = c(\"m1-s1\", \"m2-s2\"), values=cbPalette) +\n  #ylim(-pi/2,+pi/2) + \n  theme_bw() + \n  ggtitle(paste(\"model\",string_plot) ) +\n  xlab(\"time [s]\") + ylab(\"relative phase\")\nprint(p0)\n  # 2. Instantaneous period of continuous generated observations\n  \n  m1 <- post_states %>% filter(unit == 1) \n  s1 <- post_states %>% filter(unit == 2)\n  m2 <- post_states %>% filter(unit == 3)\n  s2 <- post_states %>% filter(unit == 4)\n  \n  m1_ip <- m1 %>% mutate(states_generated = c(NA,diff(states_generated)),names = \"m1\") \n  s1_ip <- s1 %>% mutate(states_generated = c(NA,diff(states_generated)),names = \"s1\")\n  m2_ip <- m2 %>% mutate(states_generated = c(NA,diff(states_generated)),names = \"m2\")\n  s2_ip <- s2 %>% mutate(states_generated = c(NA,diff(states_generated)),names = \"s2\")\n  states_generated_instperiod = rbind(m1_ip,s1_ip,m2_ip,s2_ip) \n  states_generated_instperiod$names = factor(states_generated_instperiod$names, levels = c(\"m1\",\"s1\",\"m2\",\"s2\"))\n  rm(m1_ip,s1_ip,m2_ip,s2_ip)\n  \n  # #########################################\n  \n  \n  #2. Plot instantaneous phase\n  cbPalette <- c(\"#E69F00\",\"#E69F00\",\"#56B4E9\",\"#56B4E9\")\n  p1 <-    ggplot() + \n    geom_line(data = states_generated_instperiod, \n              aes(x=time*aligned_beat_sec/100.5,\n                  y=(aligned_beat_sec/100.5)*2000*pi/(states_generated),color=names),linewidth=1.5)  + \n    theme_bw() +\n    scale_fill_manual(values=cbPalette) +\n    scale_colour_manual(labels = c(\"dm1\", \"ds1\", \"dm2\", \"ds2\"), values=cbPalette) +\n    # ggtitle(paste(\"States (black) and generated states (color), model\",s,\"\\n\",ss) )+\n    ylab(\"inst. period\") +\n    xlab(\"time [s]\")\n  p1\n#  make_fig(paste(\"Figures/chapTappers2_exampleRelphase_model_\",sep=\"\"), p0)\n#  make_fig(paste(\"Figures/chapTappers2_exampleInstPeriod_model_\",sep=\"\"), p1)\n  \n  p01 <-  p0/p1 \n  p01"},{"path":"chapTappers2.html","id":"running-all-models","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"8.4 Running all models","text":"now ready run 380 models.\nprocessed server, using script shown Code/chapTappers2/chapTappers2_05_ModellingAllModels.R.outcome calculation parameter dataset, shown Table 8.1.\nlabels value parameter refer values parameters, , coupling strength phase delay.\nTable 8.1: Dataset parameters, dynamic models fitted tapping data\n","code":""},{"path":"chapTappers2.html","id":"global-histograms","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"Global histograms","text":"Let’s look posteriors parameters models.\nmodel take posterior distribution parameter take mean (iterations mcmc-optimization) \ncoupling strength (k) phase delay (d), fluctuation.\nFigure 8.5: Histograms show mean posterior distribution parameter, 380 state-space models. Left panel coupling strength; middle panel phase delay; right panel fluctuation.\nFigure 8.5 (top panel) shows compling strength parameters \\(ks1m1\\) \\(ks2m2\\) conditions U C. values uncoupled condition (U) overall suggest high adherence-coupling strength line expectations, although performances show adherence-coupling strength < .7, considered poor. latter suggest tappings interpreted spurious interactions subject.values coupled condition (C) shows flat distribution suggesting subjects differ response entrainment. Values even go .4, suggesting loss adherence, meaning partner followed instead metronome. However, also coupling strengths close 1, suggesting influence neglected. Overall, seems mean may .7, meaning overall, entrainment happens.Figure 8.5 (middle panel) shows phase delays.\nFirst consider phase delays metronome (\\(ds1m1, ds2m2\\)). values mainly positive suggesting anticipation, U C.\nNext consider phase delays partner. seem center around zero, U C, meaning delay partner average zero. reasonable think similar delay metronome.Figure 8.5 (lower panel) shows fluctation, standard deviation observation parameter. Recall mean observation parameter state value. Obviously, metronomes, fluctuation zero, difference observation state. However, subjects, observe average fluctuation .3 phase value state, models fluctuation 1 . value standard deviation, implies 95% data points situated interval \\([0.588 (= 1.96 * .3,-0.588]\\) around states.","code":""},{"path":"chapTappers2.html","id":"histograms-uncoupled-condition-u","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"Histograms uncoupled condition (U)","text":"detailed view showh \nfigure 8.6.\ntop panel shows posterior distributions retained models terms median \\(.25/.75\\) quantiles cycles. bottom panel shows summary cycles.\ncan done delay parameters, shown figure 8.7.\nFigure 8.6: Estimated coupling strength uncoupled condition (U) (top row) coupled condition (C) (bottom row), dyads (numbered 1, 2, …) cycles shown\nFigure 8.6 now shows details coupling strength parameters per dyad per cycle. condition U, dyads low coupling strength values, dyads 1, 4, 6, 13, 14. Typically, one subject bad score, dyad 1 14, subjects low scores.\ncondition C, situation can different per dyad.\nGood performers (high coupling strength values U), either reveal entrainment dyad 2, 3, 5, 12,17, 19, 20, entrainment dyad 9 18. latter meas subjects largely resist influence observing partner. , good performing dyad (U) can reveal asymmetric entrainment, meaning one subject adheres metronome, subject fully entrained, dyad 8.\nFigure 8.7: Estimated phase delays\nFigure 8.7 reveals abberation dyad_1 6.\nmay due bad converge modelling.\nFigure 8.8: Estimated fluctuation\nFinaly, figure 8.7 shows fluctuation high dyacs, dyad 1, 6, 11, individual cycles.conclusion dyads show particular individualities can identified based posterior distributions parameters.","code":""},{"path":"chapTappers2.html","id":"leader-follower","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"Leader-follower","text":"Based parameter dataset possible get view leader-follower relationship.\nFigure 8.9 suggest conditions normal distribution around zero. mean standard deviation -0.005 (0.13) U 0.07 (0.25) C. Values zero mean subject 1 leading, zero subject 2 leading. condition C, dyad_8 pops , indicating subject 1 leading.\nFigure 8.9: Leader-folllower values. zero means subject 1 leading, zero: subject 2.\nRecall leader-follower relation (LF) difference based adherence coupling strength subjects dyad. value doesn’t capture whether subjects good performance.\nexample, know coupling strength values dyad_1 low subjects,\ndifference small subjects low values.Overall, standard deviation three times larger C, meaning due entrainment larger variability leader-follower relationships.\nLF values C pronounced U.\nexample, dyads 8, 14, 15, 17 19, values mostly positive, whereas dyads 9, certainly 13, values mostly negative, meaning subjects become consistent leader follower cycles, due entrainment!","code":""},{"path":"chapTappers2.html","id":"regression-2","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"8.5 Regression","text":"Finally, ran simple regression model data shown \nfigure 8.5.\ngoal estimate means posterior distribution defined conditions coupling strengths.","code":""},{"path":"chapTappers2.html","id":"syntax-specification","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"Syntax specification","text":"syntax model specified :distributional model estimates parameters (\\(\\mu\\) \\(\\sigma\\)) skew-normal distribution data. response called .value, refers mean distributions \\(ks1m1\\) \\(ks2m2\\) obtained state-space modelling 380 performances. \ncondition (U, C) .variable (\\(ks1m1\\) \\(ks2m2\\)) predictors, dyad:cycle group-level predictor.\nlatter implies cycles within dyad modeled random variable.phase delays use similar model assuming gaussian distribution.","code":"\n  form_K00 = bf(.value ~ condition * .variable + ( 1 + condition * .variable| dyad:cycle),\n     sigma ~ condition * .variable + ( 1 + condition * .variable| dyad:cycle))\n  form_D00 = bf(parameter ~ condition * names + ( 1 | dyad:cycle),\n                sigma ~ condition * names + ( 1  | dyad:cycle))"},{"path":"chapTappers2.html","id":"results","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"Results","text":"Figure 8.10 shows posterior predictions coupling strength phase delay parameters.\nFigure 8.10: Estimated parameters per condition, excluding group effects cycle dyad. (Top panel) Coupling strength. (Bottom panel) Phase delays\nTable 8.2 shows summary parameters.\ncan used generate states using state equation state-space model (see ).\nTable 8.2: Estimated phase delay per condition\nfar get decent view parameters state-space models.\ncan go details estimate coupling strength parameters per dyad, averaging cycles. However, contribute much knowledge already . Therefore, skip .","code":""},{"path":"chapTappers2.html","id":"plots-of-dynamic-models","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"Plots of dynamic models","text":"section, show relative phase instantaneous period representations generated observations (=posterior predictions). Basically put code chunks generating one big function, called do_plot_gen_obs (see Code/chapTappers2/chapTappers2_06_SSMPlotting.R).know already \\(k\\) high adherence, \\(\\hat{\\phi}\\) fluctuating along straight horizontal line, whose distance metronome depends \\(d\\). example, top panel figure 8.11 shows high adherence \\(ks1m1= 0.85\\) \\(ks2m2= 0.74\\) (summarized \\(k= 0.84,0.74\\) figure) anticipative bias: \\(ds1m1= 0.69[rad], ds1s2= 1.37\\) \\(ds2m2= -0.28, ds2s1= -0.31\\) (summarized \\(d= 0.69, 1.37, -0.28, -0.31\\)). Finally also fluctuation 0.23 0.37 \\(s1\\) \\(s2\\) (summarized \\(fluct= 0.23, 0.37\\)). latter gives overall idea thickness gray band around states, depends real observations, shown circles.\nbottom panel shows instantaneous period states.parameters \\(k\\) \\(d\\) can used generate function simple ode-simulator http://odetappers.shinyapps.io/odetappers2/.\nFigure 8.11: Posterior predictions\nFigure 8.12 shows generated observations dyad_2 cycle_6. Now \\(k=0.6,0.48\\) \\(d=0.45,-0.35,0.37,-0.37\\). Note rotated axis figure top panel. show better fit generated observations real observations.\nFigure 8.12: Posterior predictions\nextreme example asymmetric entrainment shown figure 8.13.\nperformance, \\(s2\\) almost completely following \\(s1\\). instantaneous period \\(s2\\) becomes almost equal instantaneous period \\(s1\\).\nFigure 8.13: Posterior predictions\ntapping data contain lot fluctuation, irregularities, may difficult find proper solution . Consider particular example Figure 8.14.\nsolution already great difficulties beginning cycle. may due priors starting value, rather narrowly defined.\nmodel assumes start around zero, around 2 -2.\nstate-space model tracks \\(s2\\) \\(s1\\).\nFigure 8.14: Posterior predictions\nHowever, way check models via Rhat, diagnostic sampling behavior applied Stan. Rhat \\(< 1.05\\). check C.dyad_1.cycle_5 observe high Rhat values.check Rhat values 10 parameters reveals 29 380 models, Markov Chain Monte Carlo (MCMC) chains converge properly. Although necessarily mean model immediately rejected, high values suspicious.\ntable shows line number right (n=380), mRhat value, showing mean Rhat relevant parameters per model, identifier model. Clearly majority models high mRhat condition C, high values dyad_1 dyad_6.\n(#tab:chapTappers2_table)Rhat diagnostics\n","code":"\n  fit <- readRDS(paste(\"Fitted/chapTappers2_\", \"C.dyad_1.cycle_5\", \".rds\", sep=\"\"))\nsummary(fit)$summary %>% head(n=10) %>% data.frame() %>% dplyr::select(Rhat)##                         Rhat\n## ks1m1              12.831067\n## ks2m2               2.944094\n## ds1m1              12.457047\n## ds2m2               2.330697\n## ds1s2               1.820453\n## ds2s1               4.471217\n## observation_std[1]  1.002823\n## observation_std[2]  2.905088\n## observation_std[3]  1.001673\n## observation_std[4]  2.305922\nRhatMean <- readRDS(\"Fitted/chapTappers2_RhatMean.rds\")\nw = which(RhatMean$mRhat > 1.05)\n#RhatMean[w,]\n\n knitr::kable(RhatMean[w,],  booktabs=T, label = NA, \n             caption = paste(\"Rhat diagnostics\")) %>%\n  kable_styling(\"striped\", font_size = 10)"},{"path":"chapTappers2.html","id":"generating-observations-from-the-average","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"Generating observations from the average","text":"earlier stage obtained mean values fitted parameters condition C.\n, plug mean values state equations.\ngives us idea average dyad population experiences entrainment.\nFigure 8.15: Generated phase-functions average dyad interaction. (Top panel) Relative phase. (Middle panel) Instantaneous frequency. (Bottom panel) instantaneous frequency difference\nresults shown figure 8.15.\ntop panel shows relative phase representation.\nmiddle panel shows instantaneous frequency.\nbottom panel shows instantaneous frequency difference.\nshow frequency rather period ’ll compare recurrence analysis.","code":"\ndydt <- function(t, y, parms) {\n  with(as.list(c(y, parms)), {\n    p600 = 2*pi*1000/600\n    p610  = 2*pi*1000/609.375\n    dm1 = p600\n    ds1 = p600  + \n      .5*(ks1m1* sin(m1 - s1 + ds1m1) + \n            (1-ks1m1)* sin(s2 - s1 + ds1s2) )\n    \n    dm2 = p610  \n    #Eigenfrequency s2, m2 (600 * 609.375/9.375) /1000 = 39\n    ds2 = p610    + \n      .5*(ks2m2* sin(m2 - s2 + ds2m2) + \n            (1-ks2m2)* sin(s1 - s2 + ds2s1) )\n    return(list(c(dm1,ds1,dm2,ds2)))\n  })\n}\n\ndt = 1/1000\ntime_points <- seq(0, 39, by = dt)\nstate <- c(m1 = 0, s1 = 0, m2 = 0, s2 = 0)\n\n# plug in the estimated parameter values here:\nparm = c(ks1m1 = 0.72, ks2m2 = 0.65, \n         ds1m1 = 0, ds2m2 = 0, \n         ds1s2 = 0, ds2s1 = 0)\n\nsolution <- ode(y = state, times = time_points, func = dydt, parms = parm) %>% \n  data.frame()\nsolution <- solution %>% mutate(\n  dm1 = c(NA,diff(m1)),\n  ds1 = c(NA,diff(s1)),\n  dm2 = c(NA,diff(m2)),\n  ds2 = c(NA,diff(s2))\n)\n\np0 <- solution %>% group_by(time) %>% ggplot() +\n  geom_line(aes(x= time,y = do_rotate(m1-s1)), color=\"#56B4E9\",size=1) +\n  geom_line(aes(x= time,y = do_rotate(m2-s2)), color = \"#E69F00\",size=1) +\n  ylim(-pi,pi) +\n  theme_bw() +\n  labs(x=\"time of one cycle\", y = \"rel. phase\") +\n  labs(y=\"relative phase\")\n\np1 <- solution %>% group_by(time) %>% ggplot() +\n  geom_line(aes(x= time,y = ds1),color=\"#56B4E9\",size=1) +\n  geom_line(aes(x= time,y = ds2),color = \"#E69F00\",size=1) +\n  geom_vline(xintercept = 39/2, color = \"#D55E00\", linetype = \"dotted\") +\n  labs(x=\"time of one cycle\", y = \"inst. frequency\") +\n  #ylim(585,635) +\n  theme_bw() \n\np2 <- solution %>% group_by(time) %>% ggplot() +\n  geom_line(aes(x= time,y = ds2 - ds1),color = \"black\",size=1, linetype = \"dotted\") +\n  geom_vline(xintercept = 36.6/2, color = \"#D55E00\", linetype = \"dotted\") +\n  labs(x=\"time of one cycle\", y = \"freq difference\") +\n  theme_bw() \n\np0 / p1 / p2\n# \\@ref(fig:chapTappers2dynEq2)"},{"path":"chapTappers2.html","id":"smooth-regression-of-relative-phase","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"Smooth regression of relative phase","text":"section try good old smooth regression approach data represented relative phase. give us smooth curve, capturing underlying dynamic tapping? Similar smooth regression modelling used chapters 4 6?use following model specification:relphase relative phase subject metronome, subjectcondition interaction two subject two conditions, dyad:cycle group-level variable cycle per dyad, kappa second parameter von_mises model fitting function.Figure 8.16 shows smooth regression solution.\nRecall vertical axis relative phase horizontal axis time one cycle.\nfigure suggests flat line uncoupled condition (U) subjects.\ncontrast, figure shows curved lines coupled condition (C), suggesting entrainment.\ncurve asymmetrical sense delayed respect metronomes anti-phase point.\nMoreover, also observe anticipation sense curves zero.\nThanks explorations dynamic model previous chapter, meanwhile know works.\nFigure 8.16: Overview raw tapping data, squeezed one cycle, coupled condition (C).\nSmooth regression limitations mainly purely descriptive, based expansion data hyper-space spline functions. goal show state-space model can replicate figure, using dynamic parameters can interpreted coupling strength phase delay.\nfact, result comes close , see top panel figure 8.15.","code":""},{"path":"chapTappers2.html","id":"recurrence-analysis","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"Recurrence analysis","text":"alternative approach, tapping data subjected recurrence analysis (Rosso et al.,2023). analysis, phase sample time \\(\\phi_t\\) expanded phase vector, \\(d\\) delay \\(\\tau\\) defining expansion. :\\[\n\\hat{\\phi}_t = <\\phi_{t + (d-1)\\tau}>\n\\]\n\\(\\hat{\\phi}_t \\R^d\\) \n\\(d\\) estimated embedding dimension, \n\\(\\tau\\) estimated delay phases.time-delayed versions phase can thought coordinates point \n\\(d\\)-dimensional space.\nexample, choose \\(d=3\\) \\(\\tau=1\\), time-delayed versions phase time \\(t=1\\) \\(x(1),x(2)\\), \\(x(3)\\). three values can thought \\(x,y,z\\) coordinates point three-dimensional space.matrix \\(R_{t,s}^{d,\\tau}\\) defined \n\\[\nR_{t,s}^{d,\\tau} = \\Theta(\\epsilon - \\left\\| x_t - x_s \\right\\|), \\quad x_t \\\\mathbb{R}^d, \\quad t, s = 1, \\ldots, T\n\\]\n\\(\\epsilon\\) threshold distance, \\(\\Theta\\) Heaviside function, \\(\\left\\| . \\right\\|\\) length vector difference, can interpreted phase difference, instantaneous frequency.\nmatrix contains \\(1\\) difference phase-vectors \\(x_t\\) \\(x_s\\) falls within ball defined \\(\\epsilon\\), \\(0\\) otherwise.Given matrix \\(R_{t,s}^{d,\\tau}\\), sum samples \\(t\\) results counts sample instance \\(s\\).\nAccordingly, resulting graph can interpreted histogram phase differences.joint recurrence analysis two subjects, figure 8.17, matrix first calculated subjects separately, giving \\(Rs1_{t,s}^{d,\\tau}\\) \\(Rs2_{t,s}^{d,\\tau}\\), whose notation can simplified \\(Rs1\\) \\(Rs2\\).Taking intersection \\(Rs1 \\cap Rs2\\) (cells \\(1\\) \\(Rs1\\) \\(Rs2\\) \\(1\\), \\(0\\) otherwise) summing rows, obtain histogram represents instantaneous frequency difference among subjects. figure 8.17 10 cycles, 19 dyads folded one single cycle.Figure 8.17 (Rosso et al., 2023) shows result dyads, time series squeezed one cycle. figure histogram, shows number times two subjects phase difference (tolerance \\(\\epsilon\\)) time, within time interval corresponding bin.\ntwo subjects different instantaneous frequencies, synchronization two subjects unstable. frequency differences vary time, peaks histogram wider.\nFigure 8.17: Recurrence analysis. blue lines considered. show uncoupled (1P Uncoupled) coupled (2P Coupled) conditions.\nRecurrence analysis limitations mainly purely descriptive doesn’t capture parameters dynamic model. Likewise, goal develop dynamic model replicate figure, using dynamic parameters can interpreted coupling strength phase delay.lower panel figure 8.15 shows result comes close recurrence analysis.","code":""},{"path":"chapTappers2.html","id":"summary","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"Summary","text":"summarize, started 380 dyadic finger tapping performances using data Rosso et al. (2024). model, estimated parameters state-space model data. configuration state-space model developed previous chapter.hypothesis uncoupled condition (U) higher adherence coupling strength coupled condition (C) confirmed. adherence coupling strengths uncoupled condition close 0.87, coupled condition close \\(ks1m1 = 0.71\\) \\(ks2m2 =  0.66\\).\nresult implies overall, two subjects seeing tapping, dramatic reduction adherence coupling strength, despite request adhere metronome. implies considerable entrainment coupling strength subject.Apparently, coupled condition (C) average (dyads) subject \\(s2\\) lower adherence coupling strength 5% metronome \\(m2\\), compared \\(s1\\). plausible \\(s1\\) advantage due tapping speed., using fitted parameters generated continuous observations based generated continuous states, can compared discrete tapping data. Using averages parameters, possible generate data @ref(fig:chapTappers2_dynEq2). curves represent relative phase, instantaneous frequency instantaneous period, instantaneous frequency difference. high similarity smooth regression solutions recurrence analysis performed entire population reveals power state-space approach.","code":""},{"path":"chapTappers2.html","id":"conclusion-6","chapter":"8 Two finger tappers’ entrainment (Part 2)","heading":"8.6 Conclusion","text":"chapter, explored synchronized finger tapping can entrained seeing partner tapping differently. fact non-voluntary entrainment can override intended audio-based synchronization shows entrainment extremely powerful phenomenon.conclusion entrainment may hard resist. seems brain determined solve incongruent feedback, degree resistance entrainment might require specific training targetted neglecting cause incongruency.Entrainment believed play crucial role activities require joint collaboration, joint music playing. context, entrainment added value dynamic adaptation activities. Entrainment fits well idea self-augmented interaction, can seen facilitator augmentation.showed entrainment can understood, basically, control competing dynamic forces, informed hearing seeing. Statistical modeling helped us understand entrainment state-space system describing causal flow timing. ends journey non-linear regression.","code":""},{"path":"chapConclusion.html","id":"chapConclusion","chapter":"9 Conclusion","heading":"9 Conclusion","text":"book, two parallel pathways mutually support : theory modelling.\nbriefly overview main findings.","code":""},{"path":"chapConclusion.html","id":"contribution-to-theory","chapter":"9 Conclusion","heading":"9.1 Contribution to theory","text":"Music interaction primarily studied viewpoint timing, dancers, violin players finger tappers.\nTiming clearly involves subconscious processing, sensorimotor adaptation structure dancing, sensorimotor feedback based parallax modality effectiveness, last least, entrainment mutual adaptation finger tapping interactions.phenomena can related predictive processing, embodiment expression individual subjects, seems reductionist understanding insufficient. order understand music interaction, also need holistic understanding level dynamic system multiple interacting units. showed timing-related emerging effects interacting units can based phase flow among interacting units.However, also assume physical states emerging embodied interactions, affect brain processing, leading particular dynamic interactions regions brain. didn’t address book ’s super-cool assumption, albeit speculative, fact brain engages interactions among neurons augment . latter imply brain state associated self-augmented interaction state. Another super-cool assumption brain states empowering effect individual, meaning associated corporeal changes beneficial individual.main hypothesis self-augmented interaction states rests overall dynamic concept covers assumptions. end book, claim proven , evidence explorations hypothesis. fact, evidence explorations support hypothesis. example, entrainment indeed facilitates collaboration makes easier co-regulate actions view common goal.However, major difficulty studying self-augmented interaction states concerned generating states laboratory setting. challenge future research clever paradigms needed generate interaction states controlled conditions.","code":""},{"path":"chapConclusion.html","id":"contribution-to-modelling","chapter":"9 Conclusion","heading":"9.2 Contribution to modelling","text":"First , word said datasets modern musicology.\nDatasets contain data multiple modalities, auditory, visual, tactile, haptic sensing, well body movement, brain activity, questionnaires.\ndata come different media, \nrecording devices audio video, motion capture systems, EEG brain scan devices.Furthermore, data high-dimensional. Apart high resolution time space – speak milliseconds millimeter ranges – modality may involve different markers sensors: full-body motion tracking requires easily >30 markers. EEG cap may 64 electrodes. Audio can measured multiple microphones . fine-resolution spatiotemporal data thus get multiplied number markers /sensors. require perfect synchronization different measuring devices involved.multiple modalities high-dimensional character data streams become challenge every music research. Efforts needed handle data make available othe researchers.\ngood data structure necessity flexible modelling.said, book assumed already dataset behavior timing.\nexplored use different modelling techniques based regression, umbrella global Bayesian epistemology.showed curve fitting interesting modelling technique capturing assumed underlying process timing. regression based smooths, data expanded larger space defined functions (splines) modelling fits data combinations functions, obtain weights functions. regression based dynamic system, fit data functions generated dynamic system, obtain parameters represent functions. approach powerful parameters express causal components understanding.","code":""},{"path":"chapConclusion.html","id":"our-limitations","chapter":"9 Conclusion","heading":"9.3 Our limitations","text":"book modest attempt explore music interactions. reached end, feel just started understanding little pieces, even little pieces understanding suffer limitations.Firstly, focus primarily revolved around behavioral data analysis using regression techniques, neglected promising advancements neurobiology neuroscience, well availability high-dimensional data (including EEG types body sensing).Secondly, controlling variables data collection, potentially compromised ecological validity music interactions. use specific technologies augmented reality (e.g. hololens), haptic connection (e.g. exoskeletons) allow unique control action-perception loops governing interactions, confronted question self-augmented interaction states can controlled, even important, perhaps, can sure human really experiencing self-augmented interaction state. Apparently, lot variability humans engage mutual interactions, facilitated music.Lastly, provide exhaustive account statistical modeling techniques. Rather, focused selected range methods, primarily regression-based, deemed relevant understanding data music interactions. hope listeners can appreciate fact music research deals small datasets, subtle effect sizes, considerable uncertainty stemming complexities natural music interaction contexts.","code":""},{"path":"chapConclusion.html","id":"outlook","chapter":"9 Conclusion","heading":"9.4 Outlook","text":"exploration music interaction R, mainly based regression modelling, turned useful connecting theory data.\nOverall, insights obtained explorations suggest timing key feature music interaction. draw discourse close, worth reiterating immense challenge better understanding dynamics underlies music-based transformative powers.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"Bader, R. (Ed.). (2018). Springer handbook systematic musicology. Springer.Bonicco-Donato, D. (2016). Une archéologie de l’interaction. De David Hume à Erving Goffman. Paris: Vrin.Bürkner P. C. (2021). Bayesian Item Response Modelling R brms Stan. Journal Statistical Software. doi:10.18637/jss.v100.i05Bürkner P. C. (2018). Advanced Bayesian Multilevel Modeling R Package brms. R Journal. doi:10.32614/RJ-2018-017Bürkner P. C. (2017). brms: R Package Bayesian Multilevel Models using Stan. Journal Statistical Software. doi:10.18637/jss.v080.i01Campo, ., Michałko, ., Van Kerrebroeck, B., Stajic, B., Pokric, M., Leman, M. (2023a). assessment presence performance AR environment motor imitation learning: case-study violinists, Computers Human Behavior, Volume 146, 2023, 107810, ISSN 0747-5632, https://doi.org/10.1016/j.chb.2023.107810.Campo, ., Michałko, ., Van Kerrebroeck, B., Leman, M. (2023b).\nDataset assessment presence performance augmented reality environment motor imitation learning: case-study violinists. Data Brief 51 109663.\nhttps://10.1016/j.chb.2023.107810Campo, ., Van Kerrebroeck, B., Leman, M. (2024).\nMC-AR — software suite comparative mocap analysis augmented reality environment\nSoftware Impacts 19 100605. https://doi.org/10.1016/j.dib.2023.109663.Campo, . et al. (submitted). Haptic Feedback Violin Education: Case Study Robotic Exoskeleton-Mediated Motor Learning.Carpenter, B. (2018). Predator-Prey Population Dynamics:\nLotka-Volterra model Stan.\nhttps://mc-stan.org/users/documentation/case-studies/lotka-volterra-predator-prey.htmlClayton, M., Sager, R., & , U. (2005). time music: concept entrainment significance ethnomusicology. European meetings ethnomusicology.(Vol. 11, pp. 1-82). Romanian Society Ethnomusicology.Collins, T., Tillmann, B., Barrett, F. S., Delbé, C., & Janata, P. (2014). combined model sensory cognitive representations underlying tonal expectations music: audio signals behavior. Psychological review, 121(1), 33.Demos, . Palmer, C. (2023).\nSocial nonlinear dynamics unite: musical group synchrony,\nTrends Cognitive Sciences. https://doi.org/10.1016/j.tics.2023.05.005Dunn, P. Smyth, G. (2018). Generalized linear models examples R. New York: Springer.Gelman, ., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, ., & Rubin, D. B. (2014). Bayesian Data Analysis (3rd ed.). CRC Press.Gesmann, M., Morris, J. Hierarchical Compartmental Reserving Models. Casualty Actuarial Society, CAS Research Papers, 19 Aug. 2020, https://www.casact.org/sites/default/files/2021-02/compartmental-reserving-models-gesmannmorris0820.pdfHallam, S. Himonides, E. (2022). power music. exploration evidence. Open book publishers.Kruschke, J. K. (2015). Bayesian Data Analysis: Tutorial R, JAGS, Stan (2nd ed.). Academic Press.Langner, G. D. (2015). neural code pitch harmony. Cambridge University Press.Leman, M. (2007). Embodied music cognition mediation technology. MIT press.Leman, M. (2016). expressive moment: interaction (music) shapes human empowerment. MIT press.McElreath, R. (2020). Statistical Rethinking: Bayesian Course Examples R Stan (2nd ed.). CRC Press. See https://github.com/rmcelreath/stat_rethinking_2020.Michałko, ., Di Stefano, N., Campo, . Leman, M. (2024). Enhancing human-human\nmusical interaction kinesthetic haptic feedback using wearable exoskeletons: theoretical foundations, validation scenarios, limitations. Frontiers Psychology. 15:1327992. https://doi.org/10.3389/fpsyg.2024.1327992Michałko, ., Six, J., Campo, ., Van Kerrebroeck, B., Pokric, M., Leman, M. (submitted). Amateur Violin practice augmented reality: Exploring user’s behaviour experience.Repp, B., Su, YH (2013). Sensorimotor synchronization: review recent research (2006–2012). Psychonomic Bulletin & Review 20, 403–452. https://doi.org/10.3758/s13423-012-0371-2Reybrouck, M., & Van Dyck, E. (2024). music drug? music listening may trigger neurochemical responses brain. Musicae Scientiae, 0(0). https://doi.org/10.1177/10298649241236770Roback, P. Legler, J. (2021). Beyond multiple linear regression. Applied generalized liear models multilevels models R. CRC press. See https://bookdown.org/roback/bookdown-BeyondMLR/Robbins, T, Everitt, B, Nutt, D. (2010). neurobiology addiction. Oxford University Press.Rosso, M., Maes, P.J. & Leman, M. (2021). Modality-specific attractor dynamics dyadic entrainment. Sci Rep 11, 18355. https://doi.org/10.1038/s41598-021-96054-8Rosso, M., Van Kerrebroeck, B., Maes, P-J & Leman, M. (2023). Embodied perspective taking enhances interpersonal synchronization. body-swap study. iScience. (accepted)Rosso, M., Maes PJ. & Leman, M. (preparation). (Tentative title) Estimating coupling phase delay parameters entrainment body-swap study.Russell JA. (1980). circumplex model affect. Journal Personality Social Psychology. 1980;39:1161–1178. doi: 10.1037//0022-3514.79.2.286.Schneider, . (2018a). Pitch pitch perception. Springer Handbook Systematic Musicology (pp. 605-686). Springer, Berlin, Heidelberg.Schneider, . (2018b). Perception timbre sound color. Springer Handbook Systematic Musicology (pp. 687-725). Springer, Berlin, Heidelberg.Sears, D. R., Pearce, M. T., Spitzer, J., Caplin, W. E., & McAdams, S. (2019). Expectations tonal cadences: Sensory cognitive priming effects. Quarterly Journal Experimental Psychology, 72(6), 1422–1438. https://doi.org/10.1177/1747021818814472Seth, . K. (2015). cybernetic Bayesian brain - interoceptive inference sensorimotor contingencies.\nT. Metzinger & J. M. Windt (Eds). Open MIND: 35(T). Frankfurt Main: MIND Group. doi: 10.15502/9783958570108Singer, J. Willett, J. (2003). Applied longitudinal data analysis. Modeling change event occurrence. Oxford University Press.Talebi, M. , Campo, ., Aarts, N. & Leman, M. (2023).\nInfluence musical context sensorimotor synchronization classical ballet solo dance. Plos one 18 (4), e0284387.\nhttps://doi.org/10.1371/journal.pone.0284387Trost, W. J., Labbé, C., & Grandjean, D. (2017). Rhythmic entrainment musical affect induction mechanism. Neuropsychologia, 96, 96-110.Vuust, Peter & Heggli, Ole & Friston, Karl & Kringelbach, Morten. (2022). Music brain. Nature Reviews Neuroscience. 23. 10.1038/s41583-022-00578-5.","code":""}]
