# Theory {#chapTheory}


All the assumptions -- or call them hypotheses -- that will tested in this book refer to a theory of music interaction. And this theory resembles what grandmother told us^[Admitted, not only grandmother. Also great writers and philosophers, including Homer in the *Illiad*, Dante in *Divina Comedia*, or Spinoza in the *Ethics*, advocated the idea that effort is needed to achieve something in life.], namely that, to achieve something in life, a little effort is needed. The idea applies to human interaction with music. An effort in the form of an alert and active participation is needed to establish and interaction with music, and achieve something from that interaction, such as a feeling of power and beauty. With music?

This chapter is an attempt to reformulate grandmother's advice from the perspective of core theoretical concepts that are prominent in modern music research. 

## Self-augmented interactions

Basically, in this book we assume that people have an urge to create and engage themselves in particular interaction states involving music, because they experience benefits from doing it. These interaction states are special in the sense that they facilitate an increased alertness and attention, reduce stress, optimize perception and critical spatial-temporal actions, engaging a chain of bodily-related changes that affect human well-being. The states that facilitate these effects are called *self-augmented interaction states*.
They are *self*-augmented because people create these interactions states for themselves, volitional, by choice and decision.

Our goal is to find evidence that supports the theory (or falsify it).
However, at this moment, we are far from being able to prove this theory of *self-augmented interaction*, the reason being that the research domain is young and insufficiently mature to handle the enormous complexity of what is going on. Evidence is likely to be based on a joint effort of behavioral and neuroscience studies, involving neurobiology as a necessary component of the entire picture. Increased alertness, reduced stress, pleasure and motivation suggest the involvement of neurotransmitters and hormones such as norepinephrine, oxytocine, cortisol, dopamine that regulate brain functions, affecting behavioral activities during interactions^[References in this book are restricted, mainly to reviews and textbooks, but not exclusively. For a review of neurochemical responses to music, see Reybrouck and Van Dyck (2024).].
We envision the complexity of a dynamic mechanism whose state can be build up over time, be maintained for a while, until it declines and becomes a normal state back again. This kind of complexity is challenging. Being able to identify the *self-augmented interaction state* is already a challenge.

However, we contribute to this theory by focusing on timing. It's a tiny little part of the grand dynamic mechanism but we believe that timing is interesting because it is a distinguishing, measurable, and partly controllable, feature of interacting. 

The paradigmatic example is the tempo of the music played by an ensemble of musicians. The tempo is a feature of timing and it is created and maintained by the collaborative effort and co-regulation of the musicians in the ensemble. It is a precarious state that is associated with the ensemble's musical quality. For sure, tempo is not the only interesting feature of timing, but it's an important one. It can be measured, for example, by identifying onsets in audio, and calculating the underlying distribution of inter-onset intervals. When timing is stable, we have a special interaction state built upon alertness, physical effort, and fine sensory-motor control. These are expected features of a self-augmented interaction state. Other bodily features associated with those states can then be studied in more detail.

In short, the theory of self-augmented interaction is about improving ourselves, in one or another way. And the drive for doing this is probably not yet entirely clear. Is it solely the effort -- pleasure -- reward -- motivation chain or is there something more, something set by goals or beliefs?
A complete theory of *self-augmented interaction* might not yet be within our reach, but our goal is to contribute to it, firstly by posing it as a valuable theory, secondly, by offering data-analysis tools that sharpen some details of contributing insights that may lead us towards the ultimate theory.

## Supporting theories

The ultimate theory, which is clearly a *complex dynamic theory*, draws upon a number of other theories about humans interacting with their environment.
These theories relate to embodiment, prediction and expression.

### Embodiment {-}
*Embodiment* holds the idea that humans have a repertoire of gestures and actions, which they use for coding and decoding music^[These ideas have been explored in several books, see Leman (2007, 2016), as well as several book chapters in God√∏y and Leman, eds. (2010) and Bader, ed. (2028).]. During music playing (or coding), different kinds of bodily gestures shape phrasing, articulations, and intonations, and structure in sound. Accordingly, musical sound will reflect traces of these gestures as patterns, called the *moving sonic forms*. During listening and dancing (or decoding), the human decoder recruits bodily gestures from the own gesture repertoire to align with these *moving sonic forms*. This alignment allows the human decoder to develop an understanding of music from a gestural/action perspective, that is, by embodying the gestural traces in the music.

Musical embodiment, as a encoding and decoding of gestures, works for many people because they have a shared repertoire of gestures and actions. That repertoire is partly biological, due to the shared bio-mechanics and biological basis of all humans over all cultures, and partly cultural, due to codifications of how people move and behave in different cultural contexts.

As timing is rooted in bodily actions that encode the sound cues for timing, there is a close relationship between timing and body movement. Sometimes it can be hard to detect timing cues from audio but it is likely that these timing cues can also be extracted from bowing gestures. For this we rely on movement recordings with *motion capture systems*^[This technology, as well as many other technologies are standard for music research. An example infrastructure can be explored at   https://asil.ugent.be/infrastructure/].

### Prediction {-}
Embodiment is connected with *prediction*, or the idea that moving sonic forms can be anticipated by the human encoder/decoder^[For some background ideas of where thid idea comes from, see Seth (2015).]. Often this anticipation is based on gesturing. For example, during dancing on the beat of music, gestural alignment and body movement is typically initiated ahead of the beat. If it were not ahead, the movement would be too late. 

Moving in sync with the musical beat thus proves that embodiment is fundamentally predictive. Consider conducting your preferred piece of music on cd^[Admitted, this is old technology, but it also works with streaming.]. Your conducting of that music is likely ahead of time, due to predictive processing of your brain. When you are really engaged in conducting, it probably gives you a feeling of agency and power. Why? It's the effect of the *reverse causality* illusion^[David Hume, in his *A Treatise of Human Nature*, launched the idea that causality in the brain is a matter of association, taking into account time and a contiguous relationship between cause and effect. In other words, Hume assumed that in the brain, causality is just a association, nothing more, no force or whatsoever.]. In that illusion, it appears as if your gesturing *causes* the music. As if your movement is the cause, and music is the effect.
The reason for that illusion is correlation and contiguity: gestural and musical events go hand in hand, and gestural events come before musical events.

Obviously, the perception of reverse causality is illusory because the music goes on when your gesturing suddenly stops. Nevertheless, the experience of the reverse causality illusion may create a strong feeling of control (agency). You may feel that the your gestures have consequences in music. You may feel control over the music, and it gives you a particular sense of power and satisfaction about that power.

The connection with self-augmented interaction is clear.
Establishing reverse causality through self-created augmented interaction states may be a crucial ability of the human decoder to create empowering effects.

Nevertheless, reverse causality is not the only effect. Due to prediction, it is just possible to co-regulate our own action with those heard from another musician, in such a way that a stable tempo can be established by collaboration. Prediction is everywhere and therefore, it's a crucial element for understanding how self-augmented interaction states can be maintained. Effects such as the *reverse causality* illusion can be a seen as a consequence of prediction.


### Expression {-}
Embodiment and prediction, when considered from the viewpoint of a social interaction, supports *expression*. This viewpoint holds that gestures are social signals, rooted in the human social biological and in the culturally codified social actions. A gesture is an expressive signal when its receiver responds with an expressive signal^[The viewpoint adopted here is based on scholars working on human interaction, such as David Hume, Charles Darwin, Adam Smith, Erving Goffman. See Bonicco-Donato (2016) for a historical overview.]. By exchanging expressive signals, through gestures, sender and receiver typically tend to trigger
the embodied predictions through arousal, an enhanced state of attention, focus and emotional engagement that strongly contributes to self-augmented interaction states. It could lead to ritualized behavior when the exchanging gestures are habituated.

Expression is therefore crucial when people interact with each other and we speak about *expressive timing* when timing works as a signal evoking responses from the audience.
By mutual exchange of gestural expressions, and thanks to predictions, humans are capable of interacting with each other in a coordinated manner. As musical rhythms enhance these exchanges of bodily expression through rhythms, it will facilitate the formation of a co-regulated interaction and pave the way for self-augmentation.

Together the three constructs offer a way for understanding the musical self-augmentation in terms of a *gestural, anticipatory, and expressive dynamic*. Ultimately, its dynamic results in a state of being where senses, cognitive abilities, and emotional engagement have become sharpened and function optimally. 


## Moving sonic forms

Given the above theories, it is useful to define music from the perspective of *moving sonic forms* and its *emergent patterns endowed with expression*.

### Pattern emergence {-}

*Pattern emergence* is the idea that a pattern has structural features conjugate with the human disposition for emergence. Due to the disposition and the structure, emergence may happen. For example, the auditory system is a disposition that transforms a harmonic structure composed of 600, 800, 1000, 1200 Hz in a pitch heard at 200 Hz^[For a review of the human auditory system and pitch as pattern emergence, see (Langner, 2015).].

The auditory disposition may also fuse multiple of those harmonic patterns into a chord. And when such harmonic patterns are played in sequence, their fusion may elicit expectations, leading to tonal tensions and relaxation dynamics^[For reviews of pitch and timbre perception in music, see Schneider (2018a, b).]. The bottom-up mechanisms of pattern emergence may compete with top-down mechanisms of patterns formed by habits, and this competition may influence the perception of tonal tension and relaxation, although the precise contributions of sensory (bottom up) and cognitive (long term memory) processing are still debated^[Collins et al. (2014) show how tonality can be understood from sensory processing. 
Sears et al. (2018) for a discussion of sensory and cognitive tonality effects.]. 

A similar observation can be made for rhythms. Rhythms are made of pulses that subsume the meter as a super-structure that emerges from the lower-level pulse structure.
Similarly, timbres might blend and form emergent  patterns of texture, a phenomenon that is well-known in orchestration. 

Blending timbres is less obvious for speech because it may just blur the signal, making it less apt for understanding its semantics. Moreover, in music it often happens that different performers co-regulate their actions in order to generate a joint pattern emergence at rhythmic, pitch and timbre levels. Again, this phenomenon of joint speech is far less prominent in speech. In heathed debates a moderator will intervene and tone down, leaving the word to only one speaker.

### Endowed expression {-}
Music is characterized by the fact that emergent patterns get *endowed with expression*. The latter refers to the importance of gesturing during encoding and decoding^[See God√∏y and Leman, 2010.]. As discussed, gestural traces form a constituent part of the sound pattern. These will mould musical pitch with portamento and intonation. In a similar way, they make intervals shorter and longer in order to pronounce rhythms. Gestural traces will define articulations (e.g., legato and staccato), sound color, musical narrative, and dynamics (e.g., crescendo and diminuendo). 

In short, human gestures get embedded in the structure of music, creating emergent patterns endowed with gestural expression.
Such emergent patterns define moving sonic forms, necessary for generating self-augmented interaction states. 

## Interaction capacities

We are now ready to have a look at music from the perspective of human interaction capacities.
Three additional concepts complete our set of concepts introduced in this chapter.
They are: affordance, entrainment, and narration.

### Affordance {-}
An *affordance* is a property of the music and the capacity to act upon an affordance is called a affordance capacity. Affordances have sometimes been linked with the notion of *frozen emotion* and the idea that composers and performers encode frozen emotion in music, while listeners have the capacity to decode these emotions because they work as affordances. In fact, it is possible to replace emotion with gesture and the idea still stands. 

### Entrainment {-}
*Entrainment* is the capacity of a human decoder to adapt to the music, and aligh with it, either in a continuous manner, when movement flows along with the music, or in a discrete manner, when movement marks musical events^[For introductions to entrainment, see f.i. Clayton et al. (2005) and Trost et al. (2017). ]. As the word suggests, entrainment implies that there is something in the music that attracts the listener. 

In the context of (co-regulated) sensorimotor synchronization, entrainment has been associated with a bias to subliminally reduce prediction errors in the alignment of body movement with sound cues. While entrainment is often defined in relation to synchronization, as the dynamic adaptation of sensorimotor behavior due to a coupling, entrainment may also be defined in a broader perspective, as the capacity of giving a response to cues, or even as a brain-principle acting on neuronal oscillations.

### Narration {-}
Last but not least we have to mention *narration*, the least well-understood principle in music research. *Narration* refers to story telling, and it is often associated with the human encoder. Jazz musicians, for example, use patterns and previously trained playing gestures as a kind of alphabet to construct larger arcs of phrases, and they bind phrases to larger structures: stories in music. The way of telling a narrative, i.e., the performance, is equally important, and it builds anticipation, entrainment, and affordance capacity. 

A good example is Clifford Brown^[He's my favourite trumpet master, difficult to line up with, though.]. He was a legendary jazz trumpeter and composer who died at the young age of 25 in a car crash. He was known for his ability to tell stories through his music, using patterns and previously trained playing gestures to construct larger arcs of phrases. One of his most famous improvizations are on *Joy Spring*. In serveral recorded solos of this piece, one hears similar phrase components arranged differently. One of these solos is widely regarded as one of the best solo improvisations ever played. Brown's work in jazz was as striking for its architectonic structure as for its emotional immediacy. 

Unfortunately, narration is not often integrated in studies on embodiment, prediction, and expression. We have a small contribution in chapter \@ref(chapDancer) but it's limited and more work is needed in this domain, where sensorimotor and cognitive capacities work together.

In short, music involves several capacities that are necessary to interact with the environment. These capacities are well-suited to process the dynamic structure of music, and in return, the emergent patterns. 


## Music addiction

<div class="figure" style="text-align: center">
<img src="Figures/chapTheory_InteractionHypothesis.png" alt="Engine for self-augmented interaction" width="100%" />
<p class="caption">(\#fig:chapTheoryInteractionHypothesis)Engine for self-augmented interaction</p>
</div>
Let us come back to grandmothers idea, that effort is needed to achieve something. So why would people engage themselves in self-augmented interactions that require effort? The answer is that it pays off. However, the compelling force behind this is likely related to the biological processes of addiction^[See Robbins et al. (2010) for theories of addiction.]. 

Figure \@ref(fig:chapTheoryInteractionHypothesis) offers a rough biological model suggesting that interaction with music engages physical effort, expression, and prediction mechanisms that co-engage arousal, valence, and agency, activating reward-related processes, such as dopamine-spread in the brain, that drive human subjects to engage more with music, as in addiction.  
Such a cycle may support the realization of self-augmented interaction states.

We assume that *emergent patterns endowed with expression* facilitate the generation of self-augmented interaction states because these patterns fit with the human capacity for affordance and entrainment. A multi-person co-regulation of actions sets a social context that can be motivating, and the formation of a musical narrative can become compelling. 
And it all pays off, in many ways.

## Note about expression theory

To close this chapter, something should be said about the *expression theory* because it is often, like the narrative, not very well understood, and often neglected. 

Briefly stated, expression theory is based on the idea that expression in person A calls for an expressive response in person B, which in turn serves as stimulus for expression in A and so on, thus leading to a mutual exchange of expressions that might result in a particular interaction state. 
This is indeed what is suggested in figure \@ref(fig:chapTheoryBayesianModel2), from a dynamic perspective.

Although this idea is very simple, expressions do not always require reasons. In many contexts, expressions really don‚Äôt require the inference of a presumed cause. Interactions are often based on a direct and spontaneous gesturing, implying responses to patterns. This direct responding goes fast, and it is based on alignment, mirroring, including counterpoint gesturing. Interpreting an expression in terms of their presumed cause, largely depends on context and type of interaction. The main point is that expressions do not always have to point to some deep underlying state that requires inference to capture it. Thus, expressive interacting may occur without assuming the causes of the expression.

Expression is biological and largely intuitive. Therefore, rather than inferencing the latent state of being (known as the theory of mind theory), it is more appropriate to speak about gestural responding (based on mirroring). The real power of expression exchange is its dynamic ability to build up and maintain self-augmented states. Expression theory may thus be understood in terms of an exchange of expressive gestures as patterns (and their possible inferred underlying states cannot always excluded) that steer-up the interaction towards self-augmented states. 

Having clarified this, the question raises whether Bayesian inference applies to patterns or to causes. 
Sorry, but Bayesian inference is explained in the next chapter.
Anyhow, the answer is that it applies to both. Responding to an expression implies the processing of patterns and the assumption of a particular shape of the observed pattern can be seen as the prior of a Bayesian inference about that pattern. Inferring the cause of an expression would also apply that Bayesian inference scheme. In that case, the prior has a focus on the cause, for example, an emotion, or a character.
In short, the Bayesian inference is a general machinery for dealing with assumptions and observations, regardless whether it applies to expressive forms or expressive causes of those forms.


## Conclusion

With a theory of music interaction in our hands, we have a perspective for understanding what music does with people and what people do with music, and why they do this. This theory evolved over several decades of research in musicology. However, it's far from being an established theory because it needs refinement, or even a reformulation. It is biased by certain trends in cognitive science, and in the future, it's likely that neuroscience and neurobiology will have a important contribution allowing for a refinement of the theory. 

In this book, we use this theory as a general framework for case studies that highlight particular phenomena related to timing. We believe that an proper description and causal modelling of timing may contribute to our understanding of that theory.
And yes, timing covers only a tiny small aspect of the entire theoretical framework but we believe that timing is an essential cornerstone. To be linked up with neuro-something in future research!

<!-- ## References -->

<!-- Reybrouck and Van Dyck (2024), -->
<!-- Leman (2007, 2016), -->
<!-- Bader (2018), -->
<!-- Bonicco-Donato (2016), -->
<!-- Langner (2015), -->
<!-- Schneider (2018a, b), -->
<!-- Collins et al. (2014), -->
<!-- Sears et al. (2018), -->
<!-- God√∏y and Leman (2010), -->
<!-- Clayton et al. (2005), -->
<!-- Trost et al. (2017), -->
<!-- Robbins et al. (2010) -->
